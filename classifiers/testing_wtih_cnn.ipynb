{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "import xml.etree.ElementTree as ET\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"covid\", \"normal\"]\n",
    "DATADIR = \"D:/Project2022/res/final dataset/original/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 - covid\\n1 - non covid\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label\n",
    "'''\n",
    "0 - covid\n",
    "1 - non covid\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_dataset(dataset_path):\n",
    "\n",
    "    df_data = pd.DataFrame()\n",
    "    raw_image = []\n",
    "    concat_data = []\n",
    "    label = []\n",
    "\n",
    "    for categoty in CATEGORIES:\n",
    "        path = os.path.join(dataset_path, categoty)  \n",
    "        \n",
    "        class_num = CATEGORIES.index(categoty)\n",
    "        \n",
    "\n",
    "        print(\"Loading dataset: class\",categoty)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array = cv2.resize(img_array, (512,512), interpolation= cv2.INTER_LINEAR)\n",
    "                row = img_array.sum(axis=0)\n",
    "                coloumn = img_array.sum(axis=1)\n",
    "                concat = np.concatenate((row, coloumn))\n",
    "                \n",
    "                raw_image.append(img_array)\n",
    "                concat_data.append(concat)\n",
    "                label.append(class_num)\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    df_data[\"raw data\"] = raw_image\n",
    "    df_data[\"concat data\"] = concat_data\n",
    "    df_data[\"label\"] = label\n",
    "    \n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: class covid\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02100539207458496,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7149,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc17dd01f9fa4b37b76006f36cf4d9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: class normal\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01901388168334961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6893,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502f412210f04bbcb55b365a54b08269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_df = pre_process_dataset(DATADIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_df[\"label\"].value_counts().plot(kind='bar')\n",
    "plt.xticks([0,1], [\"Covid\", \"Normal\"], rotation='horizontal')\n",
    "plt.ylabel('no of Samples')\n",
    "plt.title('Distribution of classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (14042, 1024)\n",
      "y shape (14042,)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_df[\"concat data\"].values\n",
    "X = [img.tolist() for img in dataset]\n",
    "\n",
    "\n",
    "#for img in dataset:\n",
    "    #X.append(img.tolist())\n",
    "X = np.array(X)\n",
    "y = np.array(dataset_df[\"label\"].values)\n",
    "print(\"X shape\", X.shape)\n",
    "print(\"y shape\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_norm = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dimensions for training \n",
    "dataset_X = np.expand_dims(X_norm, axis=-1)\n",
    "dataset_y = np.expand_dims(y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of the dataset after changing the dimension\n",
      "X :  (14042, 1024, 1)\n",
      "y :  (14042, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\" shape of the dataset after changing the dimension\")\n",
    "print(\"X : \", dataset_X.shape)\n",
    "print(\"y : \", dataset_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_X, dataset_y, shuffle=True, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1024, 1)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Conv1D_500\"\n",
    "NAME = model_name+\"-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000028B25DDBDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000028B25DDBDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "899/899 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.7732WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000028BFBBFE8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000028BFBBFE8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "899/899 [==============================] - 23s 12ms/step - loss: 0.4881 - accuracy: 0.7732 - val_loss: 0.4175 - val_accuracy: 0.8117\n",
      "Epoch 2/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4027 - accuracy: 0.8135 - val_loss: 0.4044 - val_accuracy: 0.8198\n",
      "Epoch 3/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3828 - accuracy: 0.8317 - val_loss: 0.3752 - val_accuracy: 0.8474\n",
      "Epoch 4/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3495 - accuracy: 0.8504 - val_loss: 0.3550 - val_accuracy: 0.8540\n",
      "Epoch 5/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3256 - accuracy: 0.8657 - val_loss: 0.3802 - val_accuracy: 0.8358\n",
      "Epoch 6/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3092 - accuracy: 0.8770 - val_loss: 0.3118 - val_accuracy: 0.8714\n",
      "Epoch 7/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2869 - accuracy: 0.8867 - val_loss: 0.3164 - val_accuracy: 0.8652\n",
      "Epoch 8/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2687 - accuracy: 0.8934 - val_loss: 0.2744 - val_accuracy: 0.8959\n",
      "Epoch 9/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.2472 - accuracy: 0.9033 - val_loss: 0.2620 - val_accuracy: 0.8919\n",
      "Epoch 10/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2321 - accuracy: 0.9106 - val_loss: 0.2520 - val_accuracy: 0.9048\n",
      "Epoch 11/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2244 - accuracy: 0.9141 - val_loss: 0.2608 - val_accuracy: 0.9052\n",
      "Epoch 12/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2052 - accuracy: 0.9214 - val_loss: 0.2308 - val_accuracy: 0.9119\n",
      "Epoch 13/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1993 - accuracy: 0.9218 - val_loss: 0.2240 - val_accuracy: 0.9146\n",
      "Epoch 14/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1864 - accuracy: 0.9306 - val_loss: 0.2223 - val_accuracy: 0.9065\n",
      "Epoch 15/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1812 - accuracy: 0.9290 - val_loss: 0.1938 - val_accuracy: 0.9239\n",
      "Epoch 16/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1752 - accuracy: 0.9332 - val_loss: 0.2240 - val_accuracy: 0.9186\n",
      "Epoch 17/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1677 - accuracy: 0.9351 - val_loss: 0.1850 - val_accuracy: 0.9315\n",
      "Epoch 18/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1545 - accuracy: 0.9401 - val_loss: 0.2193 - val_accuracy: 0.9203\n",
      "Epoch 19/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1540 - accuracy: 0.9447 - val_loss: 0.1855 - val_accuracy: 0.9297\n",
      "Epoch 20/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1474 - accuracy: 0.9437 - val_loss: 0.2014 - val_accuracy: 0.9248\n",
      "Epoch 21/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1426 - accuracy: 0.9446 - val_loss: 0.2050 - val_accuracy: 0.9208\n",
      "Epoch 22/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1406 - accuracy: 0.9449 - val_loss: 0.1794 - val_accuracy: 0.9355\n",
      "Epoch 23/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1376 - accuracy: 0.9464 - val_loss: 0.1731 - val_accuracy: 0.9364\n",
      "Epoch 24/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.1285 - accuracy: 0.9487 - val_loss: 0.1859 - val_accuracy: 0.9332\n",
      "Epoch 25/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1238 - accuracy: 0.9525 - val_loss: 0.1565 - val_accuracy: 0.9421\n",
      "Epoch 26/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1226 - accuracy: 0.9495 - val_loss: 0.1675 - val_accuracy: 0.9368\n",
      "Epoch 27/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1171 - accuracy: 0.9549 - val_loss: 0.1782 - val_accuracy: 0.9350\n",
      "Epoch 28/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1197 - accuracy: 0.9518 - val_loss: 0.2040 - val_accuracy: 0.9261\n",
      "Epoch 29/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1098 - accuracy: 0.9553 - val_loss: 0.1796 - val_accuracy: 0.9364\n",
      "Epoch 30/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1157 - accuracy: 0.9545 - val_loss: 0.1649 - val_accuracy: 0.9390\n",
      "Epoch 31/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1084 - accuracy: 0.9590 - val_loss: 0.2046 - val_accuracy: 0.9212\n",
      "Epoch 32/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1040 - accuracy: 0.9613 - val_loss: 0.1710 - val_accuracy: 0.9399\n",
      "Epoch 33/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1004 - accuracy: 0.9612 - val_loss: 0.1647 - val_accuracy: 0.9413\n",
      "Epoch 34/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1109 - accuracy: 0.9554 - val_loss: 0.1569 - val_accuracy: 0.9426\n",
      "Epoch 35/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.1576 - val_accuracy: 0.9475\n",
      "Epoch 36/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1038 - accuracy: 0.9583 - val_loss: 0.1489 - val_accuracy: 0.9488\n",
      "Epoch 37/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0917 - accuracy: 0.9649 - val_loss: 0.1542 - val_accuracy: 0.9457\n",
      "Epoch 38/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0886 - accuracy: 0.9667 - val_loss: 0.1429 - val_accuracy: 0.9502\n",
      "Epoch 39/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0862 - accuracy: 0.9666 - val_loss: 0.1677 - val_accuracy: 0.9381\n",
      "Epoch 40/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0906 - accuracy: 0.9662 - val_loss: 0.1472 - val_accuracy: 0.9475\n",
      "Epoch 41/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0832 - accuracy: 0.9691 - val_loss: 0.1737 - val_accuracy: 0.9386\n",
      "Epoch 42/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.0905 - accuracy: 0.9642 - val_loss: 0.1381 - val_accuracy: 0.9515\n",
      "Epoch 43/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0816 - accuracy: 0.9684 - val_loss: 0.1483 - val_accuracy: 0.9475\n",
      "Epoch 44/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0805 - accuracy: 0.9694 - val_loss: 0.2857 - val_accuracy: 0.8927\n",
      "Epoch 45/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0780 - accuracy: 0.9706 - val_loss: 0.1405 - val_accuracy: 0.9515\n",
      "Epoch 46/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0824 - accuracy: 0.9685 - val_loss: 0.1465 - val_accuracy: 0.9448\n",
      "Epoch 47/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0771 - accuracy: 0.9698 - val_loss: 0.1600 - val_accuracy: 0.9466\n",
      "Epoch 48/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0717 - accuracy: 0.9716 - val_loss: 0.1652 - val_accuracy: 0.9470\n",
      "Epoch 49/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0703 - accuracy: 0.9741 - val_loss: 0.1643 - val_accuracy: 0.9466\n",
      "Epoch 50/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0812 - accuracy: 0.9701 - val_loss: 0.1708 - val_accuracy: 0.9457\n",
      "Epoch 51/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0670 - accuracy: 0.9738 - val_loss: 0.1447 - val_accuracy: 0.9568\n",
      "Epoch 52/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0579 - accuracy: 0.9770 - val_loss: 0.1620 - val_accuracy: 0.9466\n",
      "Epoch 53/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0747 - accuracy: 0.9717 - val_loss: 0.1603 - val_accuracy: 0.9555\n",
      "Epoch 54/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0613 - accuracy: 0.9764 - val_loss: 0.1729 - val_accuracy: 0.9404\n",
      "Epoch 55/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0660 - accuracy: 0.9741 - val_loss: 0.1406 - val_accuracy: 0.9528\n",
      "Epoch 56/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0623 - accuracy: 0.9756 - val_loss: 0.1697 - val_accuracy: 0.9466\n",
      "Epoch 57/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0555 - accuracy: 0.9773 - val_loss: 0.1327 - val_accuracy: 0.9564\n",
      "Epoch 58/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0533 - accuracy: 0.9799 - val_loss: 0.1520 - val_accuracy: 0.9564\n",
      "Epoch 59/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0707 - accuracy: 0.9738 - val_loss: 0.2214 - val_accuracy: 0.9306\n",
      "Epoch 60/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0561 - accuracy: 0.9784 - val_loss: 0.1686 - val_accuracy: 0.9510\n",
      "Epoch 61/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0579 - accuracy: 0.9765 - val_loss: 0.1780 - val_accuracy: 0.9546\n",
      "Epoch 62/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0478 - accuracy: 0.9820 - val_loss: 0.1620 - val_accuracy: 0.9559\n",
      "Epoch 63/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0669 - accuracy: 0.9757 - val_loss: 0.1715 - val_accuracy: 0.9470\n",
      "Epoch 64/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.1693 - val_accuracy: 0.9533\n",
      "Epoch 65/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0464 - accuracy: 0.9834 - val_loss: 0.1508 - val_accuracy: 0.9595\n",
      "Epoch 66/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.1582 - val_accuracy: 0.9542\n",
      "Epoch 67/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0470 - accuracy: 0.9823 - val_loss: 0.1668 - val_accuracy: 0.9577\n",
      "Epoch 68/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0495 - accuracy: 0.9805 - val_loss: 0.1526 - val_accuracy: 0.9595\n",
      "Epoch 69/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0509 - accuracy: 0.9819 - val_loss: 0.1476 - val_accuracy: 0.9599\n",
      "Epoch 70/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0437 - accuracy: 0.9834 - val_loss: 0.1460 - val_accuracy: 0.9635\n",
      "Epoch 71/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.1763 - val_accuracy: 0.9573\n",
      "Epoch 72/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0527 - accuracy: 0.9824 - val_loss: 0.1792 - val_accuracy: 0.9568\n",
      "Epoch 73/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.1749 - val_accuracy: 0.9591\n",
      "Epoch 74/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.1576 - val_accuracy: 0.9599\n",
      "Epoch 75/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.1389 - val_accuracy: 0.9697\n",
      "Epoch 76/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0520 - accuracy: 0.9822 - val_loss: 0.1482 - val_accuracy: 0.9626\n",
      "Epoch 77/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0394 - accuracy: 0.9850 - val_loss: 0.1327 - val_accuracy: 0.9648\n",
      "Epoch 78/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0401 - accuracy: 0.9839 - val_loss: 0.1656 - val_accuracy: 0.9604\n",
      "Epoch 79/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0409 - accuracy: 0.9840 - val_loss: 0.1285 - val_accuracy: 0.9631\n",
      "Epoch 80/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0398 - accuracy: 0.9854 - val_loss: 0.1412 - val_accuracy: 0.9613\n",
      "Epoch 81/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: 0.2008 - val_accuracy: 0.9484\n",
      "Epoch 82/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 0.1674 - val_accuracy: 0.9586\n",
      "Epoch 83/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.1505 - val_accuracy: 0.9617\n",
      "Epoch 84/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 0.1443 - val_accuracy: 0.9604\n",
      "Epoch 85/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.1232 - val_accuracy: 0.9671\n",
      "Epoch 86/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.1655 - val_accuracy: 0.9555\n",
      "Epoch 87/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0359 - accuracy: 0.9871 - val_loss: 0.1383 - val_accuracy: 0.9644\n",
      "Epoch 88/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.2009 - val_accuracy: 0.9462\n",
      "Epoch 89/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 0.1880 - val_accuracy: 0.9546\n",
      "Epoch 90/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 0.1487 - val_accuracy: 0.9635\n",
      "Epoch 91/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0308 - accuracy: 0.9888 - val_loss: 0.1349 - val_accuracy: 0.9680\n",
      "Epoch 92/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0381 - accuracy: 0.9852 - val_loss: 0.1544 - val_accuracy: 0.9640\n",
      "Epoch 93/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 0.1542 - val_accuracy: 0.9608\n",
      "Epoch 94/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.1834 - val_accuracy: 0.9564\n",
      "Epoch 95/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0461 - accuracy: 0.9846 - val_loss: 0.1768 - val_accuracy: 0.9599\n",
      "Epoch 96/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 0.1879 - val_accuracy: 0.9599\n",
      "Epoch 97/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.1622 - val_accuracy: 0.9573\n",
      "Epoch 98/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0302 - accuracy: 0.9901 - val_loss: 0.1741 - val_accuracy: 0.9577\n",
      "Epoch 99/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0375 - accuracy: 0.9869 - val_loss: 0.1496 - val_accuracy: 0.9640\n",
      "Epoch 100/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0203 - accuracy: 0.9923 - val_loss: 0.1562 - val_accuracy: 0.9657\n",
      "Epoch 101/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.2300 - val_accuracy: 0.9564\n",
      "Epoch 102/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0353 - accuracy: 0.9870 - val_loss: 0.1837 - val_accuracy: 0.9559\n",
      "Epoch 103/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.2468 - val_accuracy: 0.9479\n",
      "Epoch 104/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 0.1370 - val_accuracy: 0.9666\n",
      "Epoch 105/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.1501 - val_accuracy: 0.9626\n",
      "Epoch 106/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0259 - accuracy: 0.9905 - val_loss: 0.1865 - val_accuracy: 0.9559\n",
      "Epoch 107/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.2799 - val_accuracy: 0.9404\n",
      "Epoch 108/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0261 - accuracy: 0.9903 - val_loss: 0.1990 - val_accuracy: 0.9586\n",
      "Epoch 109/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0221 - accuracy: 0.9918 - val_loss: 0.1593 - val_accuracy: 0.9644\n",
      "Epoch 110/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.2621 - val_accuracy: 0.9350\n",
      "Epoch 111/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.1384 - val_accuracy: 0.9680\n",
      "Epoch 112/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1565 - val_accuracy: 0.9613\n",
      "Epoch 113/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.1599 - val_accuracy: 0.9653\n",
      "Epoch 114/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.1484 - val_accuracy: 0.9715\n",
      "Epoch 115/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.1720 - val_accuracy: 0.9631\n",
      "Epoch 116/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.1352 - val_accuracy: 0.9702\n",
      "Epoch 117/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.1638 - val_accuracy: 0.9648\n",
      "Epoch 118/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.1614 - val_accuracy: 0.9622\n",
      "Epoch 119/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.2125 - val_accuracy: 0.9604\n",
      "Epoch 120/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0445 - accuracy: 0.9868 - val_loss: 0.1970 - val_accuracy: 0.9586\n",
      "Epoch 121/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.1536 - val_accuracy: 0.9675\n",
      "Epoch 122/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.1790 - val_accuracy: 0.9582\n",
      "Epoch 123/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1641 - val_accuracy: 0.9675\n",
      "Epoch 124/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.1914 - val_accuracy: 0.9568\n",
      "Epoch 125/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.1596 - val_accuracy: 0.9635\n",
      "Epoch 126/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.1674 - val_accuracy: 0.9617\n",
      "Epoch 127/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.2674 - val_accuracy: 0.9537\n",
      "Epoch 128/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.1514 - val_accuracy: 0.9688\n",
      "Epoch 129/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.1648 - val_accuracy: 0.9693\n",
      "Epoch 130/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1625 - val_accuracy: 0.9671\n",
      "Epoch 131/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.1876 - val_accuracy: 0.9653\n",
      "Epoch 132/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.1829 - val_accuracy: 0.9626\n",
      "Epoch 133/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.1523 - val_accuracy: 0.9648\n",
      "Epoch 134/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.2352 - val_accuracy: 0.9506\n",
      "Epoch 135/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.2088 - val_accuracy: 0.9599\n",
      "Epoch 136/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.1707 - val_accuracy: 0.9702\n",
      "Epoch 137/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.1458 - val_accuracy: 0.9657\n",
      "Epoch 138/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1924 - val_accuracy: 0.9586\n",
      "Epoch 139/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.1573 - val_accuracy: 0.9613\n",
      "Epoch 140/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.1395 - val_accuracy: 0.9720\n",
      "Epoch 141/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.1849 - val_accuracy: 0.9671\n",
      "Epoch 142/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0341 - accuracy: 0.9913 - val_loss: 0.1564 - val_accuracy: 0.9671\n",
      "Epoch 143/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.1446 - val_accuracy: 0.9666\n",
      "Epoch 144/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1515 - val_accuracy: 0.9684\n",
      "Epoch 145/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.2573 - val_accuracy: 0.9435\n",
      "Epoch 146/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.1708 - val_accuracy: 0.9688\n",
      "Epoch 147/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0299 - accuracy: 0.9907 - val_loss: 0.1552 - val_accuracy: 0.9737\n",
      "Epoch 148/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1672 - val_accuracy: 0.9697\n",
      "Epoch 149/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.2304 - val_accuracy: 0.9617\n",
      "Epoch 150/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.1649 - val_accuracy: 0.9684\n",
      "Epoch 151/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.1820 - val_accuracy: 0.9684\n",
      "Epoch 152/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.1737 - val_accuracy: 0.9684\n",
      "Epoch 153/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.2150 - val_accuracy: 0.9622\n",
      "Epoch 154/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.1642 - val_accuracy: 0.9671\n",
      "Epoch 155/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.1771 - val_accuracy: 0.9626\n",
      "Epoch 156/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.1685 - val_accuracy: 0.9702\n",
      "Epoch 157/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.1985 - val_accuracy: 0.9626\n",
      "Epoch 158/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.2195 - val_accuracy: 0.9559\n",
      "Epoch 159/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1751 - val_accuracy: 0.9706\n",
      "Epoch 160/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.1464 - val_accuracy: 0.9697\n",
      "Epoch 161/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.1485 - val_accuracy: 0.9742\n",
      "Epoch 162/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.1507 - val_accuracy: 0.9688\n",
      "Epoch 163/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.1704 - val_accuracy: 0.9688\n",
      "Epoch 164/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.1601 - val_accuracy: 0.9688\n",
      "Epoch 165/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.1454 - val_accuracy: 0.9715\n",
      "Epoch 166/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0408 - accuracy: 0.9900 - val_loss: 0.1626 - val_accuracy: 0.9711\n",
      "Epoch 167/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1541 - val_accuracy: 0.9742\n",
      "Epoch 168/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.1763 - val_accuracy: 0.9688\n",
      "Epoch 169/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.1516 - val_accuracy: 0.9711\n",
      "Epoch 170/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.1560 - val_accuracy: 0.9697\n",
      "Epoch 171/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 0.1928 - val_accuracy: 0.9702\n",
      "Epoch 172/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1810 - val_accuracy: 0.9733\n",
      "Epoch 173/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.2316 - val_accuracy: 0.9640\n",
      "Epoch 174/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.1531 - val_accuracy: 0.9715\n",
      "Epoch 175/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.1816 - val_accuracy: 0.9724\n",
      "Epoch 176/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.1917 - val_accuracy: 0.9662\n",
      "Epoch 177/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.1945 - val_accuracy: 0.9680\n",
      "Epoch 178/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.1767 - val_accuracy: 0.9702\n",
      "Epoch 179/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.2057 - val_accuracy: 0.9662\n",
      "Epoch 180/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.1541 - val_accuracy: 0.9737\n",
      "Epoch 181/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.1726 - val_accuracy: 0.9751\n",
      "Epoch 182/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0193 - accuracy: 0.9920 - val_loss: 0.1794 - val_accuracy: 0.9680\n",
      "Epoch 183/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.1742 - val_accuracy: 0.9702\n",
      "Epoch 184/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.1878 - val_accuracy: 0.9702\n",
      "Epoch 185/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.2070 - val_accuracy: 0.9702\n",
      "Epoch 186/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0266 - accuracy: 0.9927 - val_loss: 0.1957 - val_accuracy: 0.9684\n",
      "Epoch 187/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.1796 - val_accuracy: 0.9675\n",
      "Epoch 188/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.1820 - val_accuracy: 0.9715\n",
      "Epoch 189/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.2100 - val_accuracy: 0.9702\n",
      "Epoch 190/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.1979 - val_accuracy: 0.9720\n",
      "Epoch 191/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.1848 - val_accuracy: 0.9711\n",
      "Epoch 192/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.2187 - val_accuracy: 0.9653\n",
      "Epoch 193/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.2167 - val_accuracy: 0.9684\n",
      "Epoch 194/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.1816 - val_accuracy: 0.9702\n",
      "Epoch 195/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.1972 - val_accuracy: 0.9680\n",
      "Epoch 196/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.2106 - val_accuracy: 0.9586\n",
      "Epoch 197/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.1697 - val_accuracy: 0.9720\n",
      "Epoch 198/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.2035 - val_accuracy: 0.9702\n",
      "Epoch 199/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.1992 - val_accuracy: 0.9711\n",
      "Epoch 200/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1770 - val_accuracy: 0.9680\n",
      "Epoch 201/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0247 - accuracy: 0.9907 - val_loss: 0.2262 - val_accuracy: 0.9617\n",
      "Epoch 202/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.1870 - val_accuracy: 0.9702\n",
      "Epoch 203/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.2208 - val_accuracy: 0.9675\n",
      "Epoch 204/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1849 - val_accuracy: 0.9746\n",
      "Epoch 205/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.2566 - val_accuracy: 0.9613\n",
      "Epoch 206/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.1938 - val_accuracy: 0.9706\n",
      "Epoch 207/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.2476 - val_accuracy: 0.9640\n",
      "Epoch 208/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.2254 - val_accuracy: 0.9653\n",
      "Epoch 209/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1660 - val_accuracy: 0.9706\n",
      "Epoch 210/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1828 - val_accuracy: 0.9706\n",
      "Epoch 211/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.1926 - val_accuracy: 0.9675\n",
      "Epoch 212/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.1985 - val_accuracy: 0.9675\n",
      "Epoch 213/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.2070 - val_accuracy: 0.9666\n",
      "Epoch 214/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.2110 - val_accuracy: 0.9666\n",
      "Epoch 215/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.2182 - val_accuracy: 0.9693\n",
      "Epoch 216/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0280 - accuracy: 0.9929 - val_loss: 0.2029 - val_accuracy: 0.9697\n",
      "Epoch 217/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.2065 - val_accuracy: 0.9724\n",
      "Epoch 218/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.2773 - val_accuracy: 0.9617\n",
      "Epoch 219/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 0.2462 - val_accuracy: 0.9599\n",
      "Epoch 220/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.1995 - val_accuracy: 0.9733\n",
      "Epoch 221/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0080 - accuracy: 0.9967 - val_loss: 0.1884 - val_accuracy: 0.9751\n",
      "Epoch 222/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.2512 - val_accuracy: 0.9680\n",
      "Epoch 223/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.2297 - val_accuracy: 0.9684\n",
      "Epoch 224/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 0.2257 - val_accuracy: 0.9675\n",
      "Epoch 225/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.1904 - val_accuracy: 0.9675\n",
      "Epoch 226/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.2020 - val_accuracy: 0.9675\n",
      "Epoch 227/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.2360 - val_accuracy: 0.9671\n",
      "Epoch 228/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.2073 - val_accuracy: 0.9702\n",
      "Epoch 229/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0232 - accuracy: 0.9943 - val_loss: 0.1841 - val_accuracy: 0.9755\n",
      "Epoch 230/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.1785 - val_accuracy: 0.9653\n",
      "Epoch 231/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.2204 - val_accuracy: 0.9720\n",
      "Epoch 232/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.3206 - val_accuracy: 0.9573\n",
      "Epoch 233/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.1640 - val_accuracy: 0.9751\n",
      "Epoch 234/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.1916 - val_accuracy: 0.9720\n",
      "Epoch 235/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.1913 - val_accuracy: 0.9742\n",
      "Epoch 236/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.2139 - val_accuracy: 0.9720\n",
      "Epoch 237/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.1890 - val_accuracy: 0.9746\n",
      "Epoch 238/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.2743 - val_accuracy: 0.9608\n",
      "Epoch 239/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1855 - val_accuracy: 0.9782\n",
      "Epoch 240/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.1782 - val_accuracy: 0.9777\n",
      "Epoch 241/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.2106 - val_accuracy: 0.9715\n",
      "Epoch 242/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.2005 - val_accuracy: 0.9729\n",
      "Epoch 243/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.2326 - val_accuracy: 0.9671\n",
      "Epoch 244/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.1993 - val_accuracy: 0.9742\n",
      "Epoch 245/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.2054 - val_accuracy: 0.9742\n",
      "Epoch 246/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.2046 - val_accuracy: 0.9746\n",
      "Epoch 247/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.2314 - val_accuracy: 0.9604\n",
      "Epoch 248/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.2052 - val_accuracy: 0.9693\n",
      "Epoch 249/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.1837 - val_accuracy: 0.9742\n",
      "Epoch 250/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.2126 - val_accuracy: 0.9737\n",
      "Epoch 251/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.2946 - val_accuracy: 0.9595\n",
      "Epoch 252/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.1961 - val_accuracy: 0.9715\n",
      "Epoch 253/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.3049 - val_accuracy: 0.9586\n",
      "Epoch 254/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.2324 - val_accuracy: 0.9702\n",
      "Epoch 255/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.2405 - val_accuracy: 0.9640\n",
      "Epoch 256/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.2153 - val_accuracy: 0.9715\n",
      "Epoch 257/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.1987 - val_accuracy: 0.9769\n",
      "Epoch 258/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.1971 - val_accuracy: 0.9746\n",
      "Epoch 259/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.2252 - val_accuracy: 0.9702\n",
      "Epoch 260/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.2231 - val_accuracy: 0.9733\n",
      "Epoch 261/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.2867 - val_accuracy: 0.9675\n",
      "Epoch 262/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.1909 - val_accuracy: 0.9755\n",
      "Epoch 263/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.2042 - val_accuracy: 0.9746\n",
      "Epoch 264/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.2042 - val_accuracy: 0.9666\n",
      "Epoch 265/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.2117 - val_accuracy: 0.9733\n",
      "Epoch 266/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.2005 - val_accuracy: 0.9737\n",
      "Epoch 267/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1858 - val_accuracy: 0.9760\n",
      "Epoch 268/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0267 - accuracy: 0.9931 - val_loss: 0.2332 - val_accuracy: 0.9720\n",
      "Epoch 269/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.2132 - val_accuracy: 0.9711\n",
      "Epoch 270/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1953 - val_accuracy: 0.9755\n",
      "Epoch 271/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.2140 - val_accuracy: 0.9720\n",
      "Epoch 272/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1781 - val_accuracy: 0.9795\n",
      "Epoch 273/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.1734 - val_accuracy: 0.9680\n",
      "Epoch 274/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.1760 - val_accuracy: 0.9742\n",
      "Epoch 275/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.3455 - val_accuracy: 0.9515\n",
      "Epoch 276/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.1681 - val_accuracy: 0.9769\n",
      "Epoch 277/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.2222 - val_accuracy: 0.9711\n",
      "Epoch 278/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.1862 - val_accuracy: 0.9755\n",
      "Epoch 279/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1811 - val_accuracy: 0.9764\n",
      "Epoch 280/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1814 - val_accuracy: 0.9791\n",
      "Epoch 281/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0332 - accuracy: 0.9920 - val_loss: 0.2191 - val_accuracy: 0.9720\n",
      "Epoch 282/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1680 - val_accuracy: 0.9760\n",
      "Epoch 283/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.2306 - val_accuracy: 0.9644\n",
      "Epoch 284/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.1705 - val_accuracy: 0.9746\n",
      "Epoch 285/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.2092 - val_accuracy: 0.9715\n",
      "Epoch 286/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.3536 - val_accuracy: 0.9488\n",
      "Epoch 287/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.1875 - val_accuracy: 0.9777\n",
      "Epoch 288/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1858 - val_accuracy: 0.9764\n",
      "Epoch 289/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.2101 - val_accuracy: 0.9729\n",
      "Epoch 290/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.1989 - val_accuracy: 0.9733\n",
      "Epoch 291/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.2475 - val_accuracy: 0.9662\n",
      "Epoch 292/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1768 - val_accuracy: 0.9795\n",
      "Epoch 293/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.2112 - val_accuracy: 0.9702\n",
      "Epoch 294/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.1934 - val_accuracy: 0.9706\n",
      "Epoch 295/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1898 - val_accuracy: 0.9742\n",
      "Epoch 296/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.2022 - val_accuracy: 0.9711\n",
      "Epoch 297/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.1927 - val_accuracy: 0.9742\n",
      "Epoch 298/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.2263 - val_accuracy: 0.9715\n",
      "Epoch 299/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0255 - accuracy: 0.9943 - val_loss: 0.1843 - val_accuracy: 0.9702\n",
      "Epoch 300/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1760 - val_accuracy: 0.9746\n",
      "Epoch 301/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.2022 - val_accuracy: 0.9680\n",
      "Epoch 302/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.2006 - val_accuracy: 0.9751\n",
      "Epoch 303/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.1729 - val_accuracy: 0.9737\n",
      "Epoch 304/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.1584 - val_accuracy: 0.9800\n",
      "Epoch 305/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.1892 - val_accuracy: 0.9684\n",
      "Epoch 306/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1805 - val_accuracy: 0.9786\n",
      "Epoch 307/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9519\n",
      "Epoch 308/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.2256 - val_accuracy: 0.9586\n",
      "Epoch 309/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1905 - val_accuracy: 0.9764\n",
      "Epoch 310/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1887 - val_accuracy: 0.9769\n",
      "Epoch 311/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.1858 - val_accuracy: 0.9742\n",
      "Epoch 312/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0212 - accuracy: 0.9948 - val_loss: 0.2321 - val_accuracy: 0.9688\n",
      "Epoch 313/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.2699 - val_accuracy: 0.9671\n",
      "Epoch 314/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1967 - val_accuracy: 0.9746\n",
      "Epoch 315/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.2052 - val_accuracy: 0.9706\n",
      "Epoch 316/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1925 - val_accuracy: 0.9782\n",
      "Epoch 317/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.2276 - val_accuracy: 0.9724\n",
      "Epoch 318/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.2302 - val_accuracy: 0.9702\n",
      "Epoch 319/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0264 - accuracy: 0.9947 - val_loss: 0.1838 - val_accuracy: 0.9764\n",
      "Epoch 320/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.2188 - val_accuracy: 0.9724\n",
      "Epoch 321/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.1734 - val_accuracy: 0.9720\n",
      "Epoch 322/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.1734 - val_accuracy: 0.9786\n",
      "Epoch 323/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.2183 - val_accuracy: 0.9711\n",
      "Epoch 324/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.2064 - val_accuracy: 0.9724\n",
      "Epoch 325/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1982 - val_accuracy: 0.9755\n",
      "Epoch 326/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.2385 - val_accuracy: 0.9671\n",
      "Epoch 327/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.2077 - val_accuracy: 0.9697\n",
      "Epoch 328/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.1958 - val_accuracy: 0.9755\n",
      "Epoch 329/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.2382 - val_accuracy: 0.9688\n",
      "Epoch 330/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1878 - val_accuracy: 0.9755\n",
      "Epoch 331/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1801 - val_accuracy: 0.9755\n",
      "Epoch 332/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.2110 - val_accuracy: 0.9680\n",
      "Epoch 333/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.2141 - val_accuracy: 0.9751\n",
      "Epoch 334/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.2520 - val_accuracy: 0.9631\n",
      "Epoch 335/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1752 - val_accuracy: 0.9800\n",
      "Epoch 336/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.2143 - val_accuracy: 0.9746\n",
      "Epoch 337/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.3120 - val_accuracy: 0.9635\n",
      "Epoch 338/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1931 - val_accuracy: 0.9777\n",
      "Epoch 339/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.2046 - val_accuracy: 0.9697\n",
      "Epoch 340/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1850 - val_accuracy: 0.9742\n",
      "Epoch 341/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.1701 - val_accuracy: 0.9764\n",
      "Epoch 342/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.1548 - val_accuracy: 0.9791\n",
      "Epoch 343/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.2243 - val_accuracy: 0.9631\n",
      "Epoch 344/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.1773 - val_accuracy: 0.9755\n",
      "Epoch 345/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1847 - val_accuracy: 0.9769\n",
      "Epoch 346/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.2496 - val_accuracy: 0.9693\n",
      "Epoch 347/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1913 - val_accuracy: 0.9720\n",
      "Epoch 348/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.3586 - val_accuracy: 0.9404\n",
      "Epoch 349/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.1961 - val_accuracy: 0.9729\n",
      "Epoch 350/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9786\n",
      "Epoch 351/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.2200 - val_accuracy: 0.9733\n",
      "Epoch 352/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1755 - val_accuracy: 0.9755\n",
      "Epoch 353/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1857 - val_accuracy: 0.9746\n",
      "Epoch 354/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.2072 - val_accuracy: 0.9791\n",
      "Epoch 355/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.2139 - val_accuracy: 0.9715\n",
      "Epoch 356/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.1813 - val_accuracy: 0.9755\n",
      "Epoch 357/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.1871 - val_accuracy: 0.9760\n",
      "Epoch 358/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.1966 - val_accuracy: 0.9737\n",
      "Epoch 359/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.1924 - val_accuracy: 0.9782\n",
      "Epoch 360/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1977 - val_accuracy: 0.9746\n",
      "Epoch 361/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1797 - val_accuracy: 0.9760\n",
      "Epoch 362/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1652 - val_accuracy: 0.9791\n",
      "Epoch 363/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.2383 - val_accuracy: 0.9666\n",
      "Epoch 364/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.1511 - val_accuracy: 0.9818\n",
      "Epoch 365/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.3457 - val_accuracy: 0.9582\n",
      "Epoch 366/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2036 - val_accuracy: 0.9711\n",
      "Epoch 367/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1713 - val_accuracy: 0.9751\n",
      "Epoch 368/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1658 - val_accuracy: 0.9782\n",
      "Epoch 369/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1995 - val_accuracy: 0.9751\n",
      "Epoch 370/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.1886 - val_accuracy: 0.9786\n",
      "Epoch 371/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1804 - val_accuracy: 0.9760\n",
      "Epoch 372/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.2041 - val_accuracy: 0.9760\n",
      "Epoch 373/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.2084 - val_accuracy: 0.9724\n",
      "Epoch 374/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.2049 - val_accuracy: 0.9737\n",
      "Epoch 375/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 0.1834 - val_accuracy: 0.9751\n",
      "Epoch 376/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1657 - val_accuracy: 0.9795\n",
      "Epoch 377/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1934 - val_accuracy: 0.9755\n",
      "Epoch 378/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1604 - val_accuracy: 0.9777\n",
      "Epoch 379/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.1778 - val_accuracy: 0.9777\n",
      "Epoch 380/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1852 - val_accuracy: 0.9786\n",
      "Epoch 381/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.2073 - val_accuracy: 0.9760\n",
      "Epoch 382/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9760\n",
      "Epoch 383/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.1891 - val_accuracy: 0.9729\n",
      "Epoch 384/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.1960 - val_accuracy: 0.9782\n",
      "Epoch 385/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 9.8947e-04 - accuracy: 0.9997 - val_loss: 0.1696 - val_accuracy: 0.9795\n",
      "Epoch 386/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0176 - accuracy: 0.9955 - val_loss: 0.1614 - val_accuracy: 0.9782\n",
      "Epoch 387/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1667 - val_accuracy: 0.9795\n",
      "Epoch 388/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.1826 - val_accuracy: 0.9769\n",
      "Epoch 389/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1984 - val_accuracy: 0.9742\n",
      "Epoch 390/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.1766 - val_accuracy: 0.9795\n",
      "Epoch 391/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.1799 - val_accuracy: 0.9751\n",
      "Epoch 392/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1865 - val_accuracy: 0.9751\n",
      "Epoch 393/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1693 - val_accuracy: 0.9773\n",
      "Epoch 394/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.1910 - val_accuracy: 0.9737\n",
      "Epoch 395/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1936 - val_accuracy: 0.9742\n",
      "Epoch 396/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.1801 - val_accuracy: 0.9755\n",
      "Epoch 397/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.1978 - val_accuracy: 0.9755\n",
      "Epoch 398/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.2088 - val_accuracy: 0.9742\n",
      "Epoch 399/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.1696 - val_accuracy: 0.9782\n",
      "Epoch 400/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.2699 - val_accuracy: 0.9662\n",
      "Epoch 401/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.2042 - val_accuracy: 0.9742\n",
      "Epoch 402/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.1888 - val_accuracy: 0.9764\n",
      "Epoch 403/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1610 - val_accuracy: 0.9795\n",
      "Epoch 404/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.2135 - val_accuracy: 0.9724\n",
      "Epoch 405/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1759 - val_accuracy: 0.9773\n",
      "Epoch 406/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1713 - val_accuracy: 0.9777\n",
      "Epoch 407/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0272 - accuracy: 0.9938 - val_loss: 0.2525 - val_accuracy: 0.9671\n",
      "Epoch 408/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.2062 - val_accuracy: 0.9724\n",
      "Epoch 409/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.1890 - val_accuracy: 0.9729\n",
      "Epoch 410/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.1876 - val_accuracy: 0.9764\n",
      "Epoch 411/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 7.7593e-04 - accuracy: 0.9999 - val_loss: 0.1759 - val_accuracy: 0.9764\n",
      "Epoch 412/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.1831 - val_accuracy: 0.9760\n",
      "Epoch 413/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2239 - val_accuracy: 0.9688\n",
      "Epoch 414/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.2376 - val_accuracy: 0.9737\n",
      "Epoch 415/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2028 - val_accuracy: 0.9720\n",
      "Epoch 416/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.1788 - val_accuracy: 0.9755\n",
      "Epoch 417/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1796 - val_accuracy: 0.9786\n",
      "Epoch 418/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.2116 - val_accuracy: 0.9760\n",
      "Epoch 419/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.1693 - val_accuracy: 0.9777\n",
      "Epoch 420/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.2677 - val_accuracy: 0.9613\n",
      "Epoch 421/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.2273 - val_accuracy: 0.9706\n",
      "Epoch 422/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.3054 - val_accuracy: 0.9613\n",
      "Epoch 423/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.2041 - val_accuracy: 0.9733\n",
      "Epoch 424/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1847 - val_accuracy: 0.9760\n",
      "Epoch 425/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.2237 - val_accuracy: 0.9640\n",
      "Epoch 426/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.2465 - val_accuracy: 0.9729\n",
      "Epoch 427/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 9.2135e-04 - accuracy: 0.9999 - val_loss: 0.2160 - val_accuracy: 0.9769\n",
      "Epoch 428/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 5.1913e-04 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9764\n",
      "Epoch 429/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.2322 - val_accuracy: 0.9688\n",
      "Epoch 430/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.2178 - val_accuracy: 0.9755\n",
      "Epoch 431/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.2229 - val_accuracy: 0.9755\n",
      "Epoch 432/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.2037 - val_accuracy: 0.9746\n",
      "Epoch 433/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.2646 - val_accuracy: 0.9702\n",
      "Epoch 434/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.1806 - val_accuracy: 0.9764\n",
      "Epoch 435/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.2228 - val_accuracy: 0.9680\n",
      "Epoch 436/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.2334 - val_accuracy: 0.9742\n",
      "Epoch 437/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.2160 - val_accuracy: 0.9737\n",
      "Epoch 438/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2281 - val_accuracy: 0.9733\n",
      "Epoch 439/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.2636 - val_accuracy: 0.9729\n",
      "Epoch 440/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.2176 - val_accuracy: 0.9760\n",
      "Epoch 441/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.2095 - val_accuracy: 0.9760\n",
      "Epoch 442/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2251 - val_accuracy: 0.9769\n",
      "Epoch 443/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 4.4371e-04 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9795\n",
      "Epoch 444/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0120 - accuracy: 0.9955 - val_loss: 0.2106 - val_accuracy: 0.9715\n",
      "Epoch 445/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1996 - val_accuracy: 0.9746\n",
      "Epoch 446/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.2072 - val_accuracy: 0.9782\n",
      "Epoch 447/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.2148 - val_accuracy: 0.9760\n",
      "Epoch 448/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.2292 - val_accuracy: 0.9764\n",
      "Epoch 449/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.2212 - val_accuracy: 0.9760\n",
      "Epoch 450/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.2259 - val_accuracy: 0.9751\n",
      "Epoch 451/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.1990 - val_accuracy: 0.9822\n",
      "Epoch 452/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.2263 - val_accuracy: 0.9786\n",
      "Epoch 453/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.1870 - val_accuracy: 0.9777\n",
      "Epoch 454/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.2444 - val_accuracy: 0.9733\n",
      "Epoch 455/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 8.9276e-04 - accuracy: 0.9999 - val_loss: 0.2239 - val_accuracy: 0.9773\n",
      "Epoch 456/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.2343 - val_accuracy: 0.9764\n",
      "Epoch 457/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.2221 - val_accuracy: 0.9769\n",
      "Epoch 458/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.2241 - val_accuracy: 0.9782\n",
      "Epoch 459/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.2329 - val_accuracy: 0.9742\n",
      "Epoch 460/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.2044 - val_accuracy: 0.9737\n",
      "Epoch 461/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1968 - val_accuracy: 0.9773\n",
      "Epoch 462/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.2038 - val_accuracy: 0.9786\n",
      "Epoch 463/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.2267 - val_accuracy: 0.9715\n",
      "Epoch 464/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.2422 - val_accuracy: 0.9733\n",
      "Epoch 465/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.2332 - val_accuracy: 0.9733\n",
      "Epoch 466/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.2593 - val_accuracy: 0.9675\n",
      "Epoch 467/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.1856 - val_accuracy: 0.9782\n",
      "Epoch 468/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 4.0129e-04 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9769\n",
      "Epoch 469/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.2282 - val_accuracy: 0.9751\n",
      "Epoch 470/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.2021 - val_accuracy: 0.9742\n",
      "Epoch 471/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 9.1078e-04 - accuracy: 0.9999 - val_loss: 0.2150 - val_accuracy: 0.9737\n",
      "Epoch 472/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.2371 - val_accuracy: 0.9729\n",
      "Epoch 473/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1934 - val_accuracy: 0.9755\n",
      "Epoch 474/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.2758 - val_accuracy: 0.9706\n",
      "Epoch 475/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.1928 - val_accuracy: 0.9769\n",
      "Epoch 476/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1943 - val_accuracy: 0.9760\n",
      "Epoch 477/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1989 - val_accuracy: 0.9795\n",
      "Epoch 478/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1858 - val_accuracy: 0.9795\n",
      "Epoch 479/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 2.1747e-04 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9800\n",
      "Epoch 480/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.2255 - val_accuracy: 0.9675\n",
      "Epoch 481/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.1942 - val_accuracy: 0.9751\n",
      "Epoch 482/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.1961 - val_accuracy: 0.9813\n",
      "Epoch 483/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1793 - val_accuracy: 0.9800\n",
      "Epoch 484/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 0.2605 - val_accuracy: 0.9653\n",
      "Epoch 485/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.3007 - val_accuracy: 0.9724\n",
      "Epoch 486/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.2459 - val_accuracy: 0.9746\n",
      "Epoch 487/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.2108 - val_accuracy: 0.9795\n",
      "Epoch 488/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1968 - val_accuracy: 0.9791\n",
      "Epoch 489/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2306 - val_accuracy: 0.9755\n",
      "Epoch 490/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.2269 - val_accuracy: 0.9742\n",
      "Epoch 491/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.2786 - val_accuracy: 0.9697\n",
      "Epoch 492/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.2614 - val_accuracy: 0.9733\n",
      "Epoch 493/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.2526 - val_accuracy: 0.9773\n",
      "Epoch 494/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 6.7487e-04 - accuracy: 0.9999 - val_loss: 0.2430 - val_accuracy: 0.9773\n",
      "Epoch 495/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 8.1371e-04 - accuracy: 0.9999 - val_loss: 0.2864 - val_accuracy: 0.9693\n",
      "Epoch 496/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.2229 - val_accuracy: 0.9724\n",
      "Epoch 497/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.3174 - val_accuracy: 0.9608\n",
      "Epoch 498/500\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.2069 - val_accuracy: 0.9782\n",
      "Epoch 499/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 3.8796e-04 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9786\n",
      "Epoch 500/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0195 - accuracy: 0.9955 - val_loss: 0.3223 - val_accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 500\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    BATCH_SIZE, \n",
    "    EPOCHS, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard])\n",
    "\n",
    "model.save(\"D:/Project2022/models/\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"D:/Project2022/models/\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loss, test accuracy\n",
    "accuracy = model.evaluate(X_test, y_test, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuuracy 0.9725881218910217\n",
      "Test loss 0.22039923071861267\n"
     ]
    }
   ],
   "source": [
    "print(\"Test acuuracy\", accuracy[1])\n",
    "print(\"Test loss\", accuracy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(\"D:/Project2022/models/\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000028C0B905E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000028C0B905E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "88/88 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_test)\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       0.98      0.96      0.97      1395\n",
      "      Normal       0.96      0.98      0.97      1414\n",
      "\n",
      "    accuracy                           0.97      2809\n",
      "   macro avg       0.97      0.97      0.97      2809\n",
      "weighted avg       0.97      0.97      0.97      2809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"covid\", \"Normal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=[\"Covid\",\"Normal\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using just the Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense( 64, activation='relu', input_shape=(1024, 1)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dense_64_500\"\n",
    "NAME = model_name+\"-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000028D35A80C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000028D35A80C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "896/899 [============================>.] - ETA: 0s - loss: 0.6193 - accuracy: 0.6393WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000028BF9062048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000028BF9062048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "899/899 [==============================] - 16s 16ms/step - loss: 0.6194 - accuracy: 0.6393 - val_loss: 0.5554 - val_accuracy: 0.7374\n",
      "Epoch 2/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.4582 - accuracy: 0.7883 - val_loss: 0.4379 - val_accuracy: 0.8060\n",
      "Epoch 3/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.4053 - accuracy: 0.8196 - val_loss: 0.4090 - val_accuracy: 0.8273\n",
      "Epoch 4/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3911 - accuracy: 0.8236 - val_loss: 0.3992 - val_accuracy: 0.8060\n",
      "Epoch 5/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3764 - accuracy: 0.8318 - val_loss: 0.3895 - val_accuracy: 0.8278\n",
      "Epoch 6/500\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.3643 - accuracy: 0.8383 - val_loss: 0.3741 - val_accuracy: 0.8367\n",
      "Epoch 7/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3536 - accuracy: 0.8458 - val_loss: 0.3517 - val_accuracy: 0.8509\n",
      "Epoch 8/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3471 - accuracy: 0.8480 - val_loss: 0.3560 - val_accuracy: 0.8607\n",
      "Epoch 9/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3340 - accuracy: 0.8537 - val_loss: 0.3405 - val_accuracy: 0.8563\n",
      "Epoch 10/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3272 - accuracy: 0.8633 - val_loss: 0.3286 - val_accuracy: 0.8745\n",
      "Epoch 11/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3144 - accuracy: 0.8681 - val_loss: 0.3084 - val_accuracy: 0.8794\n",
      "Epoch 12/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3071 - accuracy: 0.8738 - val_loss: 0.3223 - val_accuracy: 0.8652\n",
      "Epoch 13/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2956 - accuracy: 0.8797 - val_loss: 0.3044 - val_accuracy: 0.8789\n",
      "Epoch 14/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2863 - accuracy: 0.8849 - val_loss: 0.2931 - val_accuracy: 0.8838\n",
      "Epoch 15/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2829 - accuracy: 0.8859 - val_loss: 0.2931 - val_accuracy: 0.8883\n",
      "Epoch 16/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2772 - accuracy: 0.8877 - val_loss: 0.2914 - val_accuracy: 0.8887\n",
      "Epoch 17/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2697 - accuracy: 0.8921 - val_loss: 0.2787 - val_accuracy: 0.8927\n",
      "Epoch 18/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2586 - accuracy: 0.8978 - val_loss: 0.2850 - val_accuracy: 0.8856\n",
      "Epoch 19/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2610 - accuracy: 0.8937 - val_loss: 0.3037 - val_accuracy: 0.8718\n",
      "Epoch 20/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2470 - accuracy: 0.9022 - val_loss: 0.2821 - val_accuracy: 0.8950\n",
      "Epoch 21/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2470 - accuracy: 0.9037 - val_loss: 0.2698 - val_accuracy: 0.8990\n",
      "Epoch 22/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2402 - accuracy: 0.9066 - val_loss: 0.2464 - val_accuracy: 0.9061\n",
      "Epoch 23/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2374 - accuracy: 0.9071 - val_loss: 0.2493 - val_accuracy: 0.9021\n",
      "Epoch 24/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2319 - accuracy: 0.9086 - val_loss: 0.2761 - val_accuracy: 0.8887\n",
      "Epoch 25/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2276 - accuracy: 0.9080 - val_loss: 0.2343 - val_accuracy: 0.9105\n",
      "Epoch 26/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2225 - accuracy: 0.9154 - val_loss: 0.2404 - val_accuracy: 0.9052\n",
      "Epoch 27/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2164 - accuracy: 0.9163 - val_loss: 0.2417 - val_accuracy: 0.9074\n",
      "Epoch 28/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2126 - accuracy: 0.9175 - val_loss: 0.2285 - val_accuracy: 0.9146\n",
      "Epoch 29/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2105 - accuracy: 0.9149 - val_loss: 0.2197 - val_accuracy: 0.9137\n",
      "Epoch 30/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2039 - accuracy: 0.9218 - val_loss: 0.2287 - val_accuracy: 0.9079\n",
      "Epoch 31/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2043 - accuracy: 0.9198 - val_loss: 0.2407 - val_accuracy: 0.9034\n",
      "Epoch 32/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1987 - accuracy: 0.9251 - val_loss: 0.2540 - val_accuracy: 0.9016\n",
      "Epoch 33/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1992 - accuracy: 0.9218 - val_loss: 0.2226 - val_accuracy: 0.9132\n",
      "Epoch 34/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1945 - accuracy: 0.9264 - val_loss: 0.2198 - val_accuracy: 0.9146\n",
      "Epoch 35/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1886 - accuracy: 0.9292 - val_loss: 0.2359 - val_accuracy: 0.9137\n",
      "Epoch 36/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1885 - accuracy: 0.9277 - val_loss: 0.2160 - val_accuracy: 0.9186\n",
      "Epoch 37/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1854 - accuracy: 0.9263 - val_loss: 0.2105 - val_accuracy: 0.9199\n",
      "Epoch 38/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1824 - accuracy: 0.9301 - val_loss: 0.2073 - val_accuracy: 0.9181\n",
      "Epoch 39/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1814 - accuracy: 0.9286 - val_loss: 0.2336 - val_accuracy: 0.9163\n",
      "Epoch 40/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1778 - accuracy: 0.9302 - val_loss: 0.2340 - val_accuracy: 0.9119\n",
      "Epoch 41/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1804 - accuracy: 0.9301 - val_loss: 0.2142 - val_accuracy: 0.9154\n",
      "Epoch 42/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1720 - accuracy: 0.9313 - val_loss: 0.2063 - val_accuracy: 0.9190\n",
      "Epoch 43/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1772 - accuracy: 0.9317 - val_loss: 0.2121 - val_accuracy: 0.9150\n",
      "Epoch 44/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1697 - accuracy: 0.9358 - val_loss: 0.2001 - val_accuracy: 0.9270\n",
      "Epoch 45/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1686 - accuracy: 0.9343 - val_loss: 0.2641 - val_accuracy: 0.8932\n",
      "Epoch 46/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1653 - accuracy: 0.9377 - val_loss: 0.2107 - val_accuracy: 0.9257\n",
      "Epoch 47/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1663 - accuracy: 0.9367 - val_loss: 0.2085 - val_accuracy: 0.9252\n",
      "Epoch 48/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1605 - accuracy: 0.9379 - val_loss: 0.2227 - val_accuracy: 0.9119\n",
      "Epoch 49/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1651 - accuracy: 0.9347 - val_loss: 0.2064 - val_accuracy: 0.9279\n",
      "Epoch 50/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1610 - accuracy: 0.9372 - val_loss: 0.2027 - val_accuracy: 0.9257\n",
      "Epoch 51/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1554 - accuracy: 0.9407 - val_loss: 0.2020 - val_accuracy: 0.9252\n",
      "Epoch 52/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1572 - accuracy: 0.9406 - val_loss: 0.1983 - val_accuracy: 0.9266\n",
      "Epoch 53/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1547 - accuracy: 0.9409 - val_loss: 0.1973 - val_accuracy: 0.9283\n",
      "Epoch 54/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1497 - accuracy: 0.9442 - val_loss: 0.2075 - val_accuracy: 0.9248\n",
      "Epoch 55/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1541 - accuracy: 0.9405 - val_loss: 0.1955 - val_accuracy: 0.9275\n",
      "Epoch 56/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1483 - accuracy: 0.9427 - val_loss: 0.1966 - val_accuracy: 0.9288\n",
      "Epoch 57/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1505 - accuracy: 0.9455 - val_loss: 0.2640 - val_accuracy: 0.8945\n",
      "Epoch 58/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1525 - accuracy: 0.9436 - val_loss: 0.2045 - val_accuracy: 0.9239\n",
      "Epoch 59/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1516 - accuracy: 0.9405 - val_loss: 0.2041 - val_accuracy: 0.9297\n",
      "Epoch 60/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1398 - accuracy: 0.9447 - val_loss: 0.1908 - val_accuracy: 0.9315\n",
      "Epoch 61/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1439 - accuracy: 0.9458 - val_loss: 0.1972 - val_accuracy: 0.9306\n",
      "Epoch 62/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1400 - accuracy: 0.9477 - val_loss: 0.1943 - val_accuracy: 0.9297\n",
      "Epoch 63/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1462 - accuracy: 0.9437 - val_loss: 0.2072 - val_accuracy: 0.9275\n",
      "Epoch 64/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1391 - accuracy: 0.9451 - val_loss: 0.1861 - val_accuracy: 0.9368\n",
      "Epoch 65/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1380 - accuracy: 0.9473 - val_loss: 0.2062 - val_accuracy: 0.9283\n",
      "Epoch 66/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1397 - accuracy: 0.9459 - val_loss: 0.1902 - val_accuracy: 0.9301\n",
      "Epoch 67/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1374 - accuracy: 0.9473 - val_loss: 0.1905 - val_accuracy: 0.9381\n",
      "Epoch 68/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1378 - accuracy: 0.9452 - val_loss: 0.2465 - val_accuracy: 0.9114\n",
      "Epoch 69/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1333 - accuracy: 0.9495 - val_loss: 0.1983 - val_accuracy: 0.9328\n",
      "Epoch 70/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1346 - accuracy: 0.9483 - val_loss: 0.1813 - val_accuracy: 0.9372\n",
      "Epoch 71/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1348 - accuracy: 0.9487 - val_loss: 0.1779 - val_accuracy: 0.9364\n",
      "Epoch 72/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1388 - accuracy: 0.9468 - val_loss: 0.1928 - val_accuracy: 0.9337\n",
      "Epoch 73/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1368 - accuracy: 0.9457 - val_loss: 0.1875 - val_accuracy: 0.9337\n",
      "Epoch 74/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1296 - accuracy: 0.9483 - val_loss: 0.2029 - val_accuracy: 0.9270\n",
      "Epoch 75/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1252 - accuracy: 0.9515 - val_loss: 0.1753 - val_accuracy: 0.9439\n",
      "Epoch 76/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1321 - accuracy: 0.9511 - val_loss: 0.1924 - val_accuracy: 0.9337\n",
      "Epoch 77/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1302 - accuracy: 0.9506 - val_loss: 0.1910 - val_accuracy: 0.9301\n",
      "Epoch 78/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1277 - accuracy: 0.9508 - val_loss: 0.1873 - val_accuracy: 0.9332\n",
      "Epoch 79/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1262 - accuracy: 0.9508 - val_loss: 0.1933 - val_accuracy: 0.9372\n",
      "Epoch 80/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1251 - accuracy: 0.9545 - val_loss: 0.1875 - val_accuracy: 0.9364\n",
      "Epoch 81/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1275 - accuracy: 0.9530 - val_loss: 0.1816 - val_accuracy: 0.9408\n",
      "Epoch 82/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1271 - accuracy: 0.9504 - val_loss: 0.1847 - val_accuracy: 0.9386\n",
      "Epoch 83/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1202 - accuracy: 0.9553 - val_loss: 0.1861 - val_accuracy: 0.9301\n",
      "Epoch 84/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1247 - accuracy: 0.9488 - val_loss: 0.1780 - val_accuracy: 0.9381\n",
      "Epoch 85/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1292 - accuracy: 0.9498 - val_loss: 0.1920 - val_accuracy: 0.9324\n",
      "Epoch 86/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1229 - accuracy: 0.9526 - val_loss: 0.1972 - val_accuracy: 0.9359\n",
      "Epoch 87/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1264 - accuracy: 0.9529 - val_loss: 0.1990 - val_accuracy: 0.9332\n",
      "Epoch 88/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1194 - accuracy: 0.9558 - val_loss: 0.1962 - val_accuracy: 0.9315\n",
      "Epoch 89/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1256 - accuracy: 0.9506 - val_loss: 0.1856 - val_accuracy: 0.9355\n",
      "Epoch 90/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1180 - accuracy: 0.9549 - val_loss: 0.2398 - val_accuracy: 0.9101\n",
      "Epoch 91/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1198 - accuracy: 0.9539 - val_loss: 0.1973 - val_accuracy: 0.9328\n",
      "Epoch 92/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1164 - accuracy: 0.9547 - val_loss: 0.1822 - val_accuracy: 0.9337\n",
      "Epoch 93/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1167 - accuracy: 0.9553 - val_loss: 0.1829 - val_accuracy: 0.9390\n",
      "Epoch 94/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1145 - accuracy: 0.9567 - val_loss: 0.2342 - val_accuracy: 0.9123\n",
      "Epoch 95/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1167 - accuracy: 0.9562 - val_loss: 0.2368 - val_accuracy: 0.9168\n",
      "Epoch 96/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1199 - accuracy: 0.9549 - val_loss: 0.1956 - val_accuracy: 0.9359\n",
      "Epoch 97/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1230 - accuracy: 0.9519 - val_loss: 0.1919 - val_accuracy: 0.9346\n",
      "Epoch 98/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1181 - accuracy: 0.9543 - val_loss: 0.1849 - val_accuracy: 0.9413\n",
      "Epoch 99/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1112 - accuracy: 0.9577 - val_loss: 0.1819 - val_accuracy: 0.9377\n",
      "Epoch 100/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1135 - accuracy: 0.9555 - val_loss: 0.2140 - val_accuracy: 0.9301\n",
      "Epoch 101/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1110 - accuracy: 0.9575 - val_loss: 0.2746 - val_accuracy: 0.8985\n",
      "Epoch 102/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1137 - accuracy: 0.9559 - val_loss: 0.2515 - val_accuracy: 0.9105\n",
      "Epoch 103/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.1077 - accuracy: 0.9586 - val_loss: 0.1822 - val_accuracy: 0.9390\n",
      "Epoch 104/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1108 - accuracy: 0.9582 - val_loss: 0.1871 - val_accuracy: 0.9364\n",
      "Epoch 105/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1086 - accuracy: 0.9586 - val_loss: 0.2040 - val_accuracy: 0.9257\n",
      "Epoch 106/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1107 - accuracy: 0.9572 - val_loss: 0.1904 - val_accuracy: 0.9341\n",
      "Epoch 107/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1054 - accuracy: 0.9609 - val_loss: 0.1795 - val_accuracy: 0.9417\n",
      "Epoch 108/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1057 - accuracy: 0.9589 - val_loss: 0.2177 - val_accuracy: 0.9226\n",
      "Epoch 109/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1082 - accuracy: 0.9586 - val_loss: 0.2068 - val_accuracy: 0.9315\n",
      "Epoch 110/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1057 - accuracy: 0.9594 - val_loss: 0.1817 - val_accuracy: 0.9377\n",
      "Epoch 111/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1065 - accuracy: 0.9605 - val_loss: 0.1748 - val_accuracy: 0.9395\n",
      "Epoch 112/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1036 - accuracy: 0.9597 - val_loss: 0.1938 - val_accuracy: 0.9355\n",
      "Epoch 113/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1093 - accuracy: 0.9576 - val_loss: 0.1761 - val_accuracy: 0.9404\n",
      "Epoch 114/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1108 - accuracy: 0.9576 - val_loss: 0.3161 - val_accuracy: 0.9083\n",
      "Epoch 115/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1043 - accuracy: 0.9604 - val_loss: 0.1994 - val_accuracy: 0.9324\n",
      "Epoch 116/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1096 - accuracy: 0.9565 - val_loss: 0.1974 - val_accuracy: 0.9364\n",
      "Epoch 117/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0977 - accuracy: 0.9636 - val_loss: 0.2106 - val_accuracy: 0.9297\n",
      "Epoch 118/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1123 - accuracy: 0.9572 - val_loss: 0.1984 - val_accuracy: 0.9372\n",
      "Epoch 119/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1036 - accuracy: 0.9605 - val_loss: 0.2287 - val_accuracy: 0.9315\n",
      "Epoch 120/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1052 - accuracy: 0.9594 - val_loss: 0.1827 - val_accuracy: 0.9404\n",
      "Epoch 121/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1045 - accuracy: 0.9611 - val_loss: 0.2148 - val_accuracy: 0.9292\n",
      "Epoch 122/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0993 - accuracy: 0.9636 - val_loss: 0.1769 - val_accuracy: 0.9448\n",
      "Epoch 123/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1000 - accuracy: 0.9608 - val_loss: 0.1768 - val_accuracy: 0.9399\n",
      "Epoch 124/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1090 - accuracy: 0.9579 - val_loss: 0.1925 - val_accuracy: 0.9372\n",
      "Epoch 125/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1051 - accuracy: 0.9572 - val_loss: 0.1756 - val_accuracy: 0.9350\n",
      "Epoch 126/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0981 - accuracy: 0.9616 - val_loss: 0.1845 - val_accuracy: 0.9404\n",
      "Epoch 127/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1018 - accuracy: 0.9612 - val_loss: 0.1784 - val_accuracy: 0.9457\n",
      "Epoch 128/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0992 - accuracy: 0.9618 - val_loss: 0.1766 - val_accuracy: 0.9426\n",
      "Epoch 129/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0999 - accuracy: 0.9629 - val_loss: 0.2211 - val_accuracy: 0.9346\n",
      "Epoch 130/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0946 - accuracy: 0.9636 - val_loss: 0.1851 - val_accuracy: 0.9439\n",
      "Epoch 131/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0992 - accuracy: 0.9599 - val_loss: 0.1826 - val_accuracy: 0.9364\n",
      "Epoch 132/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0955 - accuracy: 0.9628 - val_loss: 0.1857 - val_accuracy: 0.9350\n",
      "Epoch 133/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0973 - accuracy: 0.9638 - val_loss: 0.1815 - val_accuracy: 0.9430\n",
      "Epoch 134/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0940 - accuracy: 0.9641 - val_loss: 0.1942 - val_accuracy: 0.9368\n",
      "Epoch 135/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0961 - accuracy: 0.9633 - val_loss: 0.2170 - val_accuracy: 0.9324\n",
      "Epoch 136/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1019 - accuracy: 0.9611 - val_loss: 0.1827 - val_accuracy: 0.9421\n",
      "Epoch 137/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0928 - accuracy: 0.9616 - val_loss: 0.2072 - val_accuracy: 0.9368\n",
      "Epoch 138/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0912 - accuracy: 0.9652 - val_loss: 0.1981 - val_accuracy: 0.9355\n",
      "Epoch 139/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1030 - accuracy: 0.9614 - val_loss: 0.1788 - val_accuracy: 0.9390\n",
      "Epoch 140/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0973 - accuracy: 0.9621 - val_loss: 0.1947 - val_accuracy: 0.9341\n",
      "Epoch 141/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0945 - accuracy: 0.9616 - val_loss: 0.1981 - val_accuracy: 0.9346\n",
      "Epoch 142/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0929 - accuracy: 0.9654 - val_loss: 0.1873 - val_accuracy: 0.9372\n",
      "Epoch 143/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0950 - accuracy: 0.9629 - val_loss: 0.1852 - val_accuracy: 0.9430\n",
      "Epoch 144/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0924 - accuracy: 0.9641 - val_loss: 0.1809 - val_accuracy: 0.9404\n",
      "Epoch 145/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0931 - accuracy: 0.9637 - val_loss: 0.1804 - val_accuracy: 0.9413\n",
      "Epoch 146/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0945 - accuracy: 0.9629 - val_loss: 0.1917 - val_accuracy: 0.9350\n",
      "Epoch 147/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0925 - accuracy: 0.9644 - val_loss: 0.1846 - val_accuracy: 0.9475\n",
      "Epoch 148/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0911 - accuracy: 0.9645 - val_loss: 0.1717 - val_accuracy: 0.9506\n",
      "Epoch 149/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0877 - accuracy: 0.9663 - val_loss: 0.1971 - val_accuracy: 0.9346\n",
      "Epoch 150/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0897 - accuracy: 0.9644 - val_loss: 0.1873 - val_accuracy: 0.9399\n",
      "Epoch 151/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0913 - accuracy: 0.9643 - val_loss: 0.2236 - val_accuracy: 0.9359\n",
      "Epoch 152/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0878 - accuracy: 0.9673 - val_loss: 0.2103 - val_accuracy: 0.9319\n",
      "Epoch 153/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0906 - accuracy: 0.9627 - val_loss: 0.1908 - val_accuracy: 0.9426\n",
      "Epoch 154/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1019 - accuracy: 0.9616 - val_loss: 0.1833 - val_accuracy: 0.9439\n",
      "Epoch 155/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0878 - accuracy: 0.9654 - val_loss: 0.1899 - val_accuracy: 0.9399\n",
      "Epoch 156/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0868 - accuracy: 0.9657 - val_loss: 0.1762 - val_accuracy: 0.9453\n",
      "Epoch 157/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0814 - accuracy: 0.9696 - val_loss: 0.1821 - val_accuracy: 0.9426\n",
      "Epoch 158/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0917 - accuracy: 0.9632 - val_loss: 0.1828 - val_accuracy: 0.9426\n",
      "Epoch 159/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0936 - accuracy: 0.9637 - val_loss: 0.1815 - val_accuracy: 0.9448\n",
      "Epoch 160/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0858 - accuracy: 0.9659 - val_loss: 0.2938 - val_accuracy: 0.9088\n",
      "Epoch 161/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0880 - accuracy: 0.9657 - val_loss: 0.2036 - val_accuracy: 0.9337\n",
      "Epoch 162/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0974 - accuracy: 0.9615 - val_loss: 0.2063 - val_accuracy: 0.9381\n",
      "Epoch 163/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0825 - accuracy: 0.9674 - val_loss: 0.2116 - val_accuracy: 0.9355\n",
      "Epoch 164/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0896 - accuracy: 0.9647 - val_loss: 0.1923 - val_accuracy: 0.9439\n",
      "Epoch 165/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0822 - accuracy: 0.9686 - val_loss: 0.1839 - val_accuracy: 0.9417\n",
      "Epoch 166/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0854 - accuracy: 0.9654 - val_loss: 0.2462 - val_accuracy: 0.9315\n",
      "Epoch 167/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0895 - accuracy: 0.9647 - val_loss: 0.1661 - val_accuracy: 0.9475\n",
      "Epoch 168/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0871 - accuracy: 0.9664 - val_loss: 0.2280 - val_accuracy: 0.9212\n",
      "Epoch 169/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0898 - accuracy: 0.9656 - val_loss: 0.2015 - val_accuracy: 0.9417\n",
      "Epoch 170/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0921 - accuracy: 0.9643 - val_loss: 0.1776 - val_accuracy: 0.9426\n",
      "Epoch 171/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0836 - accuracy: 0.9676 - val_loss: 0.2041 - val_accuracy: 0.9421\n",
      "Epoch 172/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0833 - accuracy: 0.9678 - val_loss: 0.1874 - val_accuracy: 0.9408\n",
      "Epoch 173/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0876 - accuracy: 0.9668 - val_loss: 0.1941 - val_accuracy: 0.9426\n",
      "Epoch 174/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0811 - accuracy: 0.9712 - val_loss: 0.1759 - val_accuracy: 0.9488\n",
      "Epoch 175/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0902 - accuracy: 0.9659 - val_loss: 0.2166 - val_accuracy: 0.9332\n",
      "Epoch 176/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0844 - accuracy: 0.9673 - val_loss: 0.1904 - val_accuracy: 0.9462\n",
      "Epoch 177/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0842 - accuracy: 0.9677 - val_loss: 0.1872 - val_accuracy: 0.9426\n",
      "Epoch 178/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0804 - accuracy: 0.9697 - val_loss: 0.1817 - val_accuracy: 0.9426\n",
      "Epoch 179/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0828 - accuracy: 0.9682 - val_loss: 0.2384 - val_accuracy: 0.9230\n",
      "Epoch 180/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0945 - accuracy: 0.9648 - val_loss: 0.1692 - val_accuracy: 0.9484\n",
      "Epoch 181/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0808 - accuracy: 0.9683 - val_loss: 0.1771 - val_accuracy: 0.9417\n",
      "Epoch 182/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0852 - accuracy: 0.9691 - val_loss: 0.2654 - val_accuracy: 0.9146\n",
      "Epoch 183/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0879 - accuracy: 0.9644 - val_loss: 0.2141 - val_accuracy: 0.9337\n",
      "Epoch 184/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0851 - accuracy: 0.9667 - val_loss: 0.2259 - val_accuracy: 0.9315\n",
      "Epoch 185/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0812 - accuracy: 0.9688 - val_loss: 0.1847 - val_accuracy: 0.9399\n",
      "Epoch 186/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0857 - accuracy: 0.9655 - val_loss: 0.2010 - val_accuracy: 0.9404\n",
      "Epoch 187/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0893 - accuracy: 0.9674 - val_loss: 0.1779 - val_accuracy: 0.9421\n",
      "Epoch 188/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0811 - accuracy: 0.9682 - val_loss: 0.1940 - val_accuracy: 0.9404\n",
      "Epoch 189/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0799 - accuracy: 0.9690 - val_loss: 0.2002 - val_accuracy: 0.9404\n",
      "Epoch 190/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0786 - accuracy: 0.9688 - val_loss: 0.1915 - val_accuracy: 0.9421\n",
      "Epoch 191/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0879 - accuracy: 0.9672 - val_loss: 0.1902 - val_accuracy: 0.9462\n",
      "Epoch 192/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0796 - accuracy: 0.9690 - val_loss: 0.1925 - val_accuracy: 0.9417\n",
      "Epoch 193/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0803 - accuracy: 0.9684 - val_loss: 0.1715 - val_accuracy: 0.9462\n",
      "Epoch 194/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0809 - accuracy: 0.9682 - val_loss: 0.1967 - val_accuracy: 0.9395\n",
      "Epoch 195/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0837 - accuracy: 0.9674 - val_loss: 0.1929 - val_accuracy: 0.9421\n",
      "Epoch 196/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0887 - accuracy: 0.9682 - val_loss: 0.1889 - val_accuracy: 0.9462\n",
      "Epoch 197/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0724 - accuracy: 0.9735 - val_loss: 0.1911 - val_accuracy: 0.9430\n",
      "Epoch 198/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0835 - accuracy: 0.9684 - val_loss: 0.1728 - val_accuracy: 0.9395\n",
      "Epoch 199/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0769 - accuracy: 0.9710 - val_loss: 0.1913 - val_accuracy: 0.9453\n",
      "Epoch 200/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0787 - accuracy: 0.9706 - val_loss: 0.2246 - val_accuracy: 0.9439\n",
      "Epoch 201/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0896 - accuracy: 0.9665 - val_loss: 0.2152 - val_accuracy: 0.9359\n",
      "Epoch 202/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0806 - accuracy: 0.9691 - val_loss: 0.2158 - val_accuracy: 0.9355\n",
      "Epoch 203/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0763 - accuracy: 0.9723 - val_loss: 0.2077 - val_accuracy: 0.9448\n",
      "Epoch 204/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0765 - accuracy: 0.9701 - val_loss: 0.1693 - val_accuracy: 0.9479\n",
      "Epoch 205/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0834 - accuracy: 0.9674 - val_loss: 0.1840 - val_accuracy: 0.9462\n",
      "Epoch 206/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0787 - accuracy: 0.9684 - val_loss: 0.1871 - val_accuracy: 0.9475\n",
      "Epoch 207/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0743 - accuracy: 0.9721 - val_loss: 0.1948 - val_accuracy: 0.9475\n",
      "Epoch 208/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0797 - accuracy: 0.9694 - val_loss: 0.1890 - val_accuracy: 0.9475\n",
      "Epoch 209/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0814 - accuracy: 0.9672 - val_loss: 0.1996 - val_accuracy: 0.9399\n",
      "Epoch 210/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0821 - accuracy: 0.9695 - val_loss: 0.1809 - val_accuracy: 0.9462\n",
      "Epoch 211/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0761 - accuracy: 0.9714 - val_loss: 0.2168 - val_accuracy: 0.9372\n",
      "Epoch 212/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0823 - accuracy: 0.9690 - val_loss: 0.2135 - val_accuracy: 0.9390\n",
      "Epoch 213/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0805 - accuracy: 0.9686 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
      "Epoch 214/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0802 - accuracy: 0.9700 - val_loss: 0.2103 - val_accuracy: 0.9430\n",
      "Epoch 215/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0741 - accuracy: 0.9704 - val_loss: 0.1737 - val_accuracy: 0.9448\n",
      "Epoch 216/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0756 - accuracy: 0.9698 - val_loss: 0.2133 - val_accuracy: 0.9381\n",
      "Epoch 217/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0786 - accuracy: 0.9687 - val_loss: 0.1984 - val_accuracy: 0.9395\n",
      "Epoch 218/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0790 - accuracy: 0.9669 - val_loss: 0.2028 - val_accuracy: 0.9439\n",
      "Epoch 219/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0775 - accuracy: 0.9712 - val_loss: 0.2272 - val_accuracy: 0.9328\n",
      "Epoch 220/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0724 - accuracy: 0.9723 - val_loss: 0.1943 - val_accuracy: 0.9404\n",
      "Epoch 221/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0839 - accuracy: 0.9686 - val_loss: 0.1752 - val_accuracy: 0.9462\n",
      "Epoch 222/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0672 - accuracy: 0.9743 - val_loss: 0.1866 - val_accuracy: 0.9488\n",
      "Epoch 223/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0775 - accuracy: 0.9696 - val_loss: 0.2483 - val_accuracy: 0.9261\n",
      "Epoch 224/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0826 - accuracy: 0.9688 - val_loss: 0.1923 - val_accuracy: 0.9453\n",
      "Epoch 225/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0720 - accuracy: 0.9741 - val_loss: 0.1725 - val_accuracy: 0.9484\n",
      "Epoch 226/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0741 - accuracy: 0.9707 - val_loss: 0.1825 - val_accuracy: 0.9457\n",
      "Epoch 227/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0738 - accuracy: 0.9736 - val_loss: 0.1787 - val_accuracy: 0.9430\n",
      "Epoch 228/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0731 - accuracy: 0.9721 - val_loss: 0.2357 - val_accuracy: 0.9288\n",
      "Epoch 229/500\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.0744 - accuracy: 0.9715 - val_loss: 0.1865 - val_accuracy: 0.9457\n",
      "Epoch 230/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0741 - accuracy: 0.9702 - val_loss: 0.2077 - val_accuracy: 0.9381\n",
      "Epoch 231/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0688 - accuracy: 0.9736 - val_loss: 0.1810 - val_accuracy: 0.9479\n",
      "Epoch 232/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0739 - accuracy: 0.9708 - val_loss: 0.1908 - val_accuracy: 0.9390\n",
      "Epoch 233/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0752 - accuracy: 0.9707 - val_loss: 0.2237 - val_accuracy: 0.9292\n",
      "Epoch 234/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0761 - accuracy: 0.9707 - val_loss: 0.1967 - val_accuracy: 0.9439\n",
      "Epoch 235/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0669 - accuracy: 0.9737 - val_loss: 0.1910 - val_accuracy: 0.9497\n",
      "Epoch 236/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0728 - accuracy: 0.9724 - val_loss: 0.1792 - val_accuracy: 0.9524\n",
      "Epoch 237/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0724 - accuracy: 0.9720 - val_loss: 0.1820 - val_accuracy: 0.9510\n",
      "Epoch 238/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0696 - accuracy: 0.9721 - val_loss: 0.2369 - val_accuracy: 0.9212\n",
      "Epoch 239/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0704 - accuracy: 0.9733 - val_loss: 0.2119 - val_accuracy: 0.9381\n",
      "Epoch 240/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0764 - accuracy: 0.9712 - val_loss: 0.2169 - val_accuracy: 0.9364\n",
      "Epoch 241/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0719 - accuracy: 0.9723 - val_loss: 0.1813 - val_accuracy: 0.9484\n",
      "Epoch 242/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0688 - accuracy: 0.9736 - val_loss: 0.1890 - val_accuracy: 0.9421\n",
      "Epoch 243/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0698 - accuracy: 0.9736 - val_loss: 0.1944 - val_accuracy: 0.9462\n",
      "Epoch 244/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0761 - accuracy: 0.9704 - val_loss: 0.2002 - val_accuracy: 0.9453\n",
      "Epoch 245/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0720 - accuracy: 0.9721 - val_loss: 0.2146 - val_accuracy: 0.9413\n",
      "Epoch 246/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0674 - accuracy: 0.9731 - val_loss: 0.1976 - val_accuracy: 0.9453\n",
      "Epoch 247/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0752 - accuracy: 0.9702 - val_loss: 0.2001 - val_accuracy: 0.9542\n",
      "Epoch 248/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0709 - accuracy: 0.9725 - val_loss: 0.1819 - val_accuracy: 0.9470\n",
      "Epoch 249/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0656 - accuracy: 0.9761 - val_loss: 0.1905 - val_accuracy: 0.9466\n",
      "Epoch 250/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0726 - accuracy: 0.9715 - val_loss: 0.2189 - val_accuracy: 0.9453\n",
      "Epoch 251/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0682 - accuracy: 0.9746 - val_loss: 0.1819 - val_accuracy: 0.9537\n",
      "Epoch 252/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0723 - accuracy: 0.9716 - val_loss: 0.1919 - val_accuracy: 0.9444\n",
      "Epoch 253/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0794 - accuracy: 0.9707 - val_loss: 0.1875 - val_accuracy: 0.9497\n",
      "Epoch 254/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0662 - accuracy: 0.9741 - val_loss: 0.2096 - val_accuracy: 0.9421\n",
      "Epoch 255/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0710 - accuracy: 0.9726 - val_loss: 0.2477 - val_accuracy: 0.9381\n",
      "Epoch 256/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0725 - accuracy: 0.9727 - val_loss: 0.1798 - val_accuracy: 0.9502\n",
      "Epoch 257/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0711 - accuracy: 0.9747 - val_loss: 0.1955 - val_accuracy: 0.9502\n",
      "Epoch 258/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0643 - accuracy: 0.9772 - val_loss: 0.2135 - val_accuracy: 0.9399\n",
      "Epoch 259/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0685 - accuracy: 0.9721 - val_loss: 0.2020 - val_accuracy: 0.9444\n",
      "Epoch 260/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0684 - accuracy: 0.9748 - val_loss: 0.2037 - val_accuracy: 0.9435\n",
      "Epoch 261/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0661 - accuracy: 0.9741 - val_loss: 0.2104 - val_accuracy: 0.9475\n",
      "Epoch 262/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0706 - accuracy: 0.9727 - val_loss: 0.1748 - val_accuracy: 0.9510\n",
      "Epoch 263/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0714 - accuracy: 0.9715 - val_loss: 0.2184 - val_accuracy: 0.9448\n",
      "Epoch 264/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0687 - accuracy: 0.9744 - val_loss: 0.1855 - val_accuracy: 0.9484\n",
      "Epoch 265/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0686 - accuracy: 0.9724 - val_loss: 0.1943 - val_accuracy: 0.9457\n",
      "Epoch 266/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0734 - accuracy: 0.9741 - val_loss: 0.1939 - val_accuracy: 0.9493\n",
      "Epoch 267/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0619 - accuracy: 0.9769 - val_loss: 0.1968 - val_accuracy: 0.9408\n",
      "Epoch 268/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0704 - accuracy: 0.9725 - val_loss: 0.1966 - val_accuracy: 0.9435\n",
      "Epoch 269/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0736 - accuracy: 0.9723 - val_loss: 0.2072 - val_accuracy: 0.9439\n",
      "Epoch 270/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0632 - accuracy: 0.9754 - val_loss: 0.2081 - val_accuracy: 0.9475\n",
      "Epoch 271/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0681 - accuracy: 0.9732 - val_loss: 0.2092 - val_accuracy: 0.9426\n",
      "Epoch 272/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0782 - accuracy: 0.9707 - val_loss: 0.2295 - val_accuracy: 0.9390\n",
      "Epoch 273/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0695 - accuracy: 0.9734 - val_loss: 0.1940 - val_accuracy: 0.9448\n",
      "Epoch 274/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0669 - accuracy: 0.9743 - val_loss: 0.1809 - val_accuracy: 0.9475\n",
      "Epoch 275/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0641 - accuracy: 0.9743 - val_loss: 0.2108 - val_accuracy: 0.9395\n",
      "Epoch 276/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0722 - accuracy: 0.9721 - val_loss: 0.1819 - val_accuracy: 0.9510\n",
      "Epoch 277/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0705 - accuracy: 0.9728 - val_loss: 0.1998 - val_accuracy: 0.9506\n",
      "Epoch 278/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0643 - accuracy: 0.9736 - val_loss: 0.2063 - val_accuracy: 0.9453\n",
      "Epoch 279/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0634 - accuracy: 0.9751 - val_loss: 0.2604 - val_accuracy: 0.9341\n",
      "Epoch 280/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0647 - accuracy: 0.9770 - val_loss: 0.2006 - val_accuracy: 0.9470\n",
      "Epoch 281/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0618 - accuracy: 0.9766 - val_loss: 0.2182 - val_accuracy: 0.9528\n",
      "Epoch 282/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0655 - accuracy: 0.9733 - val_loss: 0.2224 - val_accuracy: 0.9453\n",
      "Epoch 283/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0627 - accuracy: 0.9755 - val_loss: 0.1928 - val_accuracy: 0.9462\n",
      "Epoch 284/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0762 - accuracy: 0.9735 - val_loss: 0.2274 - val_accuracy: 0.9439\n",
      "Epoch 285/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0625 - accuracy: 0.9755 - val_loss: 0.1776 - val_accuracy: 0.9537\n",
      "Epoch 286/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0699 - accuracy: 0.9726 - val_loss: 0.1917 - val_accuracy: 0.9497\n",
      "Epoch 287/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0675 - accuracy: 0.9741 - val_loss: 0.1981 - val_accuracy: 0.9462\n",
      "Epoch 288/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0774 - accuracy: 0.9697 - val_loss: 0.2022 - val_accuracy: 0.9421\n",
      "Epoch 289/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0647 - accuracy: 0.9769 - val_loss: 0.2126 - val_accuracy: 0.9404\n",
      "Epoch 290/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0740 - accuracy: 0.9724 - val_loss: 0.2211 - val_accuracy: 0.9408\n",
      "Epoch 291/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0626 - accuracy: 0.9743 - val_loss: 0.2155 - val_accuracy: 0.9430\n",
      "Epoch 292/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0592 - accuracy: 0.9760 - val_loss: 0.1909 - val_accuracy: 0.9457\n",
      "Epoch 293/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0626 - accuracy: 0.9776 - val_loss: 0.2799 - val_accuracy: 0.9288\n",
      "Epoch 294/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0709 - accuracy: 0.9728 - val_loss: 0.2075 - val_accuracy: 0.9426\n",
      "Epoch 295/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0661 - accuracy: 0.9751 - val_loss: 0.2485 - val_accuracy: 0.9417\n",
      "Epoch 296/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0641 - accuracy: 0.9753 - val_loss: 0.2069 - val_accuracy: 0.9479\n",
      "Epoch 297/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0718 - accuracy: 0.9726 - val_loss: 0.2312 - val_accuracy: 0.9399\n",
      "Epoch 298/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0604 - accuracy: 0.9773 - val_loss: 0.1919 - val_accuracy: 0.9479\n",
      "Epoch 299/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0607 - accuracy: 0.9776 - val_loss: 0.2110 - val_accuracy: 0.9457\n",
      "Epoch 300/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0709 - accuracy: 0.9738 - val_loss: 0.2142 - val_accuracy: 0.9404\n",
      "Epoch 301/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0630 - accuracy: 0.9744 - val_loss: 0.2011 - val_accuracy: 0.9484\n",
      "Epoch 302/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0651 - accuracy: 0.9747 - val_loss: 0.1952 - val_accuracy: 0.9413\n",
      "Epoch 303/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0616 - accuracy: 0.9765 - val_loss: 0.1906 - val_accuracy: 0.9497\n",
      "Epoch 304/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0675 - accuracy: 0.9740 - val_loss: 0.1989 - val_accuracy: 0.9453\n",
      "Epoch 305/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0684 - accuracy: 0.9740 - val_loss: 0.2262 - val_accuracy: 0.9439\n",
      "Epoch 306/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0637 - accuracy: 0.9752 - val_loss: 0.2145 - val_accuracy: 0.9457\n",
      "Epoch 307/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0640 - accuracy: 0.9746 - val_loss: 0.2010 - val_accuracy: 0.9546\n",
      "Epoch 308/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0654 - accuracy: 0.9732 - val_loss: 0.1710 - val_accuracy: 0.9502\n",
      "Epoch 309/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0683 - accuracy: 0.9733 - val_loss: 0.2113 - val_accuracy: 0.9444\n",
      "Epoch 310/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0646 - accuracy: 0.9727 - val_loss: 0.2008 - val_accuracy: 0.9510\n",
      "Epoch 311/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0598 - accuracy: 0.9779 - val_loss: 0.1818 - val_accuracy: 0.9582\n",
      "Epoch 312/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0673 - accuracy: 0.9742 - val_loss: 0.1873 - val_accuracy: 0.9479\n",
      "Epoch 313/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0628 - accuracy: 0.9759 - val_loss: 0.1948 - val_accuracy: 0.9519\n",
      "Epoch 314/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0622 - accuracy: 0.9769 - val_loss: 0.2172 - val_accuracy: 0.9479\n",
      "Epoch 315/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0674 - accuracy: 0.9738 - val_loss: 0.1911 - val_accuracy: 0.9528\n",
      "Epoch 316/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0640 - accuracy: 0.9756 - val_loss: 0.2059 - val_accuracy: 0.9453\n",
      "Epoch 317/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0578 - accuracy: 0.9770 - val_loss: 0.2033 - val_accuracy: 0.9462\n",
      "Epoch 318/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0616 - accuracy: 0.9771 - val_loss: 0.1934 - val_accuracy: 0.9493\n",
      "Epoch 319/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0561 - accuracy: 0.9785 - val_loss: 0.2190 - val_accuracy: 0.9444\n",
      "Epoch 320/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0593 - accuracy: 0.9779 - val_loss: 0.2304 - val_accuracy: 0.9430\n",
      "Epoch 321/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0686 - accuracy: 0.9754 - val_loss: 0.2075 - val_accuracy: 0.9466\n",
      "Epoch 322/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0663 - accuracy: 0.9748 - val_loss: 0.2043 - val_accuracy: 0.9502\n",
      "Epoch 323/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0657 - accuracy: 0.9722 - val_loss: 0.2056 - val_accuracy: 0.9479\n",
      "Epoch 324/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0646 - accuracy: 0.9764 - val_loss: 0.2224 - val_accuracy: 0.9475\n",
      "Epoch 325/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0550 - accuracy: 0.9773 - val_loss: 0.2279 - val_accuracy: 0.9448\n",
      "Epoch 326/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0667 - accuracy: 0.9756 - val_loss: 0.2176 - val_accuracy: 0.9377\n",
      "Epoch 327/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0622 - accuracy: 0.9770 - val_loss: 0.3502 - val_accuracy: 0.9203\n",
      "Epoch 328/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0572 - accuracy: 0.9776 - val_loss: 0.1850 - val_accuracy: 0.9475\n",
      "Epoch 329/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0641 - accuracy: 0.9752 - val_loss: 0.1899 - val_accuracy: 0.9524\n",
      "Epoch 330/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0643 - accuracy: 0.9750 - val_loss: 0.2119 - val_accuracy: 0.9399\n",
      "Epoch 331/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0582 - accuracy: 0.9784 - val_loss: 0.1931 - val_accuracy: 0.9524\n",
      "Epoch 332/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0659 - accuracy: 0.9750 - val_loss: 0.2000 - val_accuracy: 0.9546\n",
      "Epoch 333/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0597 - accuracy: 0.9785 - val_loss: 0.1879 - val_accuracy: 0.9546\n",
      "Epoch 334/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0612 - accuracy: 0.9748 - val_loss: 0.2194 - val_accuracy: 0.9462\n",
      "Epoch 335/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0570 - accuracy: 0.9766 - val_loss: 0.1749 - val_accuracy: 0.9582\n",
      "Epoch 336/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0563 - accuracy: 0.9791 - val_loss: 0.1854 - val_accuracy: 0.9555\n",
      "Epoch 337/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0681 - accuracy: 0.9742 - val_loss: 0.2130 - val_accuracy: 0.9417\n",
      "Epoch 338/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0593 - accuracy: 0.9754 - val_loss: 0.1964 - val_accuracy: 0.9475\n",
      "Epoch 339/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0574 - accuracy: 0.9779 - val_loss: 0.1985 - val_accuracy: 0.9497\n",
      "Epoch 340/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0658 - accuracy: 0.9746 - val_loss: 0.2169 - val_accuracy: 0.9453\n",
      "Epoch 341/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0563 - accuracy: 0.9776 - val_loss: 0.1859 - val_accuracy: 0.9533\n",
      "Epoch 342/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0633 - accuracy: 0.9759 - val_loss: 0.1933 - val_accuracy: 0.9591\n",
      "Epoch 343/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0693 - accuracy: 0.9751 - val_loss: 0.1947 - val_accuracy: 0.9524\n",
      "Epoch 344/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0563 - accuracy: 0.9784 - val_loss: 0.1885 - val_accuracy: 0.9537\n",
      "Epoch 345/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0573 - accuracy: 0.9785 - val_loss: 0.2233 - val_accuracy: 0.9355\n",
      "Epoch 346/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0593 - accuracy: 0.9773 - val_loss: 0.1825 - val_accuracy: 0.9564\n",
      "Epoch 347/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0675 - accuracy: 0.9741 - val_loss: 0.1859 - val_accuracy: 0.9542\n",
      "Epoch 348/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0577 - accuracy: 0.9772 - val_loss: 0.2565 - val_accuracy: 0.9381\n",
      "Epoch 349/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0596 - accuracy: 0.9776 - val_loss: 0.2219 - val_accuracy: 0.9444\n",
      "Epoch 350/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0586 - accuracy: 0.9786 - val_loss: 0.2121 - val_accuracy: 0.9493\n",
      "Epoch 351/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0598 - accuracy: 0.9759 - val_loss: 0.1959 - val_accuracy: 0.9493\n",
      "Epoch 352/500\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.0603 - accuracy: 0.9769 - val_loss: 0.1974 - val_accuracy: 0.9568\n",
      "Epoch 353/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0597 - accuracy: 0.9773 - val_loss: 0.2622 - val_accuracy: 0.9448\n",
      "Epoch 354/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0588 - accuracy: 0.9760 - val_loss: 0.2128 - val_accuracy: 0.9466\n",
      "Epoch 355/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0757 - accuracy: 0.9730 - val_loss: 0.1852 - val_accuracy: 0.9497\n",
      "Epoch 356/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0530 - accuracy: 0.9802 - val_loss: 0.2047 - val_accuracy: 0.9466\n",
      "Epoch 357/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0613 - accuracy: 0.9759 - val_loss: 0.2067 - val_accuracy: 0.9519\n",
      "Epoch 358/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0607 - accuracy: 0.9763 - val_loss: 0.2001 - val_accuracy: 0.9519\n",
      "Epoch 359/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0627 - accuracy: 0.9769 - val_loss: 0.1887 - val_accuracy: 0.9510\n",
      "Epoch 360/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0532 - accuracy: 0.9793 - val_loss: 0.1956 - val_accuracy: 0.9497\n",
      "Epoch 361/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0586 - accuracy: 0.9754 - val_loss: 0.2218 - val_accuracy: 0.9435\n",
      "Epoch 362/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0636 - accuracy: 0.9754 - val_loss: 0.2478 - val_accuracy: 0.9413\n",
      "Epoch 363/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0544 - accuracy: 0.9793 - val_loss: 0.2485 - val_accuracy: 0.9341\n",
      "Epoch 364/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0557 - accuracy: 0.9780 - val_loss: 0.2486 - val_accuracy: 0.9426\n",
      "Epoch 365/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0575 - accuracy: 0.9766 - val_loss: 0.3818 - val_accuracy: 0.9239\n",
      "Epoch 366/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0616 - accuracy: 0.9762 - val_loss: 0.2062 - val_accuracy: 0.9439\n",
      "Epoch 367/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0557 - accuracy: 0.9780 - val_loss: 0.2456 - val_accuracy: 0.9426\n",
      "Epoch 368/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0615 - accuracy: 0.9761 - val_loss: 0.1804 - val_accuracy: 0.9582\n",
      "Epoch 369/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0550 - accuracy: 0.9796 - val_loss: 0.1877 - val_accuracy: 0.9475\n",
      "Epoch 370/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0606 - accuracy: 0.9757 - val_loss: 0.2165 - val_accuracy: 0.9390\n",
      "Epoch 371/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0562 - accuracy: 0.9779 - val_loss: 0.2240 - val_accuracy: 0.9493\n",
      "Epoch 372/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0674 - accuracy: 0.9765 - val_loss: 0.2317 - val_accuracy: 0.9466\n",
      "Epoch 373/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0585 - accuracy: 0.9783 - val_loss: 0.2099 - val_accuracy: 0.9551\n",
      "Epoch 374/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0545 - accuracy: 0.9767 - val_loss: 0.2122 - val_accuracy: 0.9488\n",
      "Epoch 375/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.2143 - val_accuracy: 0.9515\n",
      "Epoch 376/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0640 - accuracy: 0.9769 - val_loss: 0.2006 - val_accuracy: 0.9537\n",
      "Epoch 377/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0474 - accuracy: 0.9809 - val_loss: 0.2685 - val_accuracy: 0.9444\n",
      "Epoch 378/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0576 - accuracy: 0.9774 - val_loss: 0.2293 - val_accuracy: 0.9479\n",
      "Epoch 379/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0614 - accuracy: 0.9767 - val_loss: 0.2144 - val_accuracy: 0.9475\n",
      "Epoch 380/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 0.1975 - val_accuracy: 0.9555\n",
      "Epoch 381/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0508 - accuracy: 0.9815 - val_loss: 0.1890 - val_accuracy: 0.9533\n",
      "Epoch 382/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0589 - accuracy: 0.9765 - val_loss: 0.1866 - val_accuracy: 0.9542\n",
      "Epoch 383/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0543 - accuracy: 0.9796 - val_loss: 0.2135 - val_accuracy: 0.9453\n",
      "Epoch 384/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0577 - accuracy: 0.9783 - val_loss: 0.2066 - val_accuracy: 0.9475\n",
      "Epoch 385/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0619 - accuracy: 0.9786 - val_loss: 0.1942 - val_accuracy: 0.9542\n",
      "Epoch 386/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0525 - accuracy: 0.9802 - val_loss: 0.2076 - val_accuracy: 0.9479\n",
      "Epoch 387/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0579 - accuracy: 0.9771 - val_loss: 0.1968 - val_accuracy: 0.9582\n",
      "Epoch 388/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0561 - accuracy: 0.9789 - val_loss: 0.1908 - val_accuracy: 0.9506\n",
      "Epoch 389/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0553 - accuracy: 0.9780 - val_loss: 0.2040 - val_accuracy: 0.9479\n",
      "Epoch 390/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0519 - accuracy: 0.9804 - val_loss: 0.1965 - val_accuracy: 0.9493\n",
      "Epoch 391/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0470 - accuracy: 0.9824 - val_loss: 0.1946 - val_accuracy: 0.9546\n",
      "Epoch 392/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0596 - accuracy: 0.9771 - val_loss: 0.1799 - val_accuracy: 0.9568\n",
      "Epoch 393/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0568 - accuracy: 0.9767 - val_loss: 0.1990 - val_accuracy: 0.9537\n",
      "Epoch 394/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0594 - accuracy: 0.9780 - val_loss: 0.2235 - val_accuracy: 0.9519\n",
      "Epoch 395/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0576 - accuracy: 0.9786 - val_loss: 0.2021 - val_accuracy: 0.9475\n",
      "Epoch 396/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0535 - accuracy: 0.9790 - val_loss: 0.2152 - val_accuracy: 0.9546\n",
      "Epoch 397/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0582 - accuracy: 0.9782 - val_loss: 0.1974 - val_accuracy: 0.9555\n",
      "Epoch 398/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0574 - accuracy: 0.9772 - val_loss: 0.3317 - val_accuracy: 0.9186\n",
      "Epoch 399/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0542 - accuracy: 0.9780 - val_loss: 0.1746 - val_accuracy: 0.9542\n",
      "Epoch 400/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0553 - accuracy: 0.9779 - val_loss: 0.2143 - val_accuracy: 0.9524\n",
      "Epoch 401/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0501 - accuracy: 0.9790 - val_loss: 0.2053 - val_accuracy: 0.9502\n",
      "Epoch 402/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0547 - accuracy: 0.9786 - val_loss: 0.2290 - val_accuracy: 0.9470\n",
      "Epoch 403/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.1879 - val_accuracy: 0.9559\n",
      "Epoch 404/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0490 - accuracy: 0.9797 - val_loss: 0.1999 - val_accuracy: 0.9475\n",
      "Epoch 405/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0532 - accuracy: 0.9793 - val_loss: 0.2123 - val_accuracy: 0.9506\n",
      "Epoch 406/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0533 - accuracy: 0.9785 - val_loss: 0.1992 - val_accuracy: 0.9555\n",
      "Epoch 407/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0580 - accuracy: 0.9791 - val_loss: 0.2321 - val_accuracy: 0.9519\n",
      "Epoch 408/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0627 - accuracy: 0.9780 - val_loss: 0.2078 - val_accuracy: 0.9493\n",
      "Epoch 409/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0503 - accuracy: 0.9794 - val_loss: 0.2018 - val_accuracy: 0.9510\n",
      "Epoch 410/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0592 - accuracy: 0.9776 - val_loss: 0.1932 - val_accuracy: 0.9564\n",
      "Epoch 411/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0482 - accuracy: 0.9811 - val_loss: 0.1848 - val_accuracy: 0.9564\n",
      "Epoch 412/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0535 - accuracy: 0.9791 - val_loss: 0.2398 - val_accuracy: 0.9417\n",
      "Epoch 413/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0609 - accuracy: 0.9754 - val_loss: 0.2154 - val_accuracy: 0.9502\n",
      "Epoch 414/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0524 - accuracy: 0.9790 - val_loss: 0.1996 - val_accuracy: 0.9533\n",
      "Epoch 415/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0556 - accuracy: 0.9784 - val_loss: 0.1937 - val_accuracy: 0.9528\n",
      "Epoch 416/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 0.1904 - val_accuracy: 0.9546\n",
      "Epoch 417/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0539 - accuracy: 0.9800 - val_loss: 0.2626 - val_accuracy: 0.9381\n",
      "Epoch 418/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0538 - accuracy: 0.9786 - val_loss: 0.2615 - val_accuracy: 0.9417\n",
      "Epoch 419/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0555 - accuracy: 0.9781 - val_loss: 0.2001 - val_accuracy: 0.9559\n",
      "Epoch 420/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0516 - accuracy: 0.9804 - val_loss: 0.2339 - val_accuracy: 0.9497\n",
      "Epoch 421/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0563 - accuracy: 0.9791 - val_loss: 0.2382 - val_accuracy: 0.9457\n",
      "Epoch 422/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0524 - accuracy: 0.9784 - val_loss: 0.2139 - val_accuracy: 0.9484\n",
      "Epoch 423/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0529 - accuracy: 0.9786 - val_loss: 0.1992 - val_accuracy: 0.9519\n",
      "Epoch 424/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0566 - accuracy: 0.9776 - val_loss: 0.2018 - val_accuracy: 0.9577\n",
      "Epoch 425/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.1977 - val_accuracy: 0.9537\n",
      "Epoch 426/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0534 - accuracy: 0.9779 - val_loss: 0.2461 - val_accuracy: 0.9346\n",
      "Epoch 427/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 0.2093 - val_accuracy: 0.9528\n",
      "Epoch 428/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0465 - accuracy: 0.9807 - val_loss: 0.2135 - val_accuracy: 0.9533\n",
      "Epoch 429/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0506 - accuracy: 0.9803 - val_loss: 0.2214 - val_accuracy: 0.9551\n",
      "Epoch 430/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0528 - accuracy: 0.9795 - val_loss: 0.2037 - val_accuracy: 0.9573\n",
      "Epoch 431/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0580 - accuracy: 0.9772 - val_loss: 0.2146 - val_accuracy: 0.9453\n",
      "Epoch 432/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0552 - accuracy: 0.9803 - val_loss: 0.2726 - val_accuracy: 0.9421\n",
      "Epoch 433/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0515 - accuracy: 0.9819 - val_loss: 0.2001 - val_accuracy: 0.9542\n",
      "Epoch 434/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0574 - accuracy: 0.9784 - val_loss: 0.2175 - val_accuracy: 0.9515\n",
      "Epoch 435/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0505 - accuracy: 0.9814 - val_loss: 0.2224 - val_accuracy: 0.9528\n",
      "Epoch 436/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0507 - accuracy: 0.9800 - val_loss: 0.1989 - val_accuracy: 0.9559\n",
      "Epoch 437/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0501 - accuracy: 0.9799 - val_loss: 0.2093 - val_accuracy: 0.9528\n",
      "Epoch 438/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0489 - accuracy: 0.9811 - val_loss: 0.2080 - val_accuracy: 0.9528\n",
      "Epoch 439/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0557 - accuracy: 0.9783 - val_loss: 0.2375 - val_accuracy: 0.9515\n",
      "Epoch 440/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0549 - accuracy: 0.9781 - val_loss: 0.2205 - val_accuracy: 0.9551\n",
      "Epoch 441/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0463 - accuracy: 0.9824 - val_loss: 0.1946 - val_accuracy: 0.9506\n",
      "Epoch 442/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0494 - accuracy: 0.9807 - val_loss: 0.2257 - val_accuracy: 0.9430\n",
      "Epoch 443/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0548 - accuracy: 0.9780 - val_loss: 0.1931 - val_accuracy: 0.9582\n",
      "Epoch 444/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0556 - accuracy: 0.9785 - val_loss: 0.1860 - val_accuracy: 0.9591\n",
      "Epoch 445/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0505 - accuracy: 0.9804 - val_loss: 0.1955 - val_accuracy: 0.9551\n",
      "Epoch 446/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0542 - accuracy: 0.9772 - val_loss: 0.2380 - val_accuracy: 0.9488\n",
      "Epoch 447/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0465 - accuracy: 0.9807 - val_loss: 0.2204 - val_accuracy: 0.9470\n",
      "Epoch 448/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0516 - accuracy: 0.9801 - val_loss: 0.1934 - val_accuracy: 0.9510\n",
      "Epoch 449/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0481 - accuracy: 0.9804 - val_loss: 0.2078 - val_accuracy: 0.9555\n",
      "Epoch 450/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0528 - accuracy: 0.9801 - val_loss: 0.2008 - val_accuracy: 0.9502\n",
      "Epoch 451/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0532 - accuracy: 0.9801 - val_loss: 0.2408 - val_accuracy: 0.9519\n",
      "Epoch 452/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0568 - accuracy: 0.9781 - val_loss: 0.2093 - val_accuracy: 0.9484\n",
      "Epoch 453/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0532 - accuracy: 0.9796 - val_loss: 0.1928 - val_accuracy: 0.9559\n",
      "Epoch 454/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0472 - accuracy: 0.9823 - val_loss: 0.2091 - val_accuracy: 0.9502\n",
      "Epoch 455/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0481 - accuracy: 0.9807 - val_loss: 0.2250 - val_accuracy: 0.9395\n",
      "Epoch 456/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0517 - accuracy: 0.9796 - val_loss: 0.2108 - val_accuracy: 0.9546\n",
      "Epoch 457/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0515 - accuracy: 0.9799 - val_loss: 0.1853 - val_accuracy: 0.9519\n",
      "Epoch 458/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0443 - accuracy: 0.9831 - val_loss: 0.2226 - val_accuracy: 0.9488\n",
      "Epoch 459/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0462 - accuracy: 0.9832 - val_loss: 0.2138 - val_accuracy: 0.9493\n",
      "Epoch 460/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0532 - accuracy: 0.9791 - val_loss: 0.2087 - val_accuracy: 0.9546\n",
      "Epoch 461/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.2061 - val_accuracy: 0.9524\n",
      "Epoch 462/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 0.2420 - val_accuracy: 0.9546\n",
      "Epoch 463/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0504 - accuracy: 0.9811 - val_loss: 0.2403 - val_accuracy: 0.9470\n",
      "Epoch 464/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0530 - accuracy: 0.9802 - val_loss: 0.2057 - val_accuracy: 0.9568\n",
      "Epoch 465/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0458 - accuracy: 0.9814 - val_loss: 0.2284 - val_accuracy: 0.9537\n",
      "Epoch 466/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0485 - accuracy: 0.9805 - val_loss: 0.2277 - val_accuracy: 0.9533\n",
      "Epoch 467/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0530 - accuracy: 0.9803 - val_loss: 0.2251 - val_accuracy: 0.9542\n",
      "Epoch 468/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0493 - accuracy: 0.9812 - val_loss: 0.2122 - val_accuracy: 0.9484\n",
      "Epoch 469/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0524 - accuracy: 0.9804 - val_loss: 0.2075 - val_accuracy: 0.9573\n",
      "Epoch 470/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0455 - accuracy: 0.9812 - val_loss: 0.2529 - val_accuracy: 0.9453\n",
      "Epoch 471/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0531 - accuracy: 0.9796 - val_loss: 0.2100 - val_accuracy: 0.9568\n",
      "Epoch 472/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0451 - accuracy: 0.9828 - val_loss: 0.2314 - val_accuracy: 0.9484\n",
      "Epoch 473/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.2355 - val_accuracy: 0.9528\n",
      "Epoch 474/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0512 - accuracy: 0.9804 - val_loss: 0.2660 - val_accuracy: 0.9426\n",
      "Epoch 475/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0478 - accuracy: 0.9812 - val_loss: 0.2178 - val_accuracy: 0.9497\n",
      "Epoch 476/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0468 - accuracy: 0.9820 - val_loss: 0.2207 - val_accuracy: 0.9542\n",
      "Epoch 477/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0482 - accuracy: 0.9804 - val_loss: 0.2111 - val_accuracy: 0.9551\n",
      "Epoch 478/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0489 - accuracy: 0.9806 - val_loss: 0.2485 - val_accuracy: 0.9439\n",
      "Epoch 479/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0572 - accuracy: 0.9784 - val_loss: 0.2288 - val_accuracy: 0.9488\n",
      "Epoch 480/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.2154 - val_accuracy: 0.9528\n",
      "Epoch 481/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0427 - accuracy: 0.9838 - val_loss: 0.2094 - val_accuracy: 0.9537\n",
      "Epoch 482/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0476 - accuracy: 0.9825 - val_loss: 0.2162 - val_accuracy: 0.9551\n",
      "Epoch 483/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0477 - accuracy: 0.9819 - val_loss: 0.2479 - val_accuracy: 0.9488\n",
      "Epoch 484/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0538 - accuracy: 0.9794 - val_loss: 0.1949 - val_accuracy: 0.9604\n",
      "Epoch 485/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0441 - accuracy: 0.9829 - val_loss: 0.2600 - val_accuracy: 0.9435\n",
      "Epoch 486/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0463 - accuracy: 0.9828 - val_loss: 0.1999 - val_accuracy: 0.9559\n",
      "Epoch 487/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0523 - accuracy: 0.9806 - val_loss: 0.2383 - val_accuracy: 0.9497\n",
      "Epoch 488/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0536 - accuracy: 0.9805 - val_loss: 0.2207 - val_accuracy: 0.9524\n",
      "Epoch 489/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0473 - accuracy: 0.9814 - val_loss: 0.2142 - val_accuracy: 0.9533\n",
      "Epoch 490/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0416 - accuracy: 0.9836 - val_loss: 0.2032 - val_accuracy: 0.9559\n",
      "Epoch 491/500\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 0.1930 - val_accuracy: 0.9555\n",
      "Epoch 492/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 0.2307 - val_accuracy: 0.9608\n",
      "Epoch 493/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0468 - accuracy: 0.9810 - val_loss: 0.2189 - val_accuracy: 0.9515\n",
      "Epoch 494/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0429 - accuracy: 0.9823 - val_loss: 0.2265 - val_accuracy: 0.9497\n",
      "Epoch 495/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0452 - accuracy: 0.9816 - val_loss: 0.2148 - val_accuracy: 0.9573\n",
      "Epoch 496/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.1787 - val_accuracy: 0.9582\n",
      "Epoch 497/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0431 - accuracy: 0.9826 - val_loss: 0.1976 - val_accuracy: 0.9528\n",
      "Epoch 498/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0597 - accuracy: 0.9781 - val_loss: 0.1979 - val_accuracy: 0.9546\n",
      "Epoch 499/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0500 - accuracy: 0.9814 - val_loss: 0.2466 - val_accuracy: 0.9493\n",
      "Epoch 500/500\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0417 - accuracy: 0.9844 - val_loss: 0.1972 - val_accuracy: 0.9551\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 500\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    BATCH_SIZE, \n",
    "    EPOCHS, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard])\n",
    "\n",
    "model.save(\"D:/Project2022/models/\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"D:/Project2022/models/\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuuracy 0.9647561311721802\n",
      "Test loss 0.1805533766746521\n"
     ]
    }
   ],
   "source": [
    "# test loss, test accuracy\n",
    "accuracy = model.evaluate(X_test, y_test, batch_size=100, verbose=0)\n",
    "print(\"Test acuuracy\", accuracy[1])\n",
    "print(\"Test loss\", accuracy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000028C067D99D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000028C067D99D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "88/88 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       0.97      0.96      0.96      1395\n",
      "      Normal       0.96      0.97      0.97      1414\n",
      "\n",
      "    accuracy                           0.96      2809\n",
      "   macro avg       0.96      0.96      0.96      2809\n",
      "weighted avg       0.96      0.96      0.96      2809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_test)\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"covid\", \"Normal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=[\"Covid\",\"Normal\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe5100db488c6dee4f6d80c262766070d3a2c928954ee439beef6560db0c40bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
