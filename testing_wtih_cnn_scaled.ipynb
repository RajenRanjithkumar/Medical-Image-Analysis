{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "import xml.etree.ElementTree as ET\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"covid\", \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:/Project2022/res/final dataset/scaled_resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 - covid\\n1 - non covid\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label\n",
    "'''\n",
    "0 - covid\n",
    "1 - non covid\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_dataset(dataset_path):\n",
    "\n",
    "    df_data = pd.DataFrame()\n",
    "    raw_image = []\n",
    "    concat_data = []\n",
    "    label = []\n",
    "\n",
    "    for categoty in CATEGORIES:\n",
    "        path = os.path.join(dataset_path, categoty)  \n",
    "        \n",
    "        class_num = CATEGORIES.index(categoty)\n",
    "        \n",
    "\n",
    "        print(\"Loading dataset: class\",categoty)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                #img_array = cv2.resize(img_array, (512,512), interpolation= cv2.INTER_LINEAR)\n",
    "                row = img_array.sum(axis=0)\n",
    "                coloumn = img_array.sum(axis=1)\n",
    "                concat = np.concatenate((row, coloumn))\n",
    "                raw_image.append(img_array)\n",
    "                concat_data.append(concat)\n",
    "                label.append(class_num)\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    df_data[\"raw data\"] = raw_image\n",
    "    df_data[\"concat data\"] = concat_data\n",
    "    df_data[\"label\"] = label\n",
    "    \n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: class covid\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018546581268310547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7149,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a1acbb545c4dbfabe34614660a2cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: class normal\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01999950408935547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6893,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a49fd68a6744c0a28e6b8b969cb274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_df = pre_process_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw data</th>\n",
       "      <th>concat data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[196, 209, 216, 221, 194, 200, 221, 228, 230,...</td>\n",
       "      <td>[64117, 64122, 46372, 44770, 44689, 44683, 450...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[236, 243, 245, 242, 236, 229, 227, 230, 233,...</td>\n",
       "      <td>[47767, 46841, 45907, 45465, 45243, 45002, 444...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[81, 83, 82, 82, 82, 83, 84, 81, 81, 83, 84, ...</td>\n",
       "      <td>[20034, 19739, 19521, 19288, 19128, 19101, 191...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[71, 74, 70, 72, 78, 83, 87, 86, 82, 83, 81, ...</td>\n",
       "      <td>[15349, 15287, 15226, 15048, 14799, 14584, 144...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[74, 76, 73, 69, 72, 80, 87, 87, 82, 85, 79, ...</td>\n",
       "      <td>[15874, 15967, 15938, 15690, 15474, 15306, 149...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw data  \\\n",
       "0  [[196, 209, 216, 221, 194, 200, 221, 228, 230,...   \n",
       "1  [[236, 243, 245, 242, 236, 229, 227, 230, 233,...   \n",
       "2  [[81, 83, 82, 82, 82, 83, 84, 81, 81, 83, 84, ...   \n",
       "3  [[71, 74, 70, 72, 78, 83, 87, 86, 82, 83, 81, ...   \n",
       "4  [[74, 76, 73, 69, 72, 80, 87, 87, 82, 85, 79, ...   \n",
       "\n",
       "                                         concat data  label  \n",
       "0  [64117, 64122, 46372, 44770, 44689, 44683, 450...      0  \n",
       "1  [47767, 46841, 45907, 45465, 45243, 45002, 444...      0  \n",
       "2  [20034, 19739, 19521, 19288, 19128, 19101, 191...      0  \n",
       "3  [15349, 15287, 15226, 15048, 14799, 14584, 144...      0  \n",
       "4  [15874, 15967, 15938, 15690, 15474, 15306, 149...      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEICAYAAACuxNj9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcEElEQVR4nO3df7xVdZ3v8dc7zB+ZmCZwEUjM6Ac6aiN57dakiTNiWXhrTHpkktkwee23/ZBqpuwRk90eWdmMznVKgUqJanyIGRVR1nRzsmNpiD+uKAYEwVFT0YwRfN8/1vfM7A77nLUPnr3ZcN7Px2M/1lqftb5rfTYez+es73f9kG0iIiIG87SdnUBERHS/FIuIiKiVYhEREbVSLCIiolaKRURE1EqxiIiIWikW0VUk/bOkvxumfT1H0qOSRpXlGyS9bTj2Xfa3VNLs4drfEI77SUn3S/rdENsN6/ePkWWPnZ1AjByS7gPGAVuBbcDtwELgcttPAth++xD29TbbPxhoG9trgGc+taz/83gfB55n+8yG/Z8yHPseYh6TgPOBQ2xv6vTxY+TKmUV02mts7wccAlwEfAj48nAfRNLu+ofQIcADKRTRaSkWsVPYftj2EuAMYLakIwAkzZf0yTJ/kKRvS3pI0oOS/k3S0yR9BXgOcF3pZvqgpMmSLOkcSWuAHzbEGgvHYZJukvSwpGslHViOdYKkdY05SrpP0kmSZgAfBs4ox7u1rP/Pbp2S10cl/UbSJkkLJe1f1vXlMVvSmtKF9JGB/m0k7V/a95b9fbTs/yRgGXBwyWP+AO1nSrpF0iOS7in599/mMEk/lPRAyedrkp7VsP5Dkn4rabOkuyRNL/FjJfWUfW+UdHFDm+Mk/az897pV0gkN694i6d6yv9WS3jTQ94/ulGIRO5Xtm4B1wF80WX1+WTeGqvvqw1UTvxlYQ3WW8kzb/7uhzfHAi4CTBzjkWcBbgYOpusMuaSHH7wL/AHy9HO+oJpu9pXxeCTyXqvvrH/tt83LgBcB04O8lvWiAQ34R2L/s5/iS89mly+0UYH3J4y39G0o6lqpr7wPAs4BXAPc1OYaAT1H9O7wImAR8vOzjBcA7gJeUs8CTG/bxBeALtkcDhwGLS5sJwPXAJ4EDgfcD35I0RtK+VP/Op5T9/Q/glgG+e3SpFIvoBuupfsH09wQwnqp//gnb/+b6h5l93PZjth8fYP1XbN9m+zHg74A39A2AP0VvAi62fa/tR4G5wKx+ZzUX2n7c9q3ArcB2RafkcgYw1/Zm2/cBnwXe3GIe5wBX2F5m+0nbv7V9Z/+NbK8q22yx3QtcTFWYoBpP2guYKunptu+zfU9Z9wTwPEkH2X7U9r+X+JnAd2x/pxx3GdADvKqsfxI4QtI+tjfYXtni94kukWIR3WAC8GCT+GeAVcD3SxfGBS3sa+0Q1v8GeDpwUEtZDu7gsr/Gfe9BdUbUp/HqpT/QfPD9IGDPJvua0GIek4B76jaSNFbSotLV9Ajw1XJsbK8C3kN1prGpbHdwaXoO8HzgTkm/kHRqiR8CnF66oB6S9BDVmdT4UpjPAN4ObJB0vaQXtvh9okukWMROJeklVL8If9p/XfnL+nzbzwVeA7yvr+8cGOgMo+7MY1LD/HOo/lK+H3gMeEZDXqOour9a3e96ql+YjfveCmysadff/SWn/vv6bYvt11J1D9X5FNV3OrJ0KZ1J1TUFgO2rbL+85GHg0yV+t+03AmNL7Julm2kt1Vnbsxo++9q+qLT7nu2/pDpTvBP4lxa/T3SJFIvYKSSNLn+VLgK+antFk21OlfQ8SQIeoeoe2VZWb6Tq0x+qMyVNlfQM4BPAN21vA/4fsLekV0t6OvBRqq6YPhuByZIG+n/mauC9kg6V9Ez+a4xj61CSK7ksBuZJ2k/SIcD7qP7yb8WXgbMlTS+D4hMG+Ct+P+BR4KEy3vCBvhWSXiDpREl7AX8EHqf8u0s6U9KYcqnzQ6XJtpLfaySdLGmUpL3LRQMTJY2T9NpSVLaU4/b9d4xdRIpFdNp1kjZT/SX6Eaq+8rMH2HYK8AOqXy43ApfavqGs+xTw0dLl8f4hHP8rwHyqLqG9gXdBdXUW8L+AL1H9Ff8Y1eB6n2+U6QOSftlkv1eUff8EWE31S/adQ8ir0TvL8e+lOuO6quy/Vrlg4Gzgc8DDwI/507OUPhcCf162uR7414Z1e1Fd1nw/1b/TWKqLCwBmACslPUo12D3L9h9trwVmlu16qf77foDqd8zTqC5WWE/V3Xg81b917EKUlx9FRESdnFlEREStFIuIiKiVYhEREbVSLCIiotbu+rA1DjroIE+ePHlnpxERsUu5+eab77c9pn98ty0WkydPpqenZ2enERGxS5H0m2bxdENFREStFIuIiKiVYhEREbVSLCIiolaKRURE1EqxiIiIWikWERFRK8UiIiJqpVhERESt3fYO7l3F5Auu39kp7Dbuu+jVOzuFiN1W284syqsZb2n4PCLpPZIOlLRM0t1lekBDm7mSVkm6S9LJDfFjJK0o6y4pr9mMiIgOaVuxsH2X7aNtHw0cA/wBuAa4AFhuewqwvCwjaSowCzic6tWNl0oaVXZ3GTCH6jWbU8r6iIjokE6NWUwH7rH9G6r39C4o8QXAaWV+JrDI9hbbq4FVwLGSxgOjbd/o6h2wCxvaREREB3SqWMwCri7z42xvACjTsSU+geol733WldiEMt8/vh1JcyT1SOrp7e0dxvQjIka2thcLSXsCrwW+Ubdpk5gHiW8ftC+3Pc32tDFjtnsce0RE7KBOnFmcAvzS9sayvLF0LVGmm0p8HTCpod1EYH2JT2wSj4iIDunEpbNv5L+6oACWALOBi8r02ob4VZIuBg6mGsi+yfY2SZslHQf8HDgL+GIH8o4Y0XJZ9/Da1S/tbmuxkPQM4C+Bv20IXwQslnQOsAY4HcD2SkmLgduBrcB5treVNucC84F9gKXlExERHdLWYmH7D8Cz+8UeoLo6qtn284B5TeI9wBHtyDEiIurlcR8REVErxSIiImqlWERERK0Ui4iIqJViERERtVIsIiKiVopFRETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqJViERERtVIsIiKiVopFRETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqNXWYiHpWZK+KelOSXdIeqmkAyUtk3R3mR7QsP1cSask3SXp5Ib4MZJWlHWXSFI7846IiD/V7jOLLwDftf1C4CjgDuACYLntKcDysoykqcAs4HBgBnCppFFlP5cBc4Ap5TOjzXlHRESDthULSaOBVwBfBrD9H7YfAmYCC8pmC4DTyvxMYJHtLbZXA6uAYyWNB0bbvtG2gYUNbSIiogPaeWbxXKAXuFLSryR9SdK+wDjbGwDKdGzZfgKwtqH9uhKbUOb7x7cjaY6kHkk9vb29w/ttIiJGsHYWiz2APwcus/1i4DFKl9MAmo1DeJD49kH7ctvTbE8bM2bMUPONiIgBtLNYrAPW2f55Wf4mVfHYWLqWKNNNDdtPamg/EVhf4hObxCMiokPaVixs/w5YK+kFJTQduB1YAswusdnAtWV+CTBL0l6SDqUayL6pdFVtlnRcuQrqrIY2ERHRAXu0ef/vBL4maU/gXuBsqgK1WNI5wBrgdADbKyUtpiooW4HzbG8r+zkXmA/sAywtn4iI6JC2FgvbtwDTmqyaPsD284B5TeI9wBHDmlxERLQsd3BHREStFIuIiKiVYhEREbVSLCIiolaKRURE1EqxiIiIWikWERFRK8UiIiJqpVhEREStFIuIiKiVYhEREbVSLCIiolaKRURE1EqxiIiIWikWERFRK8UiIiJqpVhEREStFIuIiKiVYhEREbVSLCIiolZbi4Wk+yStkHSLpJ4SO1DSMkl3l+kBDdvPlbRK0l2STm6IH1P2s0rSJZLUzrwjIuJPdeLM4pW2j7Y9rSxfACy3PQVYXpaRNBWYBRwOzAAulTSqtLkMmANMKZ8ZHcg7IiKKndENNRNYUOYXAKc1xBfZ3mJ7NbAKOFbSeGC07RttG1jY0CYiIjqg3cXCwPcl3SxpTomNs70BoEzHlvgEYG1D23UlNqHM949vR9IcST2Senp7e4fxa0REjGx7tHn/L7O9XtJYYJmkOwfZttk4hAeJbx+0LwcuB5g2bVrTbSIiYuiGdGYh6QBJR7a6ve31ZboJuAY4FthYupYo001l83XApIbmE4H1JT6xSTwiIjqktlhIukHSaEkHArcCV0q6uIV2+0rar28e+CvgNmAJMLtsNhu4tswvAWZJ2kvSoVQD2TeVrqrNko4rV0Gd1dAmIiI6oJVuqP1tPyLpbcCVtj8m6dcttBsHXFOuct0DuMr2dyX9Algs6RxgDXA6gO2VkhYDtwNbgfNsbyv7OheYD+wDLC2fiIjokFaKxR6lu+gNwEda3bHte4GjmsQfAKYP0GYeMK9JvAc4otVjR0TE8GplzOITwPeAe2z/QtJzgbvbm1ZERHST2jML298AvtGwfC/w+nYmFRER3aWVAe7nS1ou6bayfKSkj7Y/tYiI6BatdEP9CzAXeALA9q+pHssREREjRCvF4hm2b+oX29qOZCIioju1Uizul3QY5a5pSX8NbGhrVhER0VVauXT2PKpHaLxQ0m+B1cCZbc0qIiK6SitXQ90LnFTuwn6a7c3tTysiIrrJgMVC0vsGiANgu/aRHxERsXsY7Mxiv45lERERXW3AYmH7wk4mEhER3auVm/KeK+k6Sb2SNkm6tjzyIyIiRohWLp29ClgMjAcOpnr0x9XtTCoiIrpLK8VCtr9ie2v5fJUB3lQXERG7p1bus/iRpAuARVRF4gzg+vIyJGw/2Mb8IiKiC7RSLM4o07/tF38rVfHI+EVExG6ulZvyDu1EIhER0b1qi4WkUcCrgcmN2+emvIiIkaOVbqjrgD8CK4An25tORER0o1aKxUTbR7Y9k4iI6FqtXDq7VNJf7egBJI2S9CtJ3y7LB0paJunuMj2gYdu5klZJukvSyQ3xYyStKOsuUd8DqiIioiNaKRb/Dlwj6XFJj0jaLOmRIRzj3cAdDcsXAMttTwGWl2UkTaV6A9/hwAzg0jJeAnAZMAeYUj4zhnD8iIh4ilopFp8FXkr1xrzRtvezPbqVnUuaSDU4/qWG8ExgQZlfAJzWEF9ke4vt1cAq4FhJ44HRtm+0bWBhQ5uIiOiAVorF3cBt5Rf1UH0e+CB/OjA+zvYGgDIdW+ITgLUN260rsQllvn98O5LmSOqR1NPb27sD6UZERDOtDHBvAG6QtBTY0hesu3RW0qnAJts3SzqhheM0G4fwIPHtg/blVG/1Y9q0aXkkSUTEMGmlWKwunz3Lp1UvA14r6VXA3sBoSV8FNkoab3tD6WLaVLZfB0xqaD8RWF/iE5vEIyKiQ1q5g3uH3mthey4wF6CcWbzf9pmSPgPMBi4q02tLkyXAVZIupnq67RTgJtvbyqD6ccDPgbOAL+5IThERsWNauYN7DNW4w+FUZwgA2D5xB495EbBY0jnAGuD0sr+VkhYDtwNbgfNsbyttzgXmA/sAS8snIiI6pJVuqK8BXwdOBd5OdTYwpNFj2zcAN5T5B4DpA2w3D5jXJN4DHDGUY0ZExPBp5WqoZ9v+MvCE7R/bfitwXJvzioiILtLKmcUTZbpB0qupBpcnDrJ9RETsZlopFp+UtD9wPtXA8mjgvW3NKiIiukorV0N9u8w+DLyyvelEREQ3GnDMQtLfSJpS5iXpSkkPS/q1pBd3LsWIiNjZBhvgfjdwX5l/I3Ak1StU3wdc0t60IiKimwxWLLba7hvcPhVYaPsB2z8A9m1/ahER0S0GKxZPShovaW+q+yJ+0LBun/amFRER3WSwAe6/B3qAUcAS2ysBJB0P3NuB3CIioksMWCxsf1vSIcB+tn/fsKoHOKPtmUVERNcY9NJZ21uB3/eLPdbWjCIiouu08riPiIgY4Qa7z+JlZbpX59KJiIhuNNiZRd+9FDd2IpGIiOheg41ZPCHpSmCCpO1uwrP9rvalFRER3WSwYnEqcBJwInBzZ9KJiIhuNNils/cDiyTdYfvWDuYUERFdppWroR6QdI2kTZI2SvqWpLzPIiJiBGmlWFwJLAEOBiYA15VYRESMEK0Ui7G2r7S9tXzmA2PanFdERHSRVopFr6QzJY0qnzOBB+oaSdpb0k2SbpW0UtKFJX6gpGWS7i7TAxrazJW0StJdkk5uiB8jaUVZd4kk7ciXjYiIHdNKsXgr8Abgd8AG4K9LrM4W4ETbRwFHAzMkHQdcACy3PQVYXpaRNBWYBRwOzAAulTSq7OsyYA4wpXxmtPLlIiJieLTyWtU1wGuHumPbBh4ti08vHwMzgRNKfAFwA/ChEl9kewuwWtIq4FhJ9wGjbd8IIGkhcBqwdKg5RUTEjmnrs6FKt9UtwCZgme2fA+NsbwAo07Fl8wnA2obm60psQpnvH292vDmSeiT19Pb2Dut3iYgYydpaLGxvs300MJHqLOGIQTZvNg7hQeLNjne57Wm2p40ZkzH4iIjh0pGnztp+iKq7aQawUdJ4gDLdVDZbB0xqaDYRWF/iE5vEIyKiQ2qLhaT9JX2ur3tH0mcl7d9CuzGSnlXm96F6dMidVPdszC6bzQauLfNLgFmS9pJ0KNVA9k2lq2qzpOPKVVBnNbSJiIgOqB3gBq4AbqO6IgrgzVQ35b2upt14YEG5oulpwOLy9r0bgcWSzgHWAKcD2F4paTFwO7AVOM/2trKvc4H5VO/+XkoGtyMiOqqVYnGY7dc3LF9YBq0HZfvXwIubxB8Apg/QZh4wr0m8BxhsvCMiItqolTGLxyW9vG+hvBTp8falFBER3aaVM4u3AwvLOIWAB4G3tDOpiIjoLq3clHcrcJSk0WX5kbZnFRERXaW2WJR3cL8emAzs0fdYJtufaGtmERHRNVrphroWeJjqbXlb2ptORER0o1aKxUTbeXBfRMQI1srVUD+T9GdtzyQiIrpWK2cWLwfeImk1VTeUqB4qe2RbM4uIiK7RSrE4pe1ZREREV2vl0tnfdCKRiIjoXh156mxEROzaUiwiIqJWikVERNRKsYiIiFopFhERUSvFIiIiaqVYRERErRSLiIiolWIRERG1UiwiIqJW24qFpEmSfiTpDkkrJb27xA+UtEzS3WV6QEObuZJWSbpL0skN8WMkrSjrLlHfG5giIqIj2nlmsRU43/aLgOOA8yRNBS4AltueAiwvy5R1s4DDgRnApZJGlX1dBswBppRP3q8REdFBbSsWtjfY/mWZ3wzcAUwAZgILymYLgNPK/Exgke0ttlcDq4BjJY0HRtu+0baBhQ1tIiKiAzoyZiFpMvBi4OfAONsboCoowNiy2QRgbUOzdSU2ocz3jzc7zhxJPZJ6ent7h/U7RESMZG0vFpKeCXwLeI/tRwbbtEnMg8S3D9qX255me9qYMWOGnmxERDTV1mIh6elUheJrtv+1hDeWriXKdFOJrwMmNTSfCKwv8YlN4hER0SHtvBpKwJeBO2xf3LBqCTC7zM8Grm2Iz5K0l6RDqQaybypdVZslHVf2eVZDm4iI6IBWXqu6o14GvBlYIemWEvswcBGwWNI5wBrgdADbKyUtBm6nupLqPNvbSrtzgfnAPsDS8omIiA5pW7Gw/VOajzcATB+gzTxgXpN4D3DE8GUXERFDkTu4IyKiVopFRETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqJViERERtVIsIiKiVopFRETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqJViERERtVIsIiKiVopFRETUSrGIiIhaKRYREVGrbcVC0hWSNkm6rSF2oKRlku4u0wMa1s2VtErSXZJObogfI2lFWXeJJLUr54iIaK6dZxbzgRn9YhcAy21PAZaXZSRNBWYBh5c2l0oaVdpcBswBppRP/31GRESbta1Y2P4J8GC/8ExgQZlfAJzWEF9ke4vt1cAq4FhJ44HRtm+0bWBhQ5uIiOiQTo9ZjLO9AaBMx5b4BGBtw3brSmxCme8fb0rSHEk9knp6e3uHNfGIiJGsWwa4m41DeJB4U7Yvtz3N9rQxY8YMW3IRESNdp4vFxtK1RJluKvF1wKSG7SYC60t8YpN4RER0UKeLxRJgdpmfDVzbEJ8laS9Jh1INZN9Uuqo2SzquXAV1VkObiIjokD3atWNJVwMnAAdJWgd8DLgIWCzpHGANcDqA7ZWSFgO3A1uB82xvK7s6l+rKqn2ApeUTEREd1LZiYfuNA6yaPsD284B5TeI9wBHDmFpERAxRtwxwR0REF0uxiIiIWikWERFRK8UiIiJqpVhEREStFIuIiKiVYhEREbVSLCIiolaKRURE1EqxiIiIWikWERFRK8UiIiJqpVhEREStFIuIiKiVYhEREbVSLCIiolaKRURE1EqxiIiIWikWERFRK8UiIiJq7TLFQtIMSXdJWiXpgp2dT0TESLJLFAtJo4B/Ak4BpgJvlDR152YVETFy7BLFAjgWWGX7Xtv/ASwCZu7knCIiRow9dnYCLZoArG1YXgf89/4bSZoDzCmLj0q6qwO5jQQHAffv7CTq6NM7O4PYSfLzObwOaRbcVYqFmsS8XcC+HLi8/emMLJJ6bE/b2XlENJOfz87YVbqh1gGTGpYnAut3Ui4RESPOrlIsfgFMkXSopD2BWcCSnZxTRMSIsUt0Q9neKukdwPeAUcAVtlfu5LRGknTtRTfLz2cHyN6u6z8iIuJP7CrdUBERsROlWERERK0UixFI0n+TtEjSPZJul/QdSc8f4j6mSbpkgHX3STpoeLKN3ZkkS/psw/L7JX28wzncICmX3tZIsRhhJAm4BrjB9mG2pwIfBsYNZT+2e2y/qx05xoiyBXjdjv5xIWmXuEhnd5BiMfK8EnjC9j/3BWzfAvxU0mck3SZphaQzACR9XdKr+raVNF/S6yWdIOnbJfZsSd+X9CtJ/4fmN1FGNLOV6mqm9/ZfIekQScsl/bpMn1Pi8yVdLOlHwKfL8mWSfiTpXknHS7pC0h2S5jfs7zJJPZJWSrqwU19wd5FiMfIcAdzcJP464GjgKOAk4DOSxlM9h6uvcOwJTAe+06/tx4Cf2n4x1f0vz2lL5rG7+ifgTZL27xf/R2Ch7SOBrwGN3Z7PB06yfX5ZPgA4karoXAd8Djgc+DNJR5dtPlLu9D4SOF7Ske34MrurFIvo83LgatvbbG8Efgy8BFgKnChpL6qn/v7E9uP92r4C+CqA7euB33cu7djV2X4EWAj079Z8KXBVmf8K1c9on2/Y3tawfJ2r+wBWABttr7D9JLASmFy2eYOkXwK/oiokeXL1EKRYjDwrgWOaxJt2Hdn+I3ADcDLVGcaiAfabG3biqfg8cA6w7yDbNP6MPdZv3ZYyfbJhvm95D0mHAu8HppczleuBvZ9KwiNNisXI80NgL0l/0xeQ9BKqs4EzJI2SNIbqbOGmsski4GzgL6juou/vJ8Cbyr5OoeoSiGiZ7QeBxVQFo8/PqB7tA9XP10+fwiFGUxWYhyWNozpLjiHIlQQjjG1L+p/A58sbB/8I3Ae8B3gmcCvVX3AftP270uz7VN0ES8r7RPq7ELi6nOL/GFjT1i8Ru6vPAu9oWH4XcIWkDwC9VH+w7BDbt0r6FdWZ9b3A/30qiY5EedxHRETUSjdURETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqJViERERtf4/uN9iAkPutQQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_df[\"label\"].value_counts().plot(kind='bar')\n",
    "plt.xticks([0,1], [\"Covid\", \"Normal\"], rotation='horizontal')\n",
    "plt.ylabel('no of Samples')\n",
    "plt.title('Distribution of classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7149\n",
       "1    6893\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021009206771850586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 14042,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c562ce1a979b40fa8051a0bc2beaeff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (14042, 619)\n",
      "y shape (14042,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = dataset_df[\"concat data\"].values\n",
    "X = [img.tolist() for img in tqdm(dataset)]\n",
    "X = np.array(X)\n",
    "y = np.array(dataset_df[\"label\"].values)\n",
    "print(\"X shape\", X.shape)\n",
    "print(\"y shape\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_norm = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of the dataset after changing the dimension\n",
      "X :  (14042, 619, 1)\n",
      "y :  (14042, 1)\n"
     ]
    }
   ],
   "source": [
    "# change dimensions for training \n",
    "dataset_X = np.expand_dims(X_norm, axis=-1)\n",
    "dataset_y = np.expand_dims(y, axis=-1)\n",
    "print(\" shape of the dataset after changing the dimension\")\n",
    "print(\"X : \", dataset_X.shape)\n",
    "print(\"y : \", dataset_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_X, dataset_y, shuffle=True, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=X_train[0].shape))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Conv1D_resized_500\"\n",
    "NAME = model_name+\"-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000231CD18B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000231CD18B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "899/899 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.6954WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000231E8B8ACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000231E8B8ACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "899/899 [==============================] - 19s 11ms/step - loss: 0.5904 - accuracy: 0.6954 - val_loss: 0.5083 - val_accuracy: 0.7539\n",
      "Epoch 2/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4812 - accuracy: 0.7680 - val_loss: 0.4486 - val_accuracy: 0.7931\n",
      "Epoch 3/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.4331 - accuracy: 0.8027 - val_loss: 0.4186 - val_accuracy: 0.8162\n",
      "Epoch 4/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4091 - accuracy: 0.8175 - val_loss: 0.4050 - val_accuracy: 0.8318\n",
      "Epoch 5/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3933 - accuracy: 0.8301 - val_loss: 0.3731 - val_accuracy: 0.8349\n",
      "Epoch 6/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3812 - accuracy: 0.8385 - val_loss: 0.3899 - val_accuracy: 0.8251\n",
      "Epoch 7/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3822 - accuracy: 0.8318 - val_loss: 0.3712 - val_accuracy: 0.8487\n",
      "Epoch 8/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3676 - accuracy: 0.8434 - val_loss: 0.3715 - val_accuracy: 0.8474\n",
      "Epoch 9/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3627 - accuracy: 0.8418 - val_loss: 0.3764 - val_accuracy: 0.8416\n",
      "Epoch 10/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3518 - accuracy: 0.8462 - val_loss: 0.3541 - val_accuracy: 0.8482\n",
      "Epoch 11/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3511 - accuracy: 0.8492 - val_loss: 0.3517 - val_accuracy: 0.8594\n",
      "Epoch 12/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3483 - accuracy: 0.8490 - val_loss: 0.3587 - val_accuracy: 0.8482\n",
      "Epoch 13/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3431 - accuracy: 0.8539 - val_loss: 0.3408 - val_accuracy: 0.8594\n",
      "Epoch 14/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3413 - accuracy: 0.8531 - val_loss: 0.3483 - val_accuracy: 0.8545\n",
      "Epoch 15/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3354 - accuracy: 0.8559 - val_loss: 0.3812 - val_accuracy: 0.8433\n",
      "Epoch 16/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3295 - accuracy: 0.8643 - val_loss: 0.3471 - val_accuracy: 0.8531\n",
      "Epoch 17/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3213 - accuracy: 0.8626 - val_loss: 0.3649 - val_accuracy: 0.8313\n",
      "Epoch 18/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3265 - accuracy: 0.8603 - val_loss: 0.3472 - val_accuracy: 0.8545\n",
      "Epoch 19/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3188 - accuracy: 0.8616 - val_loss: 0.3398 - val_accuracy: 0.8585\n",
      "Epoch 20/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3170 - accuracy: 0.8678 - val_loss: 0.3921 - val_accuracy: 0.8385\n",
      "Epoch 21/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3175 - accuracy: 0.8652 - val_loss: 0.3351 - val_accuracy: 0.8625\n",
      "Epoch 22/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3063 - accuracy: 0.8726 - val_loss: 0.3348 - val_accuracy: 0.8589\n",
      "Epoch 23/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3083 - accuracy: 0.8739 - val_loss: 0.3251 - val_accuracy: 0.8669\n",
      "Epoch 24/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.3016 - accuracy: 0.8738 - val_loss: 0.3198 - val_accuracy: 0.8674\n",
      "Epoch 25/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.2991 - accuracy: 0.8748 - val_loss: 0.3165 - val_accuracy: 0.8674\n",
      "Epoch 26/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2978 - accuracy: 0.8738 - val_loss: 0.3494 - val_accuracy: 0.8509\n",
      "Epoch 27/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.2939 - accuracy: 0.8770 - val_loss: 0.3541 - val_accuracy: 0.8634\n",
      "Epoch 28/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.2955 - accuracy: 0.8770 - val_loss: 0.3188 - val_accuracy: 0.8732\n",
      "Epoch 29/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2881 - accuracy: 0.8795 - val_loss: 0.3155 - val_accuracy: 0.8718\n",
      "Epoch 30/500\n",
      "899/899 [==============================] - 9s 10ms/step - loss: 0.2908 - accuracy: 0.8791 - val_loss: 0.3234 - val_accuracy: 0.8749\n",
      "Epoch 31/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2852 - accuracy: 0.8819 - val_loss: 0.3073 - val_accuracy: 0.8789\n",
      "Epoch 32/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2772 - accuracy: 0.8840 - val_loss: 0.4004 - val_accuracy: 0.8193\n",
      "Epoch 33/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2801 - accuracy: 0.8852 - val_loss: 0.3122 - val_accuracy: 0.8763\n",
      "Epoch 34/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2788 - accuracy: 0.8839 - val_loss: 0.3294 - val_accuracy: 0.8683\n",
      "Epoch 35/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2731 - accuracy: 0.8884 - val_loss: 0.3109 - val_accuracy: 0.8785\n",
      "Epoch 36/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2690 - accuracy: 0.8863 - val_loss: 0.3137 - val_accuracy: 0.8763\n",
      "Epoch 37/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.2651 - accuracy: 0.8932 - val_loss: 0.3547 - val_accuracy: 0.8469\n",
      "Epoch 38/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2622 - accuracy: 0.8944 - val_loss: 0.3006 - val_accuracy: 0.8861\n",
      "Epoch 39/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2559 - accuracy: 0.8951 - val_loss: 0.2941 - val_accuracy: 0.8887\n",
      "Epoch 40/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2575 - accuracy: 0.8929 - val_loss: 0.3144 - val_accuracy: 0.8776\n",
      "Epoch 41/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2484 - accuracy: 0.8986 - val_loss: 0.3163 - val_accuracy: 0.8794\n",
      "Epoch 42/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2524 - accuracy: 0.8939 - val_loss: 0.3094 - val_accuracy: 0.8861\n",
      "Epoch 43/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2464 - accuracy: 0.8995 - val_loss: 0.2887 - val_accuracy: 0.8887\n",
      "Epoch 44/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2418 - accuracy: 0.9023 - val_loss: 0.2914 - val_accuracy: 0.8865\n",
      "Epoch 45/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2435 - accuracy: 0.9004 - val_loss: 0.3070 - val_accuracy: 0.8687\n",
      "Epoch 46/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2431 - accuracy: 0.8986 - val_loss: 0.2885 - val_accuracy: 0.8963\n",
      "Epoch 47/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2366 - accuracy: 0.9023 - val_loss: 0.3233 - val_accuracy: 0.8700\n",
      "Epoch 48/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2325 - accuracy: 0.9030 - val_loss: 0.3270 - val_accuracy: 0.8643\n",
      "Epoch 49/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2384 - accuracy: 0.9030 - val_loss: 0.2873 - val_accuracy: 0.8865\n",
      "Epoch 50/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2284 - accuracy: 0.9047 - val_loss: 0.2771 - val_accuracy: 0.9003\n",
      "Epoch 51/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2292 - accuracy: 0.9071 - val_loss: 0.2855 - val_accuracy: 0.8923\n",
      "Epoch 52/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2226 - accuracy: 0.9112 - val_loss: 0.2817 - val_accuracy: 0.8963\n",
      "Epoch 53/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2258 - accuracy: 0.9104 - val_loss: 0.2782 - val_accuracy: 0.8976\n",
      "Epoch 54/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2250 - accuracy: 0.9086 - val_loss: 0.2784 - val_accuracy: 0.8927\n",
      "Epoch 55/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2269 - accuracy: 0.9105 - val_loss: 0.2825 - val_accuracy: 0.8972\n",
      "Epoch 56/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2173 - accuracy: 0.9130 - val_loss: 0.2838 - val_accuracy: 0.8919\n",
      "Epoch 57/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2169 - accuracy: 0.9115 - val_loss: 0.2804 - val_accuracy: 0.8985\n",
      "Epoch 58/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2113 - accuracy: 0.9174 - val_loss: 0.3020 - val_accuracy: 0.8852\n",
      "Epoch 59/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2141 - accuracy: 0.9103 - val_loss: 0.2719 - val_accuracy: 0.8972\n",
      "Epoch 60/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2095 - accuracy: 0.9151 - val_loss: 0.2643 - val_accuracy: 0.8990\n",
      "Epoch 61/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2053 - accuracy: 0.9159 - val_loss: 0.2836 - val_accuracy: 0.8910\n",
      "Epoch 62/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2059 - accuracy: 0.9164 - val_loss: 0.2722 - val_accuracy: 0.8985\n",
      "Epoch 63/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2078 - accuracy: 0.9153 - val_loss: 0.2812 - val_accuracy: 0.8968\n",
      "Epoch 64/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1993 - accuracy: 0.9197 - val_loss: 0.2551 - val_accuracy: 0.9070\n",
      "Epoch 65/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2047 - accuracy: 0.9155 - val_loss: 0.2791 - val_accuracy: 0.8923\n",
      "Epoch 66/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1953 - accuracy: 0.9214 - val_loss: 0.2797 - val_accuracy: 0.8941\n",
      "Epoch 67/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1944 - accuracy: 0.9229 - val_loss: 0.2637 - val_accuracy: 0.9012\n",
      "Epoch 68/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1950 - accuracy: 0.9212 - val_loss: 0.2694 - val_accuracy: 0.8976\n",
      "Epoch 69/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1997 - accuracy: 0.9212 - val_loss: 0.2761 - val_accuracy: 0.8945\n",
      "Epoch 70/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1949 - accuracy: 0.9205 - val_loss: 0.2702 - val_accuracy: 0.8968\n",
      "Epoch 71/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1921 - accuracy: 0.9202 - val_loss: 0.2788 - val_accuracy: 0.8954\n",
      "Epoch 72/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1843 - accuracy: 0.9259 - val_loss: 0.2776 - val_accuracy: 0.8976\n",
      "Epoch 73/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1878 - accuracy: 0.9260 - val_loss: 0.2545 - val_accuracy: 0.9052\n",
      "Epoch 74/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1847 - accuracy: 0.9251 - val_loss: 0.3103 - val_accuracy: 0.8638\n",
      "Epoch 75/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1861 - accuracy: 0.9242 - val_loss: 0.2639 - val_accuracy: 0.8981\n",
      "Epoch 76/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1835 - accuracy: 0.9272 - val_loss: 0.2577 - val_accuracy: 0.9057\n",
      "Epoch 77/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1855 - accuracy: 0.9273 - val_loss: 0.2650 - val_accuracy: 0.8994\n",
      "Epoch 78/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1815 - accuracy: 0.9232 - val_loss: 0.2746 - val_accuracy: 0.8968\n",
      "Epoch 79/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1789 - accuracy: 0.9269 - val_loss: 0.2421 - val_accuracy: 0.9141\n",
      "Epoch 80/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1805 - accuracy: 0.9277 - val_loss: 0.2510 - val_accuracy: 0.9061\n",
      "Epoch 81/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1829 - accuracy: 0.9266 - val_loss: 0.2456 - val_accuracy: 0.9065\n",
      "Epoch 82/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1682 - accuracy: 0.9348 - val_loss: 0.2462 - val_accuracy: 0.9132\n",
      "Epoch 83/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1693 - accuracy: 0.9342 - val_loss: 0.2544 - val_accuracy: 0.9065\n",
      "Epoch 84/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1712 - accuracy: 0.9325 - val_loss: 0.2511 - val_accuracy: 0.9079\n",
      "Epoch 85/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1696 - accuracy: 0.9327 - val_loss: 0.2589 - val_accuracy: 0.9052\n",
      "Epoch 86/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1717 - accuracy: 0.9307 - val_loss: 0.2687 - val_accuracy: 0.9030\n",
      "Epoch 87/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1641 - accuracy: 0.9311 - val_loss: 0.2834 - val_accuracy: 0.8985\n",
      "Epoch 88/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1687 - accuracy: 0.9326 - val_loss: 0.2435 - val_accuracy: 0.9101\n",
      "Epoch 89/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1681 - accuracy: 0.9316 - val_loss: 0.2708 - val_accuracy: 0.9030\n",
      "Epoch 90/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1622 - accuracy: 0.9367 - val_loss: 0.2505 - val_accuracy: 0.9132\n",
      "Epoch 91/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1613 - accuracy: 0.9345 - val_loss: 0.2739 - val_accuracy: 0.8999\n",
      "Epoch 92/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1660 - accuracy: 0.9326 - val_loss: 0.2556 - val_accuracy: 0.8985\n",
      "Epoch 93/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1614 - accuracy: 0.9346 - val_loss: 0.2408 - val_accuracy: 0.9168\n",
      "Epoch 94/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1568 - accuracy: 0.9367 - val_loss: 0.2331 - val_accuracy: 0.9128\n",
      "Epoch 95/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1572 - accuracy: 0.9365 - val_loss: 0.2667 - val_accuracy: 0.9105\n",
      "Epoch 96/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1628 - accuracy: 0.9356 - val_loss: 0.2765 - val_accuracy: 0.9030\n",
      "Epoch 97/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1617 - accuracy: 0.9361 - val_loss: 0.2449 - val_accuracy: 0.9159\n",
      "Epoch 98/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1553 - accuracy: 0.9366 - val_loss: 0.2598 - val_accuracy: 0.9043\n",
      "Epoch 99/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1531 - accuracy: 0.9375 - val_loss: 0.2524 - val_accuracy: 0.9137\n",
      "Epoch 100/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1523 - accuracy: 0.9370 - val_loss: 0.2369 - val_accuracy: 0.9150\n",
      "Epoch 101/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1564 - accuracy: 0.9370 - val_loss: 0.2442 - val_accuracy: 0.9154\n",
      "Epoch 102/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1492 - accuracy: 0.9400 - val_loss: 0.2358 - val_accuracy: 0.9172\n",
      "Epoch 103/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1500 - accuracy: 0.9399 - val_loss: 0.2426 - val_accuracy: 0.9150\n",
      "Epoch 104/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1525 - accuracy: 0.9381 - val_loss: 0.2666 - val_accuracy: 0.9163\n",
      "Epoch 105/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1468 - accuracy: 0.9398 - val_loss: 0.2383 - val_accuracy: 0.9146\n",
      "Epoch 106/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1528 - accuracy: 0.9406 - val_loss: 0.2768 - val_accuracy: 0.9048\n",
      "Epoch 107/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1428 - accuracy: 0.9410 - val_loss: 0.2402 - val_accuracy: 0.9186\n",
      "Epoch 108/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1490 - accuracy: 0.9401 - val_loss: 0.2483 - val_accuracy: 0.9172\n",
      "Epoch 109/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1447 - accuracy: 0.9428 - val_loss: 0.2544 - val_accuracy: 0.9083\n",
      "Epoch 110/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1385 - accuracy: 0.9470 - val_loss: 0.2556 - val_accuracy: 0.9088\n",
      "Epoch 111/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1432 - accuracy: 0.9430 - val_loss: 0.2401 - val_accuracy: 0.9199\n",
      "Epoch 112/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1366 - accuracy: 0.9478 - val_loss: 0.2516 - val_accuracy: 0.9119\n",
      "Epoch 113/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1433 - accuracy: 0.9434 - val_loss: 0.2580 - val_accuracy: 0.9052\n",
      "Epoch 114/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1393 - accuracy: 0.9447 - val_loss: 0.2827 - val_accuracy: 0.8941\n",
      "Epoch 115/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1368 - accuracy: 0.9445 - val_loss: 0.2626 - val_accuracy: 0.9168\n",
      "Epoch 116/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1366 - accuracy: 0.9471 - val_loss: 0.2965 - val_accuracy: 0.9043\n",
      "Epoch 117/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1413 - accuracy: 0.9456 - val_loss: 0.2451 - val_accuracy: 0.9154\n",
      "Epoch 118/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1361 - accuracy: 0.9470 - val_loss: 0.2794 - val_accuracy: 0.9039\n",
      "Epoch 119/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1358 - accuracy: 0.9470 - val_loss: 0.2604 - val_accuracy: 0.9146\n",
      "Epoch 120/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1367 - accuracy: 0.9451 - val_loss: 0.2479 - val_accuracy: 0.9154\n",
      "Epoch 121/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1322 - accuracy: 0.9485 - val_loss: 0.2388 - val_accuracy: 0.9199\n",
      "Epoch 122/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1364 - accuracy: 0.9459 - val_loss: 0.2557 - val_accuracy: 0.9128\n",
      "Epoch 123/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1337 - accuracy: 0.9471 - val_loss: 0.2661 - val_accuracy: 0.9110\n",
      "Epoch 124/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1379 - accuracy: 0.9445 - val_loss: 0.2484 - val_accuracy: 0.9168\n",
      "Epoch 125/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1269 - accuracy: 0.9498 - val_loss: 0.2428 - val_accuracy: 0.9203\n",
      "Epoch 126/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1271 - accuracy: 0.9509 - val_loss: 0.2646 - val_accuracy: 0.9119\n",
      "Epoch 127/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1261 - accuracy: 0.9486 - val_loss: 0.2508 - val_accuracy: 0.9154\n",
      "Epoch 128/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1223 - accuracy: 0.9505 - val_loss: 0.2194 - val_accuracy: 0.9239\n",
      "Epoch 129/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1310 - accuracy: 0.9484 - val_loss: 0.2546 - val_accuracy: 0.9221\n",
      "Epoch 130/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1244 - accuracy: 0.9500 - val_loss: 0.2698 - val_accuracy: 0.9163\n",
      "Epoch 131/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1200 - accuracy: 0.9514 - val_loss: 0.3240 - val_accuracy: 0.8972\n",
      "Epoch 132/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1295 - accuracy: 0.9491 - val_loss: 0.2579 - val_accuracy: 0.9194\n",
      "Epoch 133/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1191 - accuracy: 0.9531 - val_loss: 0.2378 - val_accuracy: 0.9194\n",
      "Epoch 134/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1223 - accuracy: 0.9536 - val_loss: 0.2529 - val_accuracy: 0.9123\n",
      "Epoch 135/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1281 - accuracy: 0.9493 - val_loss: 0.2516 - val_accuracy: 0.9194\n",
      "Epoch 136/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1203 - accuracy: 0.9518 - val_loss: 0.2622 - val_accuracy: 0.9105\n",
      "Epoch 137/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1208 - accuracy: 0.9517 - val_loss: 0.2333 - val_accuracy: 0.9217\n",
      "Epoch 138/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1170 - accuracy: 0.9529 - val_loss: 0.2384 - val_accuracy: 0.9243\n",
      "Epoch 139/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1258 - accuracy: 0.9479 - val_loss: 0.2324 - val_accuracy: 0.9235\n",
      "Epoch 140/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1170 - accuracy: 0.9526 - val_loss: 0.2352 - val_accuracy: 0.9208\n",
      "Epoch 141/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.1217 - accuracy: 0.9530 - val_loss: 0.2914 - val_accuracy: 0.9008\n",
      "Epoch 142/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.1268 - accuracy: 0.9491 - val_loss: 0.2583 - val_accuracy: 0.9119\n",
      "Epoch 143/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1236 - accuracy: 0.9509 - val_loss: 0.2364 - val_accuracy: 0.9261\n",
      "Epoch 144/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1198 - accuracy: 0.9523 - val_loss: 0.2533 - val_accuracy: 0.9154\n",
      "Epoch 145/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1165 - accuracy: 0.9543 - val_loss: 0.2414 - val_accuracy: 0.9154\n",
      "Epoch 146/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.1187 - accuracy: 0.9546 - val_loss: 0.3098 - val_accuracy: 0.8883\n",
      "Epoch 147/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.2289 - val_accuracy: 0.9243\n",
      "Epoch 148/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1134 - accuracy: 0.9553 - val_loss: 0.2307 - val_accuracy: 0.9239\n",
      "Epoch 149/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.1189 - accuracy: 0.9534 - val_loss: 0.2728 - val_accuracy: 0.9074\n",
      "Epoch 150/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1078 - accuracy: 0.9564 - val_loss: 0.2577 - val_accuracy: 0.9190\n",
      "Epoch 151/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1137 - accuracy: 0.9540 - val_loss: 0.2424 - val_accuracy: 0.9186\n",
      "Epoch 152/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1099 - accuracy: 0.9557 - val_loss: 0.2517 - val_accuracy: 0.9221\n",
      "Epoch 153/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1105 - accuracy: 0.9580 - val_loss: 0.2463 - val_accuracy: 0.9288\n",
      "Epoch 154/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1155 - accuracy: 0.9557 - val_loss: 0.2461 - val_accuracy: 0.9217\n",
      "Epoch 155/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1142 - accuracy: 0.9559 - val_loss: 0.2890 - val_accuracy: 0.9061\n",
      "Epoch 156/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1087 - accuracy: 0.9578 - val_loss: 0.2380 - val_accuracy: 0.9217\n",
      "Epoch 157/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1137 - accuracy: 0.9559 - val_loss: 0.2460 - val_accuracy: 0.9226\n",
      "Epoch 158/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1187 - accuracy: 0.9542 - val_loss: 0.2629 - val_accuracy: 0.9203\n",
      "Epoch 159/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1093 - accuracy: 0.9587 - val_loss: 0.2762 - val_accuracy: 0.9092\n",
      "Epoch 160/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.1076 - accuracy: 0.9590 - val_loss: 0.2745 - val_accuracy: 0.9097\n",
      "Epoch 161/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1085 - accuracy: 0.9587 - val_loss: 0.2474 - val_accuracy: 0.9239\n",
      "Epoch 162/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1043 - accuracy: 0.9586 - val_loss: 0.3081 - val_accuracy: 0.9012\n",
      "Epoch 163/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1047 - accuracy: 0.9582 - val_loss: 0.2453 - val_accuracy: 0.9332\n",
      "Epoch 164/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1114 - accuracy: 0.9559 - val_loss: 0.2599 - val_accuracy: 0.9177\n",
      "Epoch 165/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1073 - accuracy: 0.9570 - val_loss: 0.2683 - val_accuracy: 0.9083\n",
      "Epoch 166/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1071 - accuracy: 0.9589 - val_loss: 0.2686 - val_accuracy: 0.9172\n",
      "Epoch 167/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1006 - accuracy: 0.9613 - val_loss: 0.3278 - val_accuracy: 0.8852\n",
      "Epoch 168/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1040 - accuracy: 0.9584 - val_loss: 0.2597 - val_accuracy: 0.9172\n",
      "Epoch 169/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1085 - accuracy: 0.9580 - val_loss: 0.2498 - val_accuracy: 0.9226\n",
      "Epoch 170/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1034 - accuracy: 0.9597 - val_loss: 0.2685 - val_accuracy: 0.9221\n",
      "Epoch 171/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1068 - accuracy: 0.9584 - val_loss: 0.2806 - val_accuracy: 0.9186\n",
      "Epoch 172/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0969 - accuracy: 0.9629 - val_loss: 0.2453 - val_accuracy: 0.9208\n",
      "Epoch 173/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0997 - accuracy: 0.9623 - val_loss: 0.2760 - val_accuracy: 0.9257\n",
      "Epoch 174/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1049 - accuracy: 0.9574 - val_loss: 0.2573 - val_accuracy: 0.9194\n",
      "Epoch 175/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0937 - accuracy: 0.9655 - val_loss: 0.3435 - val_accuracy: 0.9034\n",
      "Epoch 176/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1006 - accuracy: 0.9605 - val_loss: 0.2517 - val_accuracy: 0.9212\n",
      "Epoch 177/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0979 - accuracy: 0.9604 - val_loss: 0.2994 - val_accuracy: 0.9097\n",
      "Epoch 178/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0977 - accuracy: 0.9617 - val_loss: 0.2415 - val_accuracy: 0.9235\n",
      "Epoch 179/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1084 - accuracy: 0.9598 - val_loss: 0.2634 - val_accuracy: 0.9208\n",
      "Epoch 180/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1041 - accuracy: 0.9593 - val_loss: 0.2317 - val_accuracy: 0.9310\n",
      "Epoch 181/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1018 - accuracy: 0.9607 - val_loss: 0.2576 - val_accuracy: 0.9203\n",
      "Epoch 182/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0973 - accuracy: 0.9632 - val_loss: 0.2375 - val_accuracy: 0.9283\n",
      "Epoch 183/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0998 - accuracy: 0.9617 - val_loss: 0.2386 - val_accuracy: 0.9288\n",
      "Epoch 184/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0935 - accuracy: 0.9621 - val_loss: 0.2434 - val_accuracy: 0.9315\n",
      "Epoch 185/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0956 - accuracy: 0.9642 - val_loss: 0.2485 - val_accuracy: 0.9306\n",
      "Epoch 186/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0997 - accuracy: 0.9621 - val_loss: 0.2367 - val_accuracy: 0.9279\n",
      "Epoch 187/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0873 - accuracy: 0.9661 - val_loss: 0.2361 - val_accuracy: 0.9243\n",
      "Epoch 188/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0954 - accuracy: 0.9654 - val_loss: 0.2510 - val_accuracy: 0.9199\n",
      "Epoch 189/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1068 - accuracy: 0.9562 - val_loss: 0.2404 - val_accuracy: 0.9243\n",
      "Epoch 190/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0913 - accuracy: 0.9653 - val_loss: 0.2188 - val_accuracy: 0.9248\n",
      "Epoch 191/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0982 - accuracy: 0.9615 - val_loss: 0.2784 - val_accuracy: 0.9181\n",
      "Epoch 192/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0977 - accuracy: 0.9611 - val_loss: 0.2416 - val_accuracy: 0.9306\n",
      "Epoch 193/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0963 - accuracy: 0.9649 - val_loss: 0.2338 - val_accuracy: 0.9315\n",
      "Epoch 194/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0886 - accuracy: 0.9669 - val_loss: 0.2507 - val_accuracy: 0.9257\n",
      "Epoch 195/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0923 - accuracy: 0.9638 - val_loss: 0.2643 - val_accuracy: 0.9159\n",
      "Epoch 196/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0946 - accuracy: 0.9666 - val_loss: 0.2484 - val_accuracy: 0.9190\n",
      "Epoch 197/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0906 - accuracy: 0.9657 - val_loss: 0.2495 - val_accuracy: 0.9252\n",
      "Epoch 198/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0934 - accuracy: 0.9648 - val_loss: 0.2424 - val_accuracy: 0.9239\n",
      "Epoch 199/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0880 - accuracy: 0.9671 - val_loss: 0.2601 - val_accuracy: 0.9065\n",
      "Epoch 200/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0985 - accuracy: 0.9622 - val_loss: 0.2685 - val_accuracy: 0.9283\n",
      "Epoch 201/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0948 - accuracy: 0.9635 - val_loss: 0.2288 - val_accuracy: 0.9306\n",
      "Epoch 202/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0880 - accuracy: 0.9662 - val_loss: 0.2475 - val_accuracy: 0.9283\n",
      "Epoch 203/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0841 - accuracy: 0.9674 - val_loss: 0.2359 - val_accuracy: 0.9288\n",
      "Epoch 204/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0863 - accuracy: 0.9687 - val_loss: 0.2848 - val_accuracy: 0.9172\n",
      "Epoch 205/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0866 - accuracy: 0.9656 - val_loss: 0.2383 - val_accuracy: 0.9279\n",
      "Epoch 206/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0834 - accuracy: 0.9657 - val_loss: 0.2379 - val_accuracy: 0.9239\n",
      "Epoch 207/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0925 - accuracy: 0.9642 - val_loss: 0.2387 - val_accuracy: 0.9315\n",
      "Epoch 208/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0868 - accuracy: 0.9663 - val_loss: 0.2457 - val_accuracy: 0.9288\n",
      "Epoch 209/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0958 - accuracy: 0.9628 - val_loss: 0.2534 - val_accuracy: 0.9261\n",
      "Epoch 210/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0883 - accuracy: 0.9675 - val_loss: 0.2507 - val_accuracy: 0.9275\n",
      "Epoch 211/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0880 - accuracy: 0.9662 - val_loss: 0.2707 - val_accuracy: 0.9248\n",
      "Epoch 212/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0889 - accuracy: 0.9663 - val_loss: 0.2766 - val_accuracy: 0.9235\n",
      "Epoch 213/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0830 - accuracy: 0.9684 - val_loss: 0.2549 - val_accuracy: 0.9257\n",
      "Epoch 214/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0883 - accuracy: 0.9658 - val_loss: 0.2810 - val_accuracy: 0.9243\n",
      "Epoch 215/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0902 - accuracy: 0.9662 - val_loss: 0.2392 - val_accuracy: 0.9292\n",
      "Epoch 216/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0891 - accuracy: 0.9658 - val_loss: 0.2500 - val_accuracy: 0.9252\n",
      "Epoch 217/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0829 - accuracy: 0.9701 - val_loss: 0.2488 - val_accuracy: 0.9248\n",
      "Epoch 218/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0809 - accuracy: 0.9701 - val_loss: 0.2390 - val_accuracy: 0.9332\n",
      "Epoch 219/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0878 - accuracy: 0.9667 - val_loss: 0.2334 - val_accuracy: 0.9283\n",
      "Epoch 220/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0849 - accuracy: 0.9680 - val_loss: 0.2830 - val_accuracy: 0.9230\n",
      "Epoch 221/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0859 - accuracy: 0.9696 - val_loss: 0.2301 - val_accuracy: 0.9319\n",
      "Epoch 222/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0821 - accuracy: 0.9707 - val_loss: 0.2526 - val_accuracy: 0.9266\n",
      "Epoch 223/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0891 - accuracy: 0.9663 - val_loss: 0.2534 - val_accuracy: 0.9239\n",
      "Epoch 224/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0800 - accuracy: 0.9695 - val_loss: 0.2425 - val_accuracy: 0.9319\n",
      "Epoch 225/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0850 - accuracy: 0.9672 - val_loss: 0.2540 - val_accuracy: 0.9324\n",
      "Epoch 226/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0870 - accuracy: 0.9676 - val_loss: 0.3060 - val_accuracy: 0.9146\n",
      "Epoch 227/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0826 - accuracy: 0.9675 - val_loss: 0.2629 - val_accuracy: 0.9243\n",
      "Epoch 228/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0801 - accuracy: 0.9722 - val_loss: 0.3018 - val_accuracy: 0.9132\n",
      "Epoch 229/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0869 - accuracy: 0.9652 - val_loss: 0.3047 - val_accuracy: 0.9252\n",
      "Epoch 230/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0737 - accuracy: 0.9725 - val_loss: 0.2403 - val_accuracy: 0.9297\n",
      "Epoch 231/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0752 - accuracy: 0.9716 - val_loss: 0.2372 - val_accuracy: 0.9283\n",
      "Epoch 232/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0867 - accuracy: 0.9655 - val_loss: 0.2665 - val_accuracy: 0.9328\n",
      "Epoch 233/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0817 - accuracy: 0.9675 - val_loss: 0.2666 - val_accuracy: 0.9252\n",
      "Epoch 234/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0781 - accuracy: 0.9716 - val_loss: 0.2661 - val_accuracy: 0.9163\n",
      "Epoch 235/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0817 - accuracy: 0.9690 - val_loss: 0.2563 - val_accuracy: 0.9288\n",
      "Epoch 236/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0783 - accuracy: 0.9724 - val_loss: 0.2445 - val_accuracy: 0.9319\n",
      "Epoch 237/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0822 - accuracy: 0.9685 - val_loss: 0.2533 - val_accuracy: 0.9306\n",
      "Epoch 238/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0797 - accuracy: 0.9692 - val_loss: 0.2534 - val_accuracy: 0.9319\n",
      "Epoch 239/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0764 - accuracy: 0.9714 - val_loss: 0.2562 - val_accuracy: 0.9279\n",
      "Epoch 240/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0758 - accuracy: 0.9717 - val_loss: 0.3057 - val_accuracy: 0.9275\n",
      "Epoch 241/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0750 - accuracy: 0.9714 - val_loss: 0.3146 - val_accuracy: 0.9123\n",
      "Epoch 242/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0856 - accuracy: 0.9681 - val_loss: 0.2860 - val_accuracy: 0.9275\n",
      "Epoch 243/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0756 - accuracy: 0.9706 - val_loss: 0.2940 - val_accuracy: 0.9097\n",
      "Epoch 244/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0827 - accuracy: 0.9685 - val_loss: 0.2564 - val_accuracy: 0.9292\n",
      "Epoch 245/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0803 - accuracy: 0.9700 - val_loss: 0.2520 - val_accuracy: 0.9283\n",
      "Epoch 246/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0727 - accuracy: 0.9722 - val_loss: 0.2603 - val_accuracy: 0.9292\n",
      "Epoch 247/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0762 - accuracy: 0.9714 - val_loss: 0.2473 - val_accuracy: 0.9332\n",
      "Epoch 248/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0852 - accuracy: 0.9701 - val_loss: 0.2389 - val_accuracy: 0.9217\n",
      "Epoch 249/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0738 - accuracy: 0.9735 - val_loss: 0.2556 - val_accuracy: 0.9279\n",
      "Epoch 250/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0721 - accuracy: 0.9732 - val_loss: 0.2812 - val_accuracy: 0.9310\n",
      "Epoch 251/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0724 - accuracy: 0.9725 - val_loss: 0.3001 - val_accuracy: 0.9221\n",
      "Epoch 252/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0765 - accuracy: 0.9712 - val_loss: 0.2749 - val_accuracy: 0.9270\n",
      "Epoch 253/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0686 - accuracy: 0.9741 - val_loss: 0.2936 - val_accuracy: 0.9243\n",
      "Epoch 254/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0788 - accuracy: 0.9701 - val_loss: 0.2555 - val_accuracy: 0.9319\n",
      "Epoch 255/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0745 - accuracy: 0.9716 - val_loss: 0.2726 - val_accuracy: 0.9324\n",
      "Epoch 256/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0687 - accuracy: 0.9752 - val_loss: 0.2757 - val_accuracy: 0.9283\n",
      "Epoch 257/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0800 - accuracy: 0.9702 - val_loss: 0.2295 - val_accuracy: 0.9306\n",
      "Epoch 258/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0760 - accuracy: 0.9688 - val_loss: 0.2843 - val_accuracy: 0.9203\n",
      "Epoch 259/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0710 - accuracy: 0.9727 - val_loss: 0.2752 - val_accuracy: 0.9275\n",
      "Epoch 260/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0740 - accuracy: 0.9727 - val_loss: 0.2730 - val_accuracy: 0.9283\n",
      "Epoch 261/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0667 - accuracy: 0.9750 - val_loss: 0.2518 - val_accuracy: 0.9341\n",
      "Epoch 262/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.2779 - val_accuracy: 0.9270\n",
      "Epoch 263/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0745 - accuracy: 0.9721 - val_loss: 0.2686 - val_accuracy: 0.9310\n",
      "Epoch 264/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0702 - accuracy: 0.9713 - val_loss: 0.2415 - val_accuracy: 0.9310\n",
      "Epoch 265/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0683 - accuracy: 0.9720 - val_loss: 0.2609 - val_accuracy: 0.9324\n",
      "Epoch 266/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0673 - accuracy: 0.9738 - val_loss: 0.2518 - val_accuracy: 0.9261\n",
      "Epoch 267/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0698 - accuracy: 0.9726 - val_loss: 0.2742 - val_accuracy: 0.9172\n",
      "Epoch 268/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0744 - accuracy: 0.9720 - val_loss: 0.2435 - val_accuracy: 0.9310\n",
      "Epoch 269/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0698 - accuracy: 0.9732 - val_loss: 0.2708 - val_accuracy: 0.9283\n",
      "Epoch 270/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0665 - accuracy: 0.9754 - val_loss: 0.2607 - val_accuracy: 0.9279\n",
      "Epoch 271/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0623 - accuracy: 0.9759 - val_loss: 0.2577 - val_accuracy: 0.9324\n",
      "Epoch 272/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0684 - accuracy: 0.9747 - val_loss: 0.2979 - val_accuracy: 0.9301\n",
      "Epoch 273/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0663 - accuracy: 0.9747 - val_loss: 0.2645 - val_accuracy: 0.9190\n",
      "Epoch 274/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0687 - accuracy: 0.9754 - val_loss: 0.2992 - val_accuracy: 0.9257\n",
      "Epoch 275/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0711 - accuracy: 0.9718 - val_loss: 0.2768 - val_accuracy: 0.9324\n",
      "Epoch 276/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.2905 - val_accuracy: 0.9292\n",
      "Epoch 277/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0680 - accuracy: 0.9751 - val_loss: 0.2920 - val_accuracy: 0.9226\n",
      "Epoch 278/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0684 - accuracy: 0.9742 - val_loss: 0.2693 - val_accuracy: 0.9301\n",
      "Epoch 279/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0618 - accuracy: 0.9766 - val_loss: 0.2901 - val_accuracy: 0.9261\n",
      "Epoch 280/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0730 - accuracy: 0.9724 - val_loss: 0.3213 - val_accuracy: 0.9301\n",
      "Epoch 281/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0700 - accuracy: 0.9747 - val_loss: 0.2739 - val_accuracy: 0.9315\n",
      "Epoch 282/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0653 - accuracy: 0.9736 - val_loss: 0.2776 - val_accuracy: 0.9324\n",
      "Epoch 283/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0692 - accuracy: 0.9745 - val_loss: 0.2689 - val_accuracy: 0.9315\n",
      "Epoch 284/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0734 - accuracy: 0.9734 - val_loss: 0.2633 - val_accuracy: 0.9275\n",
      "Epoch 285/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0710 - accuracy: 0.9738 - val_loss: 0.2787 - val_accuracy: 0.9288\n",
      "Epoch 286/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0734 - accuracy: 0.9733 - val_loss: 0.2682 - val_accuracy: 0.9341\n",
      "Epoch 287/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0618 - accuracy: 0.9770 - val_loss: 0.3387 - val_accuracy: 0.9235\n",
      "Epoch 288/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0652 - accuracy: 0.9779 - val_loss: 0.2787 - val_accuracy: 0.9252\n",
      "Epoch 289/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0692 - accuracy: 0.9731 - val_loss: 0.2499 - val_accuracy: 0.9332\n",
      "Epoch 290/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.0653 - accuracy: 0.9760 - val_loss: 0.2568 - val_accuracy: 0.9337\n",
      "Epoch 291/500\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.0700 - accuracy: 0.9760 - val_loss: 0.2591 - val_accuracy: 0.9315\n",
      "Epoch 292/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0656 - accuracy: 0.9774 - val_loss: 0.3159 - val_accuracy: 0.9288\n",
      "Epoch 293/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0698 - accuracy: 0.9750 - val_loss: 0.2911 - val_accuracy: 0.9239\n",
      "Epoch 294/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0622 - accuracy: 0.9762 - val_loss: 0.2775 - val_accuracy: 0.9275\n",
      "Epoch 295/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0569 - accuracy: 0.9781 - val_loss: 0.2526 - val_accuracy: 0.9310\n",
      "Epoch 296/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0617 - accuracy: 0.9767 - val_loss: 0.2813 - val_accuracy: 0.9226\n",
      "Epoch 297/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0676 - accuracy: 0.9740 - val_loss: 0.2546 - val_accuracy: 0.9355\n",
      "Epoch 298/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0632 - accuracy: 0.9759 - val_loss: 0.2915 - val_accuracy: 0.9306\n",
      "Epoch 299/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0652 - accuracy: 0.9743 - val_loss: 0.2837 - val_accuracy: 0.9292\n",
      "Epoch 300/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0542 - accuracy: 0.9802 - val_loss: 0.2774 - val_accuracy: 0.9275\n",
      "Epoch 301/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0677 - accuracy: 0.9721 - val_loss: 0.2565 - val_accuracy: 0.9381\n",
      "Epoch 302/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 0.2644 - val_accuracy: 0.9332\n",
      "Epoch 303/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0650 - accuracy: 0.9753 - val_loss: 0.2760 - val_accuracy: 0.9328\n",
      "Epoch 304/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0615 - accuracy: 0.9780 - val_loss: 0.3070 - val_accuracy: 0.9248\n",
      "Epoch 305/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0667 - accuracy: 0.9755 - val_loss: 0.3031 - val_accuracy: 0.9203\n",
      "Epoch 306/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0685 - accuracy: 0.9742 - val_loss: 0.2684 - val_accuracy: 0.9350\n",
      "Epoch 307/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0512 - accuracy: 0.9817 - val_loss: 0.2636 - val_accuracy: 0.9346\n",
      "Epoch 308/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0657 - accuracy: 0.9752 - val_loss: 0.2956 - val_accuracy: 0.9172\n",
      "Epoch 309/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0601 - accuracy: 0.9767 - val_loss: 0.2679 - val_accuracy: 0.9368\n",
      "Epoch 310/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0590 - accuracy: 0.9784 - val_loss: 0.2901 - val_accuracy: 0.9315\n",
      "Epoch 311/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0665 - accuracy: 0.9746 - val_loss: 0.2517 - val_accuracy: 0.9315\n",
      "Epoch 312/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0544 - accuracy: 0.9791 - val_loss: 0.3083 - val_accuracy: 0.9168\n",
      "Epoch 313/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0633 - accuracy: 0.9769 - val_loss: 0.2767 - val_accuracy: 0.9275\n",
      "Epoch 314/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0615 - accuracy: 0.9781 - val_loss: 0.2842 - val_accuracy: 0.9337\n",
      "Epoch 315/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0576 - accuracy: 0.9767 - val_loss: 0.2906 - val_accuracy: 0.9266\n",
      "Epoch 316/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0564 - accuracy: 0.9777 - val_loss: 0.2610 - val_accuracy: 0.9288\n",
      "Epoch 317/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0548 - accuracy: 0.9794 - val_loss: 0.3116 - val_accuracy: 0.9283\n",
      "Epoch 318/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0651 - accuracy: 0.9756 - val_loss: 0.2971 - val_accuracy: 0.9248\n",
      "Epoch 319/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0639 - accuracy: 0.9759 - val_loss: 0.2989 - val_accuracy: 0.9310\n",
      "Epoch 320/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0555 - accuracy: 0.9777 - val_loss: 0.2635 - val_accuracy: 0.9310\n",
      "Epoch 321/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0614 - accuracy: 0.9767 - val_loss: 0.3129 - val_accuracy: 0.9306\n",
      "Epoch 322/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0599 - accuracy: 0.9775 - val_loss: 0.2594 - val_accuracy: 0.9350\n",
      "Epoch 323/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0567 - accuracy: 0.9776 - val_loss: 0.2942 - val_accuracy: 0.9292\n",
      "Epoch 324/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0624 - accuracy: 0.9760 - val_loss: 0.2617 - val_accuracy: 0.9252\n",
      "Epoch 325/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0526 - accuracy: 0.9804 - val_loss: 0.3170 - val_accuracy: 0.9306\n",
      "Epoch 326/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0626 - accuracy: 0.9759 - val_loss: 0.2830 - val_accuracy: 0.9332\n",
      "Epoch 327/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.2789 - val_accuracy: 0.9319\n",
      "Epoch 328/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0576 - accuracy: 0.9794 - val_loss: 0.2561 - val_accuracy: 0.9341\n",
      "Epoch 329/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0470 - accuracy: 0.9820 - val_loss: 0.2780 - val_accuracy: 0.9310\n",
      "Epoch 330/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0603 - accuracy: 0.9775 - val_loss: 0.3166 - val_accuracy: 0.9239\n",
      "Epoch 331/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0672 - accuracy: 0.9761 - val_loss: 0.2969 - val_accuracy: 0.9248\n",
      "Epoch 332/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0534 - accuracy: 0.9794 - val_loss: 0.2709 - val_accuracy: 0.9346\n",
      "Epoch 333/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0606 - accuracy: 0.9764 - val_loss: 0.2938 - val_accuracy: 0.9337\n",
      "Epoch 334/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 0.2771 - val_accuracy: 0.9372\n",
      "Epoch 335/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0543 - accuracy: 0.9797 - val_loss: 0.2590 - val_accuracy: 0.9337\n",
      "Epoch 336/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0534 - accuracy: 0.9797 - val_loss: 0.2744 - val_accuracy: 0.9257\n",
      "Epoch 337/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0578 - accuracy: 0.9782 - val_loss: 0.2886 - val_accuracy: 0.9297\n",
      "Epoch 338/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 0.2812 - val_accuracy: 0.9261\n",
      "Epoch 339/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0527 - accuracy: 0.9783 - val_loss: 0.2808 - val_accuracy: 0.9292\n",
      "Epoch 340/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0504 - accuracy: 0.9787 - val_loss: 0.3001 - val_accuracy: 0.9319\n",
      "Epoch 341/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0637 - accuracy: 0.9761 - val_loss: 0.2990 - val_accuracy: 0.9346\n",
      "Epoch 342/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0554 - accuracy: 0.9804 - val_loss: 0.2817 - val_accuracy: 0.9346\n",
      "Epoch 343/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0588 - accuracy: 0.9782 - val_loss: 0.3489 - val_accuracy: 0.9172\n",
      "Epoch 344/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0593 - accuracy: 0.9801 - val_loss: 0.4314 - val_accuracy: 0.9101\n",
      "Epoch 345/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0504 - accuracy: 0.9801 - val_loss: 0.2686 - val_accuracy: 0.9212\n",
      "Epoch 346/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0510 - accuracy: 0.9806 - val_loss: 0.2613 - val_accuracy: 0.9292\n",
      "Epoch 347/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0607 - accuracy: 0.9766 - val_loss: 0.3181 - val_accuracy: 0.9243\n",
      "Epoch 348/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0522 - accuracy: 0.9802 - val_loss: 0.2956 - val_accuracy: 0.9319\n",
      "Epoch 349/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0561 - accuracy: 0.9789 - val_loss: 0.3194 - val_accuracy: 0.9310\n",
      "Epoch 350/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0510 - accuracy: 0.9800 - val_loss: 0.3245 - val_accuracy: 0.9310\n",
      "Epoch 351/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0531 - accuracy: 0.9820 - val_loss: 0.2887 - val_accuracy: 0.9337\n",
      "Epoch 352/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0529 - accuracy: 0.9792 - val_loss: 0.2988 - val_accuracy: 0.9257\n",
      "Epoch 353/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0467 - accuracy: 0.9834 - val_loss: 0.2858 - val_accuracy: 0.9315\n",
      "Epoch 354/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0464 - accuracy: 0.9817 - val_loss: 0.3132 - val_accuracy: 0.9324\n",
      "Epoch 355/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0552 - accuracy: 0.9819 - val_loss: 0.2863 - val_accuracy: 0.9275\n",
      "Epoch 356/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0542 - accuracy: 0.9803 - val_loss: 0.3006 - val_accuracy: 0.9310\n",
      "Epoch 357/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0461 - accuracy: 0.9821 - val_loss: 0.3023 - val_accuracy: 0.9306\n",
      "Epoch 358/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0520 - accuracy: 0.9806 - val_loss: 0.2698 - val_accuracy: 0.9337\n",
      "Epoch 359/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0561 - accuracy: 0.9770 - val_loss: 0.2761 - val_accuracy: 0.9332\n",
      "Epoch 360/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 0.3045 - val_accuracy: 0.9297\n",
      "Epoch 361/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.3242 - val_accuracy: 0.9283\n",
      "Epoch 362/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0498 - accuracy: 0.9804 - val_loss: 0.2935 - val_accuracy: 0.9257\n",
      "Epoch 363/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0578 - accuracy: 0.9791 - val_loss: 0.2886 - val_accuracy: 0.9283\n",
      "Epoch 364/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0587 - accuracy: 0.9785 - val_loss: 0.2720 - val_accuracy: 0.9315\n",
      "Epoch 365/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0485 - accuracy: 0.9817 - val_loss: 0.2976 - val_accuracy: 0.9270\n",
      "Epoch 366/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 0.2706 - val_accuracy: 0.9355\n",
      "Epoch 367/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0417 - accuracy: 0.9844 - val_loss: 0.2737 - val_accuracy: 0.9332\n",
      "Epoch 368/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0663 - accuracy: 0.9759 - val_loss: 0.2957 - val_accuracy: 0.9310\n",
      "Epoch 369/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0516 - accuracy: 0.9802 - val_loss: 0.3128 - val_accuracy: 0.9350\n",
      "Epoch 370/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0447 - accuracy: 0.9835 - val_loss: 0.3450 - val_accuracy: 0.9328\n",
      "Epoch 371/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0557 - accuracy: 0.9794 - val_loss: 0.2979 - val_accuracy: 0.9292\n",
      "Epoch 372/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0451 - accuracy: 0.9824 - val_loss: 0.2703 - val_accuracy: 0.9364\n",
      "Epoch 373/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0489 - accuracy: 0.9819 - val_loss: 0.3165 - val_accuracy: 0.9283\n",
      "Epoch 374/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 0.2979 - val_accuracy: 0.9301\n",
      "Epoch 375/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0498 - accuracy: 0.9813 - val_loss: 0.3185 - val_accuracy: 0.9301\n",
      "Epoch 376/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0516 - accuracy: 0.9793 - val_loss: 0.2856 - val_accuracy: 0.9359\n",
      "Epoch 377/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0510 - accuracy: 0.9814 - val_loss: 0.4906 - val_accuracy: 0.9163\n",
      "Epoch 378/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0574 - accuracy: 0.9792 - val_loss: 0.2785 - val_accuracy: 0.9301\n",
      "Epoch 379/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0416 - accuracy: 0.9852 - val_loss: 0.3044 - val_accuracy: 0.9337\n",
      "Epoch 380/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.3387 - val_accuracy: 0.9306\n",
      "Epoch 381/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0423 - accuracy: 0.9839 - val_loss: 0.3975 - val_accuracy: 0.9252\n",
      "Epoch 382/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0651 - accuracy: 0.9752 - val_loss: 0.2638 - val_accuracy: 0.9319\n",
      "Epoch 383/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0447 - accuracy: 0.9841 - val_loss: 0.2791 - val_accuracy: 0.9306\n",
      "Epoch 384/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 0.2890 - val_accuracy: 0.9324\n",
      "Epoch 385/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.2863 - val_accuracy: 0.9261\n",
      "Epoch 386/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0470 - accuracy: 0.9821 - val_loss: 0.3067 - val_accuracy: 0.9346\n",
      "Epoch 387/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.3207 - val_accuracy: 0.9279\n",
      "Epoch 388/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.2734 - val_accuracy: 0.9364\n",
      "Epoch 389/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0398 - accuracy: 0.9840 - val_loss: 0.2855 - val_accuracy: 0.9337\n",
      "Epoch 390/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0384 - accuracy: 0.9851 - val_loss: 0.3438 - val_accuracy: 0.9319\n",
      "Epoch 391/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0456 - accuracy: 0.9828 - val_loss: 0.2720 - val_accuracy: 0.9355\n",
      "Epoch 392/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0488 - accuracy: 0.9826 - val_loss: 0.3578 - val_accuracy: 0.9297\n",
      "Epoch 393/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0541 - accuracy: 0.9803 - val_loss: 0.3801 - val_accuracy: 0.9283\n",
      "Epoch 394/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0491 - accuracy: 0.9810 - val_loss: 0.3098 - val_accuracy: 0.9319\n",
      "Epoch 395/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0429 - accuracy: 0.9834 - val_loss: 0.3192 - val_accuracy: 0.9306\n",
      "Epoch 396/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0513 - accuracy: 0.9822 - val_loss: 0.3126 - val_accuracy: 0.9306\n",
      "Epoch 397/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0397 - accuracy: 0.9843 - val_loss: 0.4912 - val_accuracy: 0.9128\n",
      "Epoch 398/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0440 - accuracy: 0.9836 - val_loss: 0.3381 - val_accuracy: 0.9341\n",
      "Epoch 399/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0511 - accuracy: 0.9817 - val_loss: 0.2733 - val_accuracy: 0.9355\n",
      "Epoch 400/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 0.2779 - val_accuracy: 0.9372\n",
      "Epoch 401/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0446 - accuracy: 0.9832 - val_loss: 0.3312 - val_accuracy: 0.9324\n",
      "Epoch 402/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.4752 - val_accuracy: 0.9203\n",
      "Epoch 403/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0456 - accuracy: 0.9838 - val_loss: 0.2948 - val_accuracy: 0.9306\n",
      "Epoch 404/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0457 - accuracy: 0.9841 - val_loss: 0.3467 - val_accuracy: 0.9266\n",
      "Epoch 405/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.2843 - val_accuracy: 0.9332\n",
      "Epoch 406/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0400 - accuracy: 0.9856 - val_loss: 0.3211 - val_accuracy: 0.9270\n",
      "Epoch 407/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 0.3236 - val_accuracy: 0.9301\n",
      "Epoch 408/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0395 - accuracy: 0.9854 - val_loss: 0.3812 - val_accuracy: 0.9226\n",
      "Epoch 409/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0512 - accuracy: 0.9803 - val_loss: 0.3153 - val_accuracy: 0.9257\n",
      "Epoch 410/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.3047 - val_accuracy: 0.9372\n",
      "Epoch 411/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0399 - accuracy: 0.9841 - val_loss: 0.3297 - val_accuracy: 0.9328\n",
      "Epoch 412/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0440 - accuracy: 0.9844 - val_loss: 0.3659 - val_accuracy: 0.9306\n",
      "Epoch 413/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0414 - accuracy: 0.9828 - val_loss: 0.3407 - val_accuracy: 0.9212\n",
      "Epoch 414/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0422 - accuracy: 0.9841 - val_loss: 0.3318 - val_accuracy: 0.9315\n",
      "Epoch 415/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0418 - accuracy: 0.9832 - val_loss: 0.3654 - val_accuracy: 0.9275\n",
      "Epoch 416/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0421 - accuracy: 0.9835 - val_loss: 0.3192 - val_accuracy: 0.9319\n",
      "Epoch 417/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0454 - accuracy: 0.9833 - val_loss: 0.3579 - val_accuracy: 0.9279\n",
      "Epoch 418/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0426 - accuracy: 0.9835 - val_loss: 0.3033 - val_accuracy: 0.9364\n",
      "Epoch 419/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0436 - accuracy: 0.9849 - val_loss: 0.3016 - val_accuracy: 0.9341\n",
      "Epoch 420/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 0.3024 - val_accuracy: 0.9297\n",
      "Epoch 421/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0409 - accuracy: 0.9852 - val_loss: 0.3166 - val_accuracy: 0.9341\n",
      "Epoch 422/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0322 - accuracy: 0.9875 - val_loss: 0.3242 - val_accuracy: 0.9283\n",
      "Epoch 423/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0490 - accuracy: 0.9815 - val_loss: 0.3410 - val_accuracy: 0.9292\n",
      "Epoch 424/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: 0.3196 - val_accuracy: 0.9359\n",
      "Epoch 425/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0403 - accuracy: 0.9838 - val_loss: 0.3177 - val_accuracy: 0.9341\n",
      "Epoch 426/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0503 - accuracy: 0.9807 - val_loss: 0.3041 - val_accuracy: 0.9324\n",
      "Epoch 427/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0399 - accuracy: 0.9864 - val_loss: 0.3203 - val_accuracy: 0.9355\n",
      "Epoch 428/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.3143 - val_accuracy: 0.9368\n",
      "Epoch 429/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0360 - accuracy: 0.9868 - val_loss: 0.3293 - val_accuracy: 0.9315\n",
      "Epoch 430/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0417 - accuracy: 0.9845 - val_loss: 0.3514 - val_accuracy: 0.9239\n",
      "Epoch 431/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0517 - accuracy: 0.9819 - val_loss: 0.3149 - val_accuracy: 0.9368\n",
      "Epoch 432/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.3124 - val_accuracy: 0.9359\n",
      "Epoch 433/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0338 - accuracy: 0.9872 - val_loss: 0.4072 - val_accuracy: 0.9012\n",
      "Epoch 434/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0370 - accuracy: 0.9864 - val_loss: 0.3232 - val_accuracy: 0.9364\n",
      "Epoch 435/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.3453 - val_accuracy: 0.9288\n",
      "Epoch 436/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0399 - accuracy: 0.9848 - val_loss: 0.3451 - val_accuracy: 0.9315\n",
      "Epoch 437/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.3826 - val_accuracy: 0.9310\n",
      "Epoch 438/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0395 - accuracy: 0.9860 - val_loss: 0.3034 - val_accuracy: 0.9377\n",
      "Epoch 439/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.3173 - val_accuracy: 0.9194\n",
      "Epoch 440/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.3041 - val_accuracy: 0.9306\n",
      "Epoch 441/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0492 - accuracy: 0.9829 - val_loss: 0.3001 - val_accuracy: 0.9341\n",
      "Epoch 442/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0401 - accuracy: 0.9860 - val_loss: 0.3013 - val_accuracy: 0.9319\n",
      "Epoch 443/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0416 - accuracy: 0.9832 - val_loss: 0.2870 - val_accuracy: 0.9404\n",
      "Epoch 444/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0385 - accuracy: 0.9856 - val_loss: 0.3168 - val_accuracy: 0.9337\n",
      "Epoch 445/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0394 - accuracy: 0.9851 - val_loss: 0.3004 - val_accuracy: 0.9355\n",
      "Epoch 446/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.3204 - val_accuracy: 0.9372\n",
      "Epoch 447/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.3316 - val_accuracy: 0.9310\n",
      "Epoch 448/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0419 - accuracy: 0.9850 - val_loss: 0.3136 - val_accuracy: 0.9341\n",
      "Epoch 449/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0342 - accuracy: 0.9881 - val_loss: 0.2923 - val_accuracy: 0.9332\n",
      "Epoch 450/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0357 - accuracy: 0.9870 - val_loss: 0.3163 - val_accuracy: 0.9226\n",
      "Epoch 451/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0399 - accuracy: 0.9843 - val_loss: 0.2959 - val_accuracy: 0.9297\n",
      "Epoch 452/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.3312 - val_accuracy: 0.9315\n",
      "Epoch 453/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 0.3009 - val_accuracy: 0.9324\n",
      "Epoch 454/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.2836 - val_accuracy: 0.9386\n",
      "Epoch 455/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.3165 - val_accuracy: 0.9359\n",
      "Epoch 456/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0351 - accuracy: 0.9866 - val_loss: 0.3884 - val_accuracy: 0.9341\n",
      "Epoch 457/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.3063 - val_accuracy: 0.9341\n",
      "Epoch 458/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 0.3407 - val_accuracy: 0.9243\n",
      "Epoch 459/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0340 - accuracy: 0.9865 - val_loss: 0.3322 - val_accuracy: 0.9364\n",
      "Epoch 460/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 0.3214 - val_accuracy: 0.9292\n",
      "Epoch 461/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0346 - accuracy: 0.9870 - val_loss: 0.3544 - val_accuracy: 0.9292\n",
      "Epoch 462/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 0.3196 - val_accuracy: 0.9337\n",
      "Epoch 463/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.3314 - val_accuracy: 0.9377\n",
      "Epoch 464/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 0.3487 - val_accuracy: 0.9235\n",
      "Epoch 465/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0361 - accuracy: 0.9872 - val_loss: 0.3786 - val_accuracy: 0.9332\n",
      "Epoch 466/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.2916 - val_accuracy: 0.9332\n",
      "Epoch 467/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.3410 - val_accuracy: 0.9279\n",
      "Epoch 468/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0346 - accuracy: 0.9866 - val_loss: 0.3347 - val_accuracy: 0.9283\n",
      "Epoch 469/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0353 - accuracy: 0.9866 - val_loss: 0.3045 - val_accuracy: 0.9355\n",
      "Epoch 470/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0363 - accuracy: 0.9869 - val_loss: 0.3492 - val_accuracy: 0.9364\n",
      "Epoch 471/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0352 - accuracy: 0.9873 - val_loss: 0.3345 - val_accuracy: 0.9306\n",
      "Epoch 472/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0362 - accuracy: 0.9861 - val_loss: 0.3282 - val_accuracy: 0.9306\n",
      "Epoch 473/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0300 - accuracy: 0.9891 - val_loss: 0.3565 - val_accuracy: 0.9288\n",
      "Epoch 474/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 0.3016 - val_accuracy: 0.9359\n",
      "Epoch 475/500\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.0433 - accuracy: 0.9842 - val_loss: 0.3340 - val_accuracy: 0.9306\n",
      "Epoch 476/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0318 - accuracy: 0.9869 - val_loss: 0.3062 - val_accuracy: 0.9355\n",
      "Epoch 477/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.3328 - val_accuracy: 0.9266\n",
      "Epoch 478/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0350 - accuracy: 0.9876 - val_loss: 0.3134 - val_accuracy: 0.9332\n",
      "Epoch 479/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.3309 - val_accuracy: 0.9221\n",
      "Epoch 480/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0408 - accuracy: 0.9844 - val_loss: 0.3542 - val_accuracy: 0.9283\n",
      "Epoch 481/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0348 - accuracy: 0.9869 - val_loss: 0.3047 - val_accuracy: 0.9346\n",
      "Epoch 482/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0303 - accuracy: 0.9883 - val_loss: 0.3063 - val_accuracy: 0.9315\n",
      "Epoch 483/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.3627 - val_accuracy: 0.9270\n",
      "Epoch 484/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.3055 - val_accuracy: 0.9390\n",
      "Epoch 485/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0307 - accuracy: 0.9889 - val_loss: 0.3258 - val_accuracy: 0.9390\n",
      "Epoch 486/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0498 - accuracy: 0.9830 - val_loss: 0.3170 - val_accuracy: 0.9332\n",
      "Epoch 487/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0306 - accuracy: 0.9881 - val_loss: 0.3232 - val_accuracy: 0.9328\n",
      "Epoch 488/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0369 - accuracy: 0.9870 - val_loss: 0.3584 - val_accuracy: 0.9217\n",
      "Epoch 489/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.3132 - val_accuracy: 0.9350\n",
      "Epoch 490/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0284 - accuracy: 0.9895 - val_loss: 0.3553 - val_accuracy: 0.9350\n",
      "Epoch 491/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0306 - accuracy: 0.9878 - val_loss: 0.3480 - val_accuracy: 0.9332\n",
      "Epoch 492/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0371 - accuracy: 0.9863 - val_loss: 0.3262 - val_accuracy: 0.9350\n",
      "Epoch 493/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0253 - accuracy: 0.9900 - val_loss: 0.3008 - val_accuracy: 0.9390\n",
      "Epoch 494/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0395 - accuracy: 0.9859 - val_loss: 0.3870 - val_accuracy: 0.9239\n",
      "Epoch 495/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0397 - accuracy: 0.9871 - val_loss: 0.3002 - val_accuracy: 0.9328\n",
      "Epoch 496/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0264 - accuracy: 0.9901 - val_loss: 0.3250 - val_accuracy: 0.9372\n",
      "Epoch 497/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 0.3189 - val_accuracy: 0.9341\n",
      "Epoch 498/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 0.3496 - val_accuracy: 0.9275\n",
      "Epoch 499/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0283 - accuracy: 0.9890 - val_loss: 0.3714 - val_accuracy: 0.9346\n",
      "Epoch 500/500\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0347 - accuracy: 0.9858 - val_loss: 0.3211 - val_accuracy: 0.9306\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 500\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    BATCH_SIZE, \n",
    "    EPOCHS, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard])\n",
    "\n",
    "model.save(\"D:/Project2022/models/\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loss, test accuracy\n",
    "accuracy = model.evaluate(X_test, y_test, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuuracy 0.9430402517318726\n",
      "Test loss 0.297277569770813\n"
     ]
    }
   ],
   "source": [
    "print(\"Test acuuracy\", accuracy[1])\n",
    "print(\"Test loss\", accuracy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000231DCB0E8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000231DCB0E8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "88/88 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_test)\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       0.94      0.95      0.94      1395\n",
      "      Normal       0.95      0.94      0.94      1414\n",
      "\n",
      "    accuracy                           0.94      2809\n",
      "   macro avg       0.94      0.94      0.94      2809\n",
      "weighted avg       0.94      0.94      0.94      2809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test, y_pred, target_names=[\"covid\", \"Normal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=[\"Covid\",\"Normal\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using just the Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense( 64, activation='relu', input_shape=X_train[0].shape))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dense_resized_64_500\"\n",
    "NAME = model_name+\"-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000231DCDE8DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000231DCDE8DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "895/899 [============================>.] - ETA: 0s - loss: 0.6123 - accuracy: 0.6736WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000231DCD3CB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000231DCD3CB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "899/899 [==============================] - 13s 13ms/step - loss: 0.6123 - accuracy: 0.6735 - val_loss: 0.5596 - val_accuracy: 0.7170\n",
      "Epoch 2/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.5160 - accuracy: 0.7503 - val_loss: 0.4826 - val_accuracy: 0.7859\n",
      "Epoch 3/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.4664 - accuracy: 0.7854 - val_loss: 0.4303 - val_accuracy: 0.8011\n",
      "Epoch 4/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.4436 - accuracy: 0.7971 - val_loss: 0.4195 - val_accuracy: 0.8060\n",
      "Epoch 5/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.4264 - accuracy: 0.8073 - val_loss: 0.4088 - val_accuracy: 0.8184\n",
      "Epoch 6/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.4134 - accuracy: 0.8177 - val_loss: 0.4079 - val_accuracy: 0.8180\n",
      "Epoch 7/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.4055 - accuracy: 0.8228 - val_loss: 0.3945 - val_accuracy: 0.8313\n",
      "Epoch 8/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3937 - accuracy: 0.8267 - val_loss: 0.3849 - val_accuracy: 0.8362\n",
      "Epoch 9/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3879 - accuracy: 0.8278 - val_loss: 0.3701 - val_accuracy: 0.8393\n",
      "Epoch 10/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3780 - accuracy: 0.8350 - val_loss: 0.3934 - val_accuracy: 0.8353\n",
      "Epoch 11/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3793 - accuracy: 0.8317 - val_loss: 0.4036 - val_accuracy: 0.8224\n",
      "Epoch 12/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3674 - accuracy: 0.8393 - val_loss: 0.3652 - val_accuracy: 0.8402\n",
      "Epoch 13/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3610 - accuracy: 0.8452 - val_loss: 0.3746 - val_accuracy: 0.8442\n",
      "Epoch 14/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3574 - accuracy: 0.8444 - val_loss: 0.3648 - val_accuracy: 0.8425\n",
      "Epoch 15/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3521 - accuracy: 0.8484 - val_loss: 0.3576 - val_accuracy: 0.8545\n",
      "Epoch 16/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3460 - accuracy: 0.8485 - val_loss: 0.3607 - val_accuracy: 0.8447\n",
      "Epoch 17/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3407 - accuracy: 0.8573 - val_loss: 0.3433 - val_accuracy: 0.8514\n",
      "Epoch 18/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3336 - accuracy: 0.8597 - val_loss: 0.3513 - val_accuracy: 0.8500\n",
      "Epoch 19/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3372 - accuracy: 0.8558 - val_loss: 0.3440 - val_accuracy: 0.8576\n",
      "Epoch 20/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3261 - accuracy: 0.8635 - val_loss: 0.3371 - val_accuracy: 0.8594\n",
      "Epoch 21/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3186 - accuracy: 0.8653 - val_loss: 0.3516 - val_accuracy: 0.8460\n",
      "Epoch 22/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3128 - accuracy: 0.8676 - val_loss: 0.3295 - val_accuracy: 0.8625\n",
      "Epoch 23/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3119 - accuracy: 0.8652 - val_loss: 0.3439 - val_accuracy: 0.8558\n",
      "Epoch 24/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3079 - accuracy: 0.8666 - val_loss: 0.3313 - val_accuracy: 0.8625\n",
      "Epoch 25/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3038 - accuracy: 0.8738 - val_loss: 0.3303 - val_accuracy: 0.8594\n",
      "Epoch 26/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2972 - accuracy: 0.8771 - val_loss: 0.3187 - val_accuracy: 0.8660\n",
      "Epoch 27/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2980 - accuracy: 0.8753 - val_loss: 0.3134 - val_accuracy: 0.8687\n",
      "Epoch 28/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2961 - accuracy: 0.8765 - val_loss: 0.3083 - val_accuracy: 0.8781\n",
      "Epoch 29/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2847 - accuracy: 0.8800 - val_loss: 0.3142 - val_accuracy: 0.8705\n",
      "Epoch 30/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2837 - accuracy: 0.8830 - val_loss: 0.3135 - val_accuracy: 0.8736\n",
      "Epoch 31/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2771 - accuracy: 0.8839 - val_loss: 0.3261 - val_accuracy: 0.8669\n",
      "Epoch 32/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2760 - accuracy: 0.8857 - val_loss: 0.3116 - val_accuracy: 0.8767\n",
      "Epoch 33/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2736 - accuracy: 0.8876 - val_loss: 0.2977 - val_accuracy: 0.8803\n",
      "Epoch 34/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2725 - accuracy: 0.8874 - val_loss: 0.3294 - val_accuracy: 0.8629\n",
      "Epoch 35/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2649 - accuracy: 0.8915 - val_loss: 0.3186 - val_accuracy: 0.8598\n",
      "Epoch 36/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2666 - accuracy: 0.8907 - val_loss: 0.2973 - val_accuracy: 0.8803\n",
      "Epoch 37/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2624 - accuracy: 0.8880 - val_loss: 0.2961 - val_accuracy: 0.8803\n",
      "Epoch 38/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2596 - accuracy: 0.8919 - val_loss: 0.3011 - val_accuracy: 0.8834\n",
      "Epoch 39/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2549 - accuracy: 0.8963 - val_loss: 0.2995 - val_accuracy: 0.8821\n",
      "Epoch 40/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2503 - accuracy: 0.8973 - val_loss: 0.2919 - val_accuracy: 0.8847\n",
      "Epoch 41/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2479 - accuracy: 0.8970 - val_loss: 0.2816 - val_accuracy: 0.8914\n",
      "Epoch 42/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2480 - accuracy: 0.8986 - val_loss: 0.2767 - val_accuracy: 0.8910\n",
      "Epoch 43/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2447 - accuracy: 0.8982 - val_loss: 0.2861 - val_accuracy: 0.8821\n",
      "Epoch 44/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2438 - accuracy: 0.9047 - val_loss: 0.3317 - val_accuracy: 0.8531\n",
      "Epoch 45/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2463 - accuracy: 0.8975 - val_loss: 0.3601 - val_accuracy: 0.8478\n",
      "Epoch 46/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2335 - accuracy: 0.9063 - val_loss: 0.2759 - val_accuracy: 0.8901\n",
      "Epoch 47/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2350 - accuracy: 0.9030 - val_loss: 0.2937 - val_accuracy: 0.8741\n",
      "Epoch 48/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2311 - accuracy: 0.9060 - val_loss: 0.3122 - val_accuracy: 0.8709\n",
      "Epoch 49/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2273 - accuracy: 0.9089 - val_loss: 0.2957 - val_accuracy: 0.8825\n",
      "Epoch 50/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2258 - accuracy: 0.9070 - val_loss: 0.2739 - val_accuracy: 0.8932\n",
      "Epoch 51/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2255 - accuracy: 0.9057 - val_loss: 0.2795 - val_accuracy: 0.8879\n",
      "Epoch 52/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2147 - accuracy: 0.9109 - val_loss: 0.2780 - val_accuracy: 0.8830\n",
      "Epoch 53/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2207 - accuracy: 0.9111 - val_loss: 0.2901 - val_accuracy: 0.8870\n",
      "Epoch 54/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2195 - accuracy: 0.9110 - val_loss: 0.2777 - val_accuracy: 0.8870\n",
      "Epoch 55/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2122 - accuracy: 0.9154 - val_loss: 0.2659 - val_accuracy: 0.8927\n",
      "Epoch 56/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2157 - accuracy: 0.9135 - val_loss: 0.2917 - val_accuracy: 0.8772\n",
      "Epoch 57/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2118 - accuracy: 0.9132 - val_loss: 0.2767 - val_accuracy: 0.8963\n",
      "Epoch 58/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2059 - accuracy: 0.9192 - val_loss: 0.2681 - val_accuracy: 0.8901\n",
      "Epoch 59/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2092 - accuracy: 0.9135 - val_loss: 0.2656 - val_accuracy: 0.8959\n",
      "Epoch 60/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2083 - accuracy: 0.9146 - val_loss: 0.2806 - val_accuracy: 0.8883\n",
      "Epoch 61/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2042 - accuracy: 0.9182 - val_loss: 0.2623 - val_accuracy: 0.8985\n",
      "Epoch 62/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2071 - accuracy: 0.9132 - val_loss: 0.2808 - val_accuracy: 0.8865\n",
      "Epoch 63/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2037 - accuracy: 0.9202 - val_loss: 0.2589 - val_accuracy: 0.8994\n",
      "Epoch 64/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2019 - accuracy: 0.9184 - val_loss: 0.3484 - val_accuracy: 0.8531\n",
      "Epoch 65/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1977 - accuracy: 0.9199 - val_loss: 0.2960 - val_accuracy: 0.8772\n",
      "Epoch 66/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1980 - accuracy: 0.9179 - val_loss: 0.2964 - val_accuracy: 0.8758\n",
      "Epoch 67/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1922 - accuracy: 0.9227 - val_loss: 0.2542 - val_accuracy: 0.8985\n",
      "Epoch 68/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1927 - accuracy: 0.9213 - val_loss: 0.2630 - val_accuracy: 0.8981\n",
      "Epoch 69/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1853 - accuracy: 0.9259 - val_loss: 0.2861 - val_accuracy: 0.8816\n",
      "Epoch 70/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1886 - accuracy: 0.9211 - val_loss: 0.2698 - val_accuracy: 0.8861\n",
      "Epoch 71/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1865 - accuracy: 0.9252 - val_loss: 0.2600 - val_accuracy: 0.8968\n",
      "Epoch 72/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1914 - accuracy: 0.9217 - val_loss: 0.2551 - val_accuracy: 0.8972\n",
      "Epoch 73/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1864 - accuracy: 0.9240 - val_loss: 0.2719 - val_accuracy: 0.8923\n",
      "Epoch 74/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1801 - accuracy: 0.9266 - val_loss: 0.2770 - val_accuracy: 0.8879\n",
      "Epoch 75/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1869 - accuracy: 0.9224 - val_loss: 0.2528 - val_accuracy: 0.8945\n",
      "Epoch 76/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1823 - accuracy: 0.9269 - val_loss: 0.2601 - val_accuracy: 0.8914\n",
      "Epoch 77/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1779 - accuracy: 0.9270 - val_loss: 0.2543 - val_accuracy: 0.8959\n",
      "Epoch 78/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1826 - accuracy: 0.9254 - val_loss: 0.2518 - val_accuracy: 0.9070\n",
      "Epoch 79/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1744 - accuracy: 0.9293 - val_loss: 0.2712 - val_accuracy: 0.8905\n",
      "Epoch 80/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1754 - accuracy: 0.9302 - val_loss: 0.2557 - val_accuracy: 0.9016\n",
      "Epoch 81/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1772 - accuracy: 0.9284 - val_loss: 0.2523 - val_accuracy: 0.8981\n",
      "Epoch 82/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1735 - accuracy: 0.9284 - val_loss: 0.2822 - val_accuracy: 0.8887\n",
      "Epoch 83/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1700 - accuracy: 0.9310 - val_loss: 0.2742 - val_accuracy: 0.8923\n",
      "Epoch 84/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1698 - accuracy: 0.9327 - val_loss: 0.2777 - val_accuracy: 0.8865\n",
      "Epoch 85/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1721 - accuracy: 0.9316 - val_loss: 0.2670 - val_accuracy: 0.8932\n",
      "Epoch 86/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1705 - accuracy: 0.9297 - val_loss: 0.2592 - val_accuracy: 0.8887\n",
      "Epoch 87/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1647 - accuracy: 0.9325 - val_loss: 0.2537 - val_accuracy: 0.8999\n",
      "Epoch 88/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1750 - accuracy: 0.9280 - val_loss: 0.2795 - val_accuracy: 0.8852\n",
      "Epoch 89/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1688 - accuracy: 0.9309 - val_loss: 0.2380 - val_accuracy: 0.9057\n",
      "Epoch 90/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1616 - accuracy: 0.9379 - val_loss: 0.2610 - val_accuracy: 0.8941\n",
      "Epoch 91/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1646 - accuracy: 0.9313 - val_loss: 0.2452 - val_accuracy: 0.9025\n",
      "Epoch 92/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1614 - accuracy: 0.9350 - val_loss: 0.2512 - val_accuracy: 0.9039\n",
      "Epoch 93/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1518 - accuracy: 0.9398 - val_loss: 0.2627 - val_accuracy: 0.8981\n",
      "Epoch 94/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1584 - accuracy: 0.9359 - val_loss: 0.2754 - val_accuracy: 0.8945\n",
      "Epoch 95/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1611 - accuracy: 0.9338 - val_loss: 0.2529 - val_accuracy: 0.8981\n",
      "Epoch 96/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1536 - accuracy: 0.9366 - val_loss: 0.2462 - val_accuracy: 0.9025\n",
      "Epoch 97/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1554 - accuracy: 0.9358 - val_loss: 0.3003 - val_accuracy: 0.8798\n",
      "Epoch 98/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1506 - accuracy: 0.9371 - val_loss: 0.2576 - val_accuracy: 0.8985\n",
      "Epoch 99/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1638 - accuracy: 0.9370 - val_loss: 0.2411 - val_accuracy: 0.9074\n",
      "Epoch 100/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1515 - accuracy: 0.9377 - val_loss: 0.2450 - val_accuracy: 0.9043\n",
      "Epoch 101/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1535 - accuracy: 0.9368 - val_loss: 0.2545 - val_accuracy: 0.8976\n",
      "Epoch 102/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1558 - accuracy: 0.9349 - val_loss: 0.2641 - val_accuracy: 0.9016\n",
      "Epoch 103/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1517 - accuracy: 0.9371 - val_loss: 0.2581 - val_accuracy: 0.8994\n",
      "Epoch 104/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1495 - accuracy: 0.9392 - val_loss: 0.2385 - val_accuracy: 0.9097\n",
      "Epoch 105/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1522 - accuracy: 0.9376 - val_loss: 0.2331 - val_accuracy: 0.9097\n",
      "Epoch 106/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1400 - accuracy: 0.9448 - val_loss: 0.2538 - val_accuracy: 0.8990\n",
      "Epoch 107/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1532 - accuracy: 0.9391 - val_loss: 0.2459 - val_accuracy: 0.9021\n",
      "Epoch 108/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1438 - accuracy: 0.9418 - val_loss: 0.3166 - val_accuracy: 0.8767\n",
      "Epoch 109/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1432 - accuracy: 0.9405 - val_loss: 0.2483 - val_accuracy: 0.9012\n",
      "Epoch 110/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1477 - accuracy: 0.9429 - val_loss: 0.2460 - val_accuracy: 0.9065\n",
      "Epoch 111/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1434 - accuracy: 0.9414 - val_loss: 0.2630 - val_accuracy: 0.8954\n",
      "Epoch 112/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1397 - accuracy: 0.9410 - val_loss: 0.2425 - val_accuracy: 0.9119\n",
      "Epoch 113/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1380 - accuracy: 0.9432 - val_loss: 0.2283 - val_accuracy: 0.9132\n",
      "Epoch 114/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1410 - accuracy: 0.9426 - val_loss: 0.2495 - val_accuracy: 0.9065\n",
      "Epoch 115/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1372 - accuracy: 0.9447 - val_loss: 0.2600 - val_accuracy: 0.9030\n",
      "Epoch 116/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1429 - accuracy: 0.9437 - val_loss: 0.2664 - val_accuracy: 0.8985\n",
      "Epoch 117/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1359 - accuracy: 0.9446 - val_loss: 0.2473 - val_accuracy: 0.9105\n",
      "Epoch 118/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1326 - accuracy: 0.9468 - val_loss: 0.2611 - val_accuracy: 0.9074\n",
      "Epoch 119/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1386 - accuracy: 0.9440 - val_loss: 0.2391 - val_accuracy: 0.9074\n",
      "Epoch 120/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1319 - accuracy: 0.9468 - val_loss: 0.2621 - val_accuracy: 0.9016\n",
      "Epoch 121/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1388 - accuracy: 0.9424 - val_loss: 0.2636 - val_accuracy: 0.9079\n",
      "Epoch 122/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1378 - accuracy: 0.9421 - val_loss: 0.3633 - val_accuracy: 0.8718\n",
      "Epoch 123/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1331 - accuracy: 0.9468 - val_loss: 0.2596 - val_accuracy: 0.9043\n",
      "Epoch 124/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1296 - accuracy: 0.9464 - val_loss: 0.2552 - val_accuracy: 0.9088\n",
      "Epoch 125/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1341 - accuracy: 0.9438 - val_loss: 0.2426 - val_accuracy: 0.9074\n",
      "Epoch 126/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1318 - accuracy: 0.9449 - val_loss: 0.2607 - val_accuracy: 0.9043\n",
      "Epoch 127/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1302 - accuracy: 0.9495 - val_loss: 0.2865 - val_accuracy: 0.8976\n",
      "Epoch 128/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1291 - accuracy: 0.9474 - val_loss: 0.2636 - val_accuracy: 0.9146\n",
      "Epoch 129/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1360 - accuracy: 0.9442 - val_loss: 0.2940 - val_accuracy: 0.8892\n",
      "Epoch 130/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1263 - accuracy: 0.9466 - val_loss: 0.2384 - val_accuracy: 0.9070\n",
      "Epoch 131/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1341 - accuracy: 0.9449 - val_loss: 0.2812 - val_accuracy: 0.9057\n",
      "Epoch 132/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1310 - accuracy: 0.9467 - val_loss: 0.2442 - val_accuracy: 0.9074\n",
      "Epoch 133/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1270 - accuracy: 0.9475 - val_loss: 0.2902 - val_accuracy: 0.8963\n",
      "Epoch 134/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1264 - accuracy: 0.9470 - val_loss: 0.2475 - val_accuracy: 0.9070\n",
      "Epoch 135/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1237 - accuracy: 0.9496 - val_loss: 0.4097 - val_accuracy: 0.8598\n",
      "Epoch 136/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1287 - accuracy: 0.9486 - val_loss: 0.2507 - val_accuracy: 0.9057\n",
      "Epoch 137/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1293 - accuracy: 0.9468 - val_loss: 0.2418 - val_accuracy: 0.9132\n",
      "Epoch 138/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1227 - accuracy: 0.9496 - val_loss: 0.2597 - val_accuracy: 0.8999\n",
      "Epoch 139/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1254 - accuracy: 0.9489 - val_loss: 0.2487 - val_accuracy: 0.9016\n",
      "Epoch 140/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1198 - accuracy: 0.9514 - val_loss: 0.2629 - val_accuracy: 0.9030\n",
      "Epoch 141/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1197 - accuracy: 0.9509 - val_loss: 0.2354 - val_accuracy: 0.9114\n",
      "Epoch 142/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1196 - accuracy: 0.9496 - val_loss: 0.2512 - val_accuracy: 0.9025\n",
      "Epoch 143/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1238 - accuracy: 0.9495 - val_loss: 0.2398 - val_accuracy: 0.9101\n",
      "Epoch 144/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1172 - accuracy: 0.9505 - val_loss: 0.2586 - val_accuracy: 0.9061\n",
      "Epoch 145/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1172 - accuracy: 0.9513 - val_loss: 0.2781 - val_accuracy: 0.9008\n",
      "Epoch 146/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1233 - accuracy: 0.9503 - val_loss: 0.2470 - val_accuracy: 0.9132\n",
      "Epoch 147/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1201 - accuracy: 0.9507 - val_loss: 0.2435 - val_accuracy: 0.9097\n",
      "Epoch 148/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1175 - accuracy: 0.9506 - val_loss: 0.2790 - val_accuracy: 0.8972\n",
      "Epoch 149/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1155 - accuracy: 0.9528 - val_loss: 0.2676 - val_accuracy: 0.8999\n",
      "Epoch 150/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1220 - accuracy: 0.9496 - val_loss: 0.2628 - val_accuracy: 0.9079\n",
      "Epoch 151/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1114 - accuracy: 0.9567 - val_loss: 0.2246 - val_accuracy: 0.9186\n",
      "Epoch 152/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1147 - accuracy: 0.9524 - val_loss: 0.4087 - val_accuracy: 0.8683\n",
      "Epoch 153/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1185 - accuracy: 0.9514 - val_loss: 0.2777 - val_accuracy: 0.9008\n",
      "Epoch 154/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1185 - accuracy: 0.9514 - val_loss: 0.2437 - val_accuracy: 0.9105\n",
      "Epoch 155/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1187 - accuracy: 0.9524 - val_loss: 0.2655 - val_accuracy: 0.8990\n",
      "Epoch 156/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1067 - accuracy: 0.9568 - val_loss: 0.2247 - val_accuracy: 0.9190\n",
      "Epoch 157/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1128 - accuracy: 0.9536 - val_loss: 0.2595 - val_accuracy: 0.9039\n",
      "Epoch 158/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1161 - accuracy: 0.9540 - val_loss: 0.2550 - val_accuracy: 0.9074\n",
      "Epoch 159/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1070 - accuracy: 0.9593 - val_loss: 0.2554 - val_accuracy: 0.9110\n",
      "Epoch 160/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1130 - accuracy: 0.9536 - val_loss: 0.2540 - val_accuracy: 0.9097\n",
      "Epoch 161/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1177 - accuracy: 0.9537 - val_loss: 0.2769 - val_accuracy: 0.9039\n",
      "Epoch 162/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1100 - accuracy: 0.9549 - val_loss: 0.2780 - val_accuracy: 0.8972\n",
      "Epoch 163/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1107 - accuracy: 0.9567 - val_loss: 0.2551 - val_accuracy: 0.9074\n",
      "Epoch 164/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1143 - accuracy: 0.9533 - val_loss: 0.2408 - val_accuracy: 0.9123\n",
      "Epoch 165/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1056 - accuracy: 0.9570 - val_loss: 0.2653 - val_accuracy: 0.9088\n",
      "Epoch 166/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1122 - accuracy: 0.9543 - val_loss: 0.2526 - val_accuracy: 0.9101\n",
      "Epoch 167/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1087 - accuracy: 0.9567 - val_loss: 0.3058 - val_accuracy: 0.8945\n",
      "Epoch 168/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1041 - accuracy: 0.9598 - val_loss: 0.3491 - val_accuracy: 0.8736\n",
      "Epoch 169/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1185 - accuracy: 0.9535 - val_loss: 0.2458 - val_accuracy: 0.9105\n",
      "Epoch 170/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1116 - accuracy: 0.9539 - val_loss: 0.2380 - val_accuracy: 0.9168\n",
      "Epoch 171/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1139 - accuracy: 0.9555 - val_loss: 0.2684 - val_accuracy: 0.9052\n",
      "Epoch 172/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1058 - accuracy: 0.9577 - val_loss: 0.2979 - val_accuracy: 0.8968\n",
      "Epoch 173/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1107 - accuracy: 0.9549 - val_loss: 0.2544 - val_accuracy: 0.9025\n",
      "Epoch 174/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1112 - accuracy: 0.9543 - val_loss: 0.3166 - val_accuracy: 0.8887\n",
      "Epoch 175/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1011 - accuracy: 0.9603 - val_loss: 0.2356 - val_accuracy: 0.9141\n",
      "Epoch 176/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1098 - accuracy: 0.9569 - val_loss: 0.2609 - val_accuracy: 0.9021\n",
      "Epoch 177/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1074 - accuracy: 0.9572 - val_loss: 0.2378 - val_accuracy: 0.9128\n",
      "Epoch 178/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1140 - accuracy: 0.9554 - val_loss: 0.2367 - val_accuracy: 0.9163\n",
      "Epoch 179/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1066 - accuracy: 0.9565 - val_loss: 0.3004 - val_accuracy: 0.9012\n",
      "Epoch 180/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1062 - accuracy: 0.9576 - val_loss: 0.2688 - val_accuracy: 0.9039\n",
      "Epoch 181/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1013 - accuracy: 0.9595 - val_loss: 0.2378 - val_accuracy: 0.9177\n",
      "Epoch 182/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1026 - accuracy: 0.9593 - val_loss: 0.3228 - val_accuracy: 0.8896\n",
      "Epoch 183/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1052 - accuracy: 0.9597 - val_loss: 0.2362 - val_accuracy: 0.9128\n",
      "Epoch 184/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1106 - accuracy: 0.9543 - val_loss: 0.2809 - val_accuracy: 0.9097\n",
      "Epoch 185/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1081 - accuracy: 0.9539 - val_loss: 0.2443 - val_accuracy: 0.9146\n",
      "Epoch 186/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1064 - accuracy: 0.9533 - val_loss: 0.2363 - val_accuracy: 0.9154\n",
      "Epoch 187/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1014 - accuracy: 0.9582 - val_loss: 0.2632 - val_accuracy: 0.9097\n",
      "Epoch 188/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1017 - accuracy: 0.9569 - val_loss: 0.2604 - val_accuracy: 0.9074\n",
      "Epoch 189/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1058 - accuracy: 0.9573 - val_loss: 0.2818 - val_accuracy: 0.8968\n",
      "Epoch 190/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1058 - accuracy: 0.9577 - val_loss: 0.2578 - val_accuracy: 0.9034\n",
      "Epoch 191/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0966 - accuracy: 0.9611 - val_loss: 0.3137 - val_accuracy: 0.8976\n",
      "Epoch 192/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0986 - accuracy: 0.9603 - val_loss: 0.2481 - val_accuracy: 0.9146\n",
      "Epoch 193/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0977 - accuracy: 0.9613 - val_loss: 0.2511 - val_accuracy: 0.9097\n",
      "Epoch 194/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0965 - accuracy: 0.9608 - val_loss: 0.2488 - val_accuracy: 0.9123\n",
      "Epoch 195/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0957 - accuracy: 0.9609 - val_loss: 0.2450 - val_accuracy: 0.9172\n",
      "Epoch 196/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1062 - accuracy: 0.9567 - val_loss: 0.2508 - val_accuracy: 0.9172\n",
      "Epoch 197/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1017 - accuracy: 0.9600 - val_loss: 0.2936 - val_accuracy: 0.9052\n",
      "Epoch 198/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1083 - accuracy: 0.9566 - val_loss: 0.2671 - val_accuracy: 0.9052\n",
      "Epoch 199/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1036 - accuracy: 0.9595 - val_loss: 0.2524 - val_accuracy: 0.9110\n",
      "Epoch 200/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0991 - accuracy: 0.9572 - val_loss: 0.2617 - val_accuracy: 0.9128\n",
      "Epoch 201/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0964 - accuracy: 0.9621 - val_loss: 0.2905 - val_accuracy: 0.8936\n",
      "Epoch 202/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0979 - accuracy: 0.9608 - val_loss: 0.2736 - val_accuracy: 0.9119\n",
      "Epoch 203/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0978 - accuracy: 0.9606 - val_loss: 0.3381 - val_accuracy: 0.8981\n",
      "Epoch 204/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0994 - accuracy: 0.9615 - val_loss: 0.2550 - val_accuracy: 0.9101\n",
      "Epoch 205/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0938 - accuracy: 0.9622 - val_loss: 0.2584 - val_accuracy: 0.9088\n",
      "Epoch 206/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0932 - accuracy: 0.9629 - val_loss: 0.2546 - val_accuracy: 0.9177\n",
      "Epoch 207/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1002 - accuracy: 0.9607 - val_loss: 0.2471 - val_accuracy: 0.9186\n",
      "Epoch 208/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0938 - accuracy: 0.9629 - val_loss: 0.2779 - val_accuracy: 0.9159\n",
      "Epoch 209/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0964 - accuracy: 0.9607 - val_loss: 0.2666 - val_accuracy: 0.9132\n",
      "Epoch 210/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0992 - accuracy: 0.9599 - val_loss: 0.2642 - val_accuracy: 0.9114\n",
      "Epoch 211/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0872 - accuracy: 0.9644 - val_loss: 0.2513 - val_accuracy: 0.9123\n",
      "Epoch 212/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0897 - accuracy: 0.9642 - val_loss: 0.2927 - val_accuracy: 0.9008\n",
      "Epoch 213/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0971 - accuracy: 0.9617 - val_loss: 0.3221 - val_accuracy: 0.9025\n",
      "Epoch 214/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0989 - accuracy: 0.9623 - val_loss: 0.2645 - val_accuracy: 0.9074\n",
      "Epoch 215/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0911 - accuracy: 0.9632 - val_loss: 0.2377 - val_accuracy: 0.9186\n",
      "Epoch 216/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.2501 - val_accuracy: 0.9154\n",
      "Epoch 217/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0995 - accuracy: 0.9592 - val_loss: 0.2548 - val_accuracy: 0.9194\n",
      "Epoch 218/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0932 - accuracy: 0.9635 - val_loss: 0.3017 - val_accuracy: 0.8990\n",
      "Epoch 219/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0965 - accuracy: 0.9636 - val_loss: 0.3054 - val_accuracy: 0.8945\n",
      "Epoch 220/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0864 - accuracy: 0.9657 - val_loss: 0.3033 - val_accuracy: 0.9070\n",
      "Epoch 221/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0892 - accuracy: 0.9651 - val_loss: 0.2727 - val_accuracy: 0.9083\n",
      "Epoch 222/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0926 - accuracy: 0.9637 - val_loss: 0.2502 - val_accuracy: 0.9181\n",
      "Epoch 223/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0900 - accuracy: 0.9652 - val_loss: 0.2671 - val_accuracy: 0.9119\n",
      "Epoch 224/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0855 - accuracy: 0.9680 - val_loss: 0.2732 - val_accuracy: 0.9101\n",
      "Epoch 225/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0917 - accuracy: 0.9656 - val_loss: 0.3712 - val_accuracy: 0.8749\n",
      "Epoch 226/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0951 - accuracy: 0.9621 - val_loss: 0.2555 - val_accuracy: 0.9168\n",
      "Epoch 227/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0984 - accuracy: 0.9603 - val_loss: 0.2329 - val_accuracy: 0.9226\n",
      "Epoch 228/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0891 - accuracy: 0.9653 - val_loss: 0.2769 - val_accuracy: 0.9132\n",
      "Epoch 229/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0851 - accuracy: 0.9655 - val_loss: 0.2687 - val_accuracy: 0.9110\n",
      "Epoch 230/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0895 - accuracy: 0.9644 - val_loss: 0.2491 - val_accuracy: 0.9168\n",
      "Epoch 231/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0939 - accuracy: 0.9644 - val_loss: 0.3094 - val_accuracy: 0.9079\n",
      "Epoch 232/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0882 - accuracy: 0.9648 - val_loss: 0.2845 - val_accuracy: 0.9097\n",
      "Epoch 233/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0827 - accuracy: 0.9668 - val_loss: 0.3002 - val_accuracy: 0.9101\n",
      "Epoch 234/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0835 - accuracy: 0.9683 - val_loss: 0.2503 - val_accuracy: 0.9168\n",
      "Epoch 235/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0942 - accuracy: 0.9617 - val_loss: 0.2544 - val_accuracy: 0.9146\n",
      "Epoch 236/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0926 - accuracy: 0.9634 - val_loss: 0.3186 - val_accuracy: 0.8954\n",
      "Epoch 237/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0804 - accuracy: 0.9683 - val_loss: 0.2571 - val_accuracy: 0.9203\n",
      "Epoch 238/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0971 - accuracy: 0.9614 - val_loss: 0.2998 - val_accuracy: 0.9154\n",
      "Epoch 239/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0757 - accuracy: 0.9687 - val_loss: 0.2779 - val_accuracy: 0.9065\n",
      "Epoch 240/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0929 - accuracy: 0.9626 - val_loss: 0.2895 - val_accuracy: 0.9150\n",
      "Epoch 241/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0937 - accuracy: 0.9631 - val_loss: 0.2991 - val_accuracy: 0.9092\n",
      "Epoch 242/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0849 - accuracy: 0.9671 - val_loss: 0.2630 - val_accuracy: 0.9172\n",
      "Epoch 243/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0895 - accuracy: 0.9662 - val_loss: 0.2511 - val_accuracy: 0.9150\n",
      "Epoch 244/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0847 - accuracy: 0.9646 - val_loss: 0.2626 - val_accuracy: 0.9141\n",
      "Epoch 245/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0859 - accuracy: 0.9645 - val_loss: 0.2569 - val_accuracy: 0.9194\n",
      "Epoch 246/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0811 - accuracy: 0.9678 - val_loss: 0.2920 - val_accuracy: 0.9123\n",
      "Epoch 247/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0862 - accuracy: 0.9653 - val_loss: 0.2716 - val_accuracy: 0.9048\n",
      "Epoch 248/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0838 - accuracy: 0.9671 - val_loss: 0.2891 - val_accuracy: 0.9048\n",
      "Epoch 249/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0986 - accuracy: 0.9614 - val_loss: 0.3260 - val_accuracy: 0.8932\n",
      "Epoch 250/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0828 - accuracy: 0.9639 - val_loss: 0.2879 - val_accuracy: 0.9128\n",
      "Epoch 251/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0883 - accuracy: 0.9654 - val_loss: 0.2537 - val_accuracy: 0.9203\n",
      "Epoch 252/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0758 - accuracy: 0.9703 - val_loss: 0.2704 - val_accuracy: 0.9141\n",
      "Epoch 253/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0781 - accuracy: 0.9692 - val_loss: 0.2423 - val_accuracy: 0.9239\n",
      "Epoch 254/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0965 - accuracy: 0.9629 - val_loss: 0.2667 - val_accuracy: 0.9190\n",
      "Epoch 255/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0809 - accuracy: 0.9683 - val_loss: 0.2570 - val_accuracy: 0.9226\n",
      "Epoch 256/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0818 - accuracy: 0.9681 - val_loss: 0.2742 - val_accuracy: 0.9159\n",
      "Epoch 257/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0898 - accuracy: 0.9641 - val_loss: 0.2666 - val_accuracy: 0.9221\n",
      "Epoch 258/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0897 - accuracy: 0.9634 - val_loss: 0.2790 - val_accuracy: 0.9146\n",
      "Epoch 259/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0829 - accuracy: 0.9692 - val_loss: 0.2447 - val_accuracy: 0.9270\n",
      "Epoch 260/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0825 - accuracy: 0.9665 - val_loss: 0.2681 - val_accuracy: 0.9110\n",
      "Epoch 261/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0791 - accuracy: 0.9688 - val_loss: 0.2772 - val_accuracy: 0.9190\n",
      "Epoch 262/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0871 - accuracy: 0.9656 - val_loss: 0.2858 - val_accuracy: 0.9190\n",
      "Epoch 263/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0745 - accuracy: 0.9730 - val_loss: 0.3036 - val_accuracy: 0.9079\n",
      "Epoch 264/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0815 - accuracy: 0.9667 - val_loss: 0.2596 - val_accuracy: 0.9154\n",
      "Epoch 265/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0826 - accuracy: 0.9662 - val_loss: 0.3051 - val_accuracy: 0.9092\n",
      "Epoch 266/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0858 - accuracy: 0.9656 - val_loss: 0.2806 - val_accuracy: 0.9128\n",
      "Epoch 267/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0832 - accuracy: 0.9701 - val_loss: 0.2780 - val_accuracy: 0.9057\n",
      "Epoch 268/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0733 - accuracy: 0.9697 - val_loss: 0.2724 - val_accuracy: 0.9163\n",
      "Epoch 269/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0798 - accuracy: 0.9674 - val_loss: 0.2719 - val_accuracy: 0.9177\n",
      "Epoch 270/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0807 - accuracy: 0.9673 - val_loss: 0.2721 - val_accuracy: 0.9163\n",
      "Epoch 271/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0837 - accuracy: 0.9678 - val_loss: 0.3347 - val_accuracy: 0.8914\n",
      "Epoch 272/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0902 - accuracy: 0.9662 - val_loss: 0.2801 - val_accuracy: 0.9137\n",
      "Epoch 273/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0797 - accuracy: 0.9681 - val_loss: 0.2877 - val_accuracy: 0.9105\n",
      "Epoch 274/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0768 - accuracy: 0.9690 - val_loss: 0.2535 - val_accuracy: 0.9212\n",
      "Epoch 275/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0716 - accuracy: 0.9728 - val_loss: 0.2918 - val_accuracy: 0.9154\n",
      "Epoch 276/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0882 - accuracy: 0.9662 - val_loss: 0.2549 - val_accuracy: 0.9203\n",
      "Epoch 277/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0763 - accuracy: 0.9706 - val_loss: 0.2528 - val_accuracy: 0.9194\n",
      "Epoch 278/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0772 - accuracy: 0.9712 - val_loss: 0.3187 - val_accuracy: 0.9079\n",
      "Epoch 279/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0805 - accuracy: 0.9682 - val_loss: 0.3133 - val_accuracy: 0.9070\n",
      "Epoch 280/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0721 - accuracy: 0.9718 - val_loss: 0.3092 - val_accuracy: 0.9012\n",
      "Epoch 281/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0733 - accuracy: 0.9716 - val_loss: 0.3013 - val_accuracy: 0.9008\n",
      "Epoch 282/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0766 - accuracy: 0.9703 - val_loss: 0.3352 - val_accuracy: 0.9057\n",
      "Epoch 283/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0705 - accuracy: 0.9728 - val_loss: 0.2828 - val_accuracy: 0.9168\n",
      "Epoch 284/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0782 - accuracy: 0.9686 - val_loss: 0.2872 - val_accuracy: 0.9123\n",
      "Epoch 285/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0820 - accuracy: 0.9680 - val_loss: 0.3091 - val_accuracy: 0.9021\n",
      "Epoch 286/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0792 - accuracy: 0.9691 - val_loss: 0.3638 - val_accuracy: 0.9025\n",
      "Epoch 287/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0733 - accuracy: 0.9717 - val_loss: 0.2426 - val_accuracy: 0.9248\n",
      "Epoch 288/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0786 - accuracy: 0.9691 - val_loss: 0.3093 - val_accuracy: 0.9074\n",
      "Epoch 289/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0769 - accuracy: 0.9675 - val_loss: 0.2538 - val_accuracy: 0.9283\n",
      "Epoch 290/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0737 - accuracy: 0.9716 - val_loss: 0.2813 - val_accuracy: 0.9132\n",
      "Epoch 291/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0776 - accuracy: 0.9674 - val_loss: 0.2641 - val_accuracy: 0.9168\n",
      "Epoch 292/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0688 - accuracy: 0.9732 - val_loss: 0.3323 - val_accuracy: 0.9110\n",
      "Epoch 293/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0742 - accuracy: 0.9705 - val_loss: 0.2711 - val_accuracy: 0.9199\n",
      "Epoch 294/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0792 - accuracy: 0.9686 - val_loss: 0.2882 - val_accuracy: 0.9074\n",
      "Epoch 295/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0675 - accuracy: 0.9732 - val_loss: 0.2491 - val_accuracy: 0.9266\n",
      "Epoch 296/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0751 - accuracy: 0.9705 - val_loss: 0.2933 - val_accuracy: 0.9128\n",
      "Epoch 297/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0685 - accuracy: 0.9746 - val_loss: 0.2910 - val_accuracy: 0.9186\n",
      "Epoch 298/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0693 - accuracy: 0.9741 - val_loss: 0.2955 - val_accuracy: 0.9172\n",
      "Epoch 299/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0737 - accuracy: 0.9697 - val_loss: 0.3132 - val_accuracy: 0.9137\n",
      "Epoch 300/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0735 - accuracy: 0.9707 - val_loss: 0.3979 - val_accuracy: 0.8999\n",
      "Epoch 301/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 0.2814 - val_accuracy: 0.9159\n",
      "Epoch 302/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0740 - accuracy: 0.9710 - val_loss: 0.3203 - val_accuracy: 0.9088\n",
      "Epoch 303/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0778 - accuracy: 0.9700 - val_loss: 0.3034 - val_accuracy: 0.9141\n",
      "Epoch 304/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0792 - accuracy: 0.9690 - val_loss: 0.2672 - val_accuracy: 0.9243\n",
      "Epoch 305/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0761 - accuracy: 0.9711 - val_loss: 0.3163 - val_accuracy: 0.9141\n",
      "Epoch 306/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0712 - accuracy: 0.9725 - val_loss: 0.3216 - val_accuracy: 0.9137\n",
      "Epoch 307/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0705 - accuracy: 0.9747 - val_loss: 0.2833 - val_accuracy: 0.9088\n",
      "Epoch 308/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0671 - accuracy: 0.9735 - val_loss: 0.2705 - val_accuracy: 0.9114\n",
      "Epoch 309/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0774 - accuracy: 0.9715 - val_loss: 0.2882 - val_accuracy: 0.9150\n",
      "Epoch 310/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0699 - accuracy: 0.9730 - val_loss: 0.3296 - val_accuracy: 0.9101\n",
      "Epoch 311/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0693 - accuracy: 0.9715 - val_loss: 0.2840 - val_accuracy: 0.9150\n",
      "Epoch 312/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0675 - accuracy: 0.9722 - val_loss: 0.2699 - val_accuracy: 0.9203\n",
      "Epoch 313/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0734 - accuracy: 0.9712 - val_loss: 0.3130 - val_accuracy: 0.9132\n",
      "Epoch 314/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0749 - accuracy: 0.9690 - val_loss: 0.3229 - val_accuracy: 0.9137\n",
      "Epoch 315/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0763 - accuracy: 0.9693 - val_loss: 0.2866 - val_accuracy: 0.9172\n",
      "Epoch 316/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0676 - accuracy: 0.9738 - val_loss: 0.2875 - val_accuracy: 0.9186\n",
      "Epoch 317/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0720 - accuracy: 0.9718 - val_loss: 0.3015 - val_accuracy: 0.9203\n",
      "Epoch 318/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0696 - accuracy: 0.9726 - val_loss: 0.3495 - val_accuracy: 0.9092\n",
      "Epoch 319/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0713 - accuracy: 0.9711 - val_loss: 0.2983 - val_accuracy: 0.9137\n",
      "Epoch 320/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0709 - accuracy: 0.9722 - val_loss: 0.2844 - val_accuracy: 0.9168\n",
      "Epoch 321/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0769 - accuracy: 0.9694 - val_loss: 0.2865 - val_accuracy: 0.9159\n",
      "Epoch 322/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0763 - accuracy: 0.9702 - val_loss: 0.3288 - val_accuracy: 0.9074\n",
      "Epoch 323/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0689 - accuracy: 0.9734 - val_loss: 0.3634 - val_accuracy: 0.8999\n",
      "Epoch 324/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0702 - accuracy: 0.9720 - val_loss: 0.2501 - val_accuracy: 0.9239\n",
      "Epoch 325/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0720 - accuracy: 0.9740 - val_loss: 0.3782 - val_accuracy: 0.9057\n",
      "Epoch 326/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0725 - accuracy: 0.9725 - val_loss: 0.2695 - val_accuracy: 0.9163\n",
      "Epoch 327/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0627 - accuracy: 0.9760 - val_loss: 0.3702 - val_accuracy: 0.8990\n",
      "Epoch 328/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0712 - accuracy: 0.9714 - val_loss: 0.2691 - val_accuracy: 0.9194\n",
      "Epoch 329/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0701 - accuracy: 0.9737 - val_loss: 0.2934 - val_accuracy: 0.9194\n",
      "Epoch 330/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0688 - accuracy: 0.9732 - val_loss: 0.3053 - val_accuracy: 0.9159\n",
      "Epoch 331/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0662 - accuracy: 0.9734 - val_loss: 0.2661 - val_accuracy: 0.9248\n",
      "Epoch 332/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0708 - accuracy: 0.9740 - val_loss: 0.2933 - val_accuracy: 0.9235\n",
      "Epoch 333/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0644 - accuracy: 0.9743 - val_loss: 0.2942 - val_accuracy: 0.9141\n",
      "Epoch 334/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0755 - accuracy: 0.9695 - val_loss: 0.2955 - val_accuracy: 0.9181\n",
      "Epoch 335/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0645 - accuracy: 0.9741 - val_loss: 0.2663 - val_accuracy: 0.9212\n",
      "Epoch 336/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0680 - accuracy: 0.9730 - val_loss: 0.2659 - val_accuracy: 0.9217\n",
      "Epoch 337/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0689 - accuracy: 0.9735 - val_loss: 0.3324 - val_accuracy: 0.9123\n",
      "Epoch 338/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0631 - accuracy: 0.9752 - val_loss: 0.3010 - val_accuracy: 0.9194\n",
      "Epoch 339/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0771 - accuracy: 0.9680 - val_loss: 0.2768 - val_accuracy: 0.9243\n",
      "Epoch 340/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0611 - accuracy: 0.9757 - val_loss: 0.3297 - val_accuracy: 0.9048\n",
      "Epoch 341/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0665 - accuracy: 0.9742 - val_loss: 0.2934 - val_accuracy: 0.9172\n",
      "Epoch 342/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0710 - accuracy: 0.9725 - val_loss: 0.2879 - val_accuracy: 0.9159\n",
      "Epoch 343/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0670 - accuracy: 0.9743 - val_loss: 0.2965 - val_accuracy: 0.9123\n",
      "Epoch 344/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0791 - accuracy: 0.9701 - val_loss: 0.3058 - val_accuracy: 0.9154\n",
      "Epoch 345/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0622 - accuracy: 0.9757 - val_loss: 0.2932 - val_accuracy: 0.9132\n",
      "Epoch 346/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0655 - accuracy: 0.9756 - val_loss: 0.2749 - val_accuracy: 0.9177\n",
      "Epoch 347/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0692 - accuracy: 0.9720 - val_loss: 0.3844 - val_accuracy: 0.9030\n",
      "Epoch 348/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0618 - accuracy: 0.9752 - val_loss: 0.3353 - val_accuracy: 0.8950\n",
      "Epoch 349/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0661 - accuracy: 0.9757 - val_loss: 0.2885 - val_accuracy: 0.9159\n",
      "Epoch 350/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0612 - accuracy: 0.9762 - val_loss: 0.2986 - val_accuracy: 0.9168\n",
      "Epoch 351/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0612 - accuracy: 0.9767 - val_loss: 0.2988 - val_accuracy: 0.9154\n",
      "Epoch 352/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0660 - accuracy: 0.9743 - val_loss: 0.2715 - val_accuracy: 0.9235\n",
      "Epoch 353/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0624 - accuracy: 0.9747 - val_loss: 0.2899 - val_accuracy: 0.9172\n",
      "Epoch 354/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0601 - accuracy: 0.9774 - val_loss: 0.2772 - val_accuracy: 0.9208\n",
      "Epoch 355/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0677 - accuracy: 0.9725 - val_loss: 0.3341 - val_accuracy: 0.9105\n",
      "Epoch 356/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0635 - accuracy: 0.9743 - val_loss: 0.2936 - val_accuracy: 0.9190\n",
      "Epoch 357/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0715 - accuracy: 0.9725 - val_loss: 0.4978 - val_accuracy: 0.8745\n",
      "Epoch 358/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0656 - accuracy: 0.9737 - val_loss: 0.3014 - val_accuracy: 0.9190\n",
      "Epoch 359/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0623 - accuracy: 0.9783 - val_loss: 0.3281 - val_accuracy: 0.9163\n",
      "Epoch 360/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0693 - accuracy: 0.9743 - val_loss: 0.3023 - val_accuracy: 0.9154\n",
      "Epoch 361/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0606 - accuracy: 0.9770 - val_loss: 0.2835 - val_accuracy: 0.9217\n",
      "Epoch 362/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0576 - accuracy: 0.9777 - val_loss: 0.5990 - val_accuracy: 0.8669\n",
      "Epoch 363/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0646 - accuracy: 0.9761 - val_loss: 0.2996 - val_accuracy: 0.9177\n",
      "Epoch 364/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0645 - accuracy: 0.9734 - val_loss: 0.3310 - val_accuracy: 0.9186\n",
      "Epoch 365/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0626 - accuracy: 0.9746 - val_loss: 0.3228 - val_accuracy: 0.9163\n",
      "Epoch 366/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.3331 - val_accuracy: 0.9039\n",
      "Epoch 367/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0642 - accuracy: 0.9740 - val_loss: 0.2983 - val_accuracy: 0.9177\n",
      "Epoch 368/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0641 - accuracy: 0.9723 - val_loss: 0.2853 - val_accuracy: 0.9239\n",
      "Epoch 369/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0571 - accuracy: 0.9780 - val_loss: 0.3501 - val_accuracy: 0.9101\n",
      "Epoch 370/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0682 - accuracy: 0.9733 - val_loss: 0.3450 - val_accuracy: 0.9123\n",
      "Epoch 371/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0674 - accuracy: 0.9760 - val_loss: 0.3226 - val_accuracy: 0.9221\n",
      "Epoch 372/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0550 - accuracy: 0.9796 - val_loss: 0.3088 - val_accuracy: 0.9123\n",
      "Epoch 373/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0597 - accuracy: 0.9753 - val_loss: 0.3190 - val_accuracy: 0.9163\n",
      "Epoch 374/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0666 - accuracy: 0.9752 - val_loss: 0.2815 - val_accuracy: 0.9190\n",
      "Epoch 375/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0616 - accuracy: 0.9766 - val_loss: 0.3290 - val_accuracy: 0.9097\n",
      "Epoch 376/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0653 - accuracy: 0.9752 - val_loss: 0.3060 - val_accuracy: 0.9208\n",
      "Epoch 377/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0523 - accuracy: 0.9797 - val_loss: 0.3258 - val_accuracy: 0.9110\n",
      "Epoch 378/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0664 - accuracy: 0.9745 - val_loss: 0.3099 - val_accuracy: 0.9190\n",
      "Epoch 379/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0623 - accuracy: 0.9762 - val_loss: 0.3321 - val_accuracy: 0.9177\n",
      "Epoch 380/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0631 - accuracy: 0.9740 - val_loss: 0.3044 - val_accuracy: 0.9226\n",
      "Epoch 381/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0662 - accuracy: 0.9743 - val_loss: 0.2840 - val_accuracy: 0.9248\n",
      "Epoch 382/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0554 - accuracy: 0.9783 - val_loss: 0.3029 - val_accuracy: 0.9239\n",
      "Epoch 383/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0639 - accuracy: 0.9754 - val_loss: 0.3040 - val_accuracy: 0.9212\n",
      "Epoch 384/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0533 - accuracy: 0.9793 - val_loss: 0.2795 - val_accuracy: 0.9297\n",
      "Epoch 385/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0562 - accuracy: 0.9792 - val_loss: 0.3799 - val_accuracy: 0.9070\n",
      "Epoch 386/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0623 - accuracy: 0.9776 - val_loss: 0.3545 - val_accuracy: 0.9088\n",
      "Epoch 387/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0582 - accuracy: 0.9772 - val_loss: 0.3291 - val_accuracy: 0.9154\n",
      "Epoch 388/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0634 - accuracy: 0.9741 - val_loss: 0.2887 - val_accuracy: 0.9177\n",
      "Epoch 389/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0729 - accuracy: 0.9725 - val_loss: 0.3904 - val_accuracy: 0.9083\n",
      "Epoch 390/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0566 - accuracy: 0.9773 - val_loss: 0.2753 - val_accuracy: 0.9235\n",
      "Epoch 391/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0532 - accuracy: 0.9793 - val_loss: 0.3639 - val_accuracy: 0.9114\n",
      "Epoch 392/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0684 - accuracy: 0.9754 - val_loss: 0.3110 - val_accuracy: 0.9070\n",
      "Epoch 393/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0598 - accuracy: 0.9769 - val_loss: 0.3249 - val_accuracy: 0.9141\n",
      "Epoch 394/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0593 - accuracy: 0.9760 - val_loss: 0.3385 - val_accuracy: 0.9146\n",
      "Epoch 395/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0539 - accuracy: 0.9795 - val_loss: 0.2882 - val_accuracy: 0.9190\n",
      "Epoch 396/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0644 - accuracy: 0.9766 - val_loss: 0.4070 - val_accuracy: 0.8798\n",
      "Epoch 397/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0580 - accuracy: 0.9762 - val_loss: 0.3494 - val_accuracy: 0.9146\n",
      "Epoch 398/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.2731 - val_accuracy: 0.9212\n",
      "Epoch 399/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0545 - accuracy: 0.9799 - val_loss: 0.2764 - val_accuracy: 0.9319\n",
      "Epoch 400/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0579 - accuracy: 0.9773 - val_loss: 0.3238 - val_accuracy: 0.9217\n",
      "Epoch 401/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 0.2763 - val_accuracy: 0.9261\n",
      "Epoch 402/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0526 - accuracy: 0.9792 - val_loss: 0.2844 - val_accuracy: 0.9186\n",
      "Epoch 403/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0545 - accuracy: 0.9785 - val_loss: 0.3348 - val_accuracy: 0.9177\n",
      "Epoch 404/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0597 - accuracy: 0.9771 - val_loss: 0.3450 - val_accuracy: 0.9132\n",
      "Epoch 405/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0596 - accuracy: 0.9777 - val_loss: 0.3122 - val_accuracy: 0.9194\n",
      "Epoch 406/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0505 - accuracy: 0.9804 - val_loss: 0.2991 - val_accuracy: 0.9248\n",
      "Epoch 407/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0674 - accuracy: 0.9738 - val_loss: 0.2983 - val_accuracy: 0.9226\n",
      "Epoch 408/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0602 - accuracy: 0.9746 - val_loss: 0.3219 - val_accuracy: 0.9239\n",
      "Epoch 409/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0506 - accuracy: 0.9794 - val_loss: 0.2907 - val_accuracy: 0.9288\n",
      "Epoch 410/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0537 - accuracy: 0.9779 - val_loss: 0.3070 - val_accuracy: 0.9203\n",
      "Epoch 411/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0574 - accuracy: 0.9764 - val_loss: 0.4111 - val_accuracy: 0.9092\n",
      "Epoch 412/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0577 - accuracy: 0.9785 - val_loss: 0.3412 - val_accuracy: 0.9190\n",
      "Epoch 413/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0534 - accuracy: 0.9790 - val_loss: 0.2836 - val_accuracy: 0.9270\n",
      "Epoch 414/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0636 - accuracy: 0.9756 - val_loss: 0.2767 - val_accuracy: 0.9235\n",
      "Epoch 415/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0607 - accuracy: 0.9746 - val_loss: 0.4221 - val_accuracy: 0.9088\n",
      "Epoch 416/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0492 - accuracy: 0.9801 - val_loss: 0.3043 - val_accuracy: 0.9257\n",
      "Epoch 417/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0546 - accuracy: 0.9781 - val_loss: 0.2894 - val_accuracy: 0.9275\n",
      "Epoch 418/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0614 - accuracy: 0.9761 - val_loss: 0.3770 - val_accuracy: 0.9079\n",
      "Epoch 419/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0526 - accuracy: 0.9785 - val_loss: 0.3122 - val_accuracy: 0.9239\n",
      "Epoch 420/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0470 - accuracy: 0.9806 - val_loss: 0.3671 - val_accuracy: 0.9203\n",
      "Epoch 421/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0665 - accuracy: 0.9756 - val_loss: 0.2995 - val_accuracy: 0.9208\n",
      "Epoch 422/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0626 - accuracy: 0.9750 - val_loss: 0.2927 - val_accuracy: 0.9221\n",
      "Epoch 423/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 0.3225 - val_accuracy: 0.9248\n",
      "Epoch 424/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0598 - accuracy: 0.9766 - val_loss: 0.3260 - val_accuracy: 0.9181\n",
      "Epoch 425/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0516 - accuracy: 0.9783 - val_loss: 0.3222 - val_accuracy: 0.9235\n",
      "Epoch 426/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0570 - accuracy: 0.9777 - val_loss: 0.2894 - val_accuracy: 0.9221\n",
      "Epoch 427/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0544 - accuracy: 0.9776 - val_loss: 0.3140 - val_accuracy: 0.9230\n",
      "Epoch 428/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0842 - accuracy: 0.9714 - val_loss: 0.3295 - val_accuracy: 0.9217\n",
      "Epoch 429/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0570 - accuracy: 0.9781 - val_loss: 0.2927 - val_accuracy: 0.9212\n",
      "Epoch 430/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0585 - accuracy: 0.9782 - val_loss: 0.2799 - val_accuracy: 0.9275\n",
      "Epoch 431/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0687 - accuracy: 0.9753 - val_loss: 0.3014 - val_accuracy: 0.9221\n",
      "Epoch 432/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0574 - accuracy: 0.9792 - val_loss: 0.2965 - val_accuracy: 0.9226\n",
      "Epoch 433/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.2890 - val_accuracy: 0.9217\n",
      "Epoch 434/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.3152 - val_accuracy: 0.9239\n",
      "Epoch 435/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0601 - accuracy: 0.9790 - val_loss: 0.3125 - val_accuracy: 0.9172\n",
      "Epoch 436/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0585 - accuracy: 0.9786 - val_loss: 0.2924 - val_accuracy: 0.9212\n",
      "Epoch 437/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.2744 - val_accuracy: 0.9270\n",
      "Epoch 438/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0465 - accuracy: 0.9817 - val_loss: 0.3622 - val_accuracy: 0.9159\n",
      "Epoch 439/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0543 - accuracy: 0.9782 - val_loss: 0.4253 - val_accuracy: 0.9079\n",
      "Epoch 440/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0560 - accuracy: 0.9782 - val_loss: 0.4127 - val_accuracy: 0.9043\n",
      "Epoch 441/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0559 - accuracy: 0.9799 - val_loss: 0.2877 - val_accuracy: 0.9230\n",
      "Epoch 442/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0592 - accuracy: 0.9777 - val_loss: 0.3039 - val_accuracy: 0.9226\n",
      "Epoch 443/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0532 - accuracy: 0.9807 - val_loss: 0.2778 - val_accuracy: 0.9292\n",
      "Epoch 444/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0569 - accuracy: 0.9772 - val_loss: 0.3109 - val_accuracy: 0.9199\n",
      "Epoch 445/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0537 - accuracy: 0.9780 - val_loss: 0.3153 - val_accuracy: 0.9199\n",
      "Epoch 446/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0509 - accuracy: 0.9817 - val_loss: 0.3492 - val_accuracy: 0.9128\n",
      "Epoch 447/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0502 - accuracy: 0.9806 - val_loss: 0.3309 - val_accuracy: 0.9199\n",
      "Epoch 448/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0563 - accuracy: 0.9769 - val_loss: 0.3912 - val_accuracy: 0.8963\n",
      "Epoch 449/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0531 - accuracy: 0.9791 - val_loss: 0.3017 - val_accuracy: 0.9190\n",
      "Epoch 450/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0573 - accuracy: 0.9782 - val_loss: 0.3329 - val_accuracy: 0.9163\n",
      "Epoch 451/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0486 - accuracy: 0.9803 - val_loss: 0.3171 - val_accuracy: 0.9159\n",
      "Epoch 452/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0506 - accuracy: 0.9809 - val_loss: 0.3867 - val_accuracy: 0.9105\n",
      "Epoch 453/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0464 - accuracy: 0.9815 - val_loss: 0.2974 - val_accuracy: 0.9181\n",
      "Epoch 454/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0556 - accuracy: 0.9781 - val_loss: 0.3077 - val_accuracy: 0.9217\n",
      "Epoch 455/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0554 - accuracy: 0.9792 - val_loss: 0.3002 - val_accuracy: 0.9248\n",
      "Epoch 456/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0532 - accuracy: 0.9791 - val_loss: 0.3606 - val_accuracy: 0.9159\n",
      "Epoch 457/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0553 - accuracy: 0.9797 - val_loss: 0.3183 - val_accuracy: 0.9199\n",
      "Epoch 458/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0477 - accuracy: 0.9819 - val_loss: 0.3372 - val_accuracy: 0.9186\n",
      "Epoch 459/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0651 - accuracy: 0.9747 - val_loss: 0.3258 - val_accuracy: 0.9203\n",
      "Epoch 460/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0515 - accuracy: 0.9806 - val_loss: 0.3346 - val_accuracy: 0.9137\n",
      "Epoch 461/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0434 - accuracy: 0.9830 - val_loss: 0.4108 - val_accuracy: 0.9070\n",
      "Epoch 462/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0625 - accuracy: 0.9765 - val_loss: 0.3537 - val_accuracy: 0.9163\n",
      "Epoch 463/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0582 - accuracy: 0.9786 - val_loss: 0.3231 - val_accuracy: 0.9137\n",
      "Epoch 464/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0468 - accuracy: 0.9816 - val_loss: 0.3303 - val_accuracy: 0.9194\n",
      "Epoch 465/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0565 - accuracy: 0.9793 - val_loss: 0.3057 - val_accuracy: 0.9199\n",
      "Epoch 466/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0465 - accuracy: 0.9807 - val_loss: 0.5180 - val_accuracy: 0.9034\n",
      "Epoch 467/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0578 - accuracy: 0.9765 - val_loss: 0.3393 - val_accuracy: 0.9194\n",
      "Epoch 468/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0527 - accuracy: 0.9786 - val_loss: 0.2909 - val_accuracy: 0.9172\n",
      "Epoch 469/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0479 - accuracy: 0.9822 - val_loss: 0.3380 - val_accuracy: 0.9194\n",
      "Epoch 470/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0586 - accuracy: 0.9774 - val_loss: 0.3681 - val_accuracy: 0.9141\n",
      "Epoch 471/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0462 - accuracy: 0.9816 - val_loss: 0.3249 - val_accuracy: 0.9230\n",
      "Epoch 472/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0519 - accuracy: 0.9804 - val_loss: 0.3062 - val_accuracy: 0.9283\n",
      "Epoch 473/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0440 - accuracy: 0.9835 - val_loss: 0.3198 - val_accuracy: 0.9243\n",
      "Epoch 474/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0586 - accuracy: 0.9790 - val_loss: 0.3528 - val_accuracy: 0.9208\n",
      "Epoch 475/500\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0499 - accuracy: 0.9813 - val_loss: 0.4817 - val_accuracy: 0.8927\n",
      "Epoch 476/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0507 - accuracy: 0.9790 - val_loss: 0.2805 - val_accuracy: 0.9288\n",
      "Epoch 477/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0504 - accuracy: 0.9832 - val_loss: 0.3175 - val_accuracy: 0.9208\n",
      "Epoch 478/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0547 - accuracy: 0.9789 - val_loss: 0.3128 - val_accuracy: 0.9226\n",
      "Epoch 479/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0515 - accuracy: 0.9793 - val_loss: 0.2864 - val_accuracy: 0.9310\n",
      "Epoch 480/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0497 - accuracy: 0.9813 - val_loss: 0.3503 - val_accuracy: 0.9194\n",
      "Epoch 481/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.3551 - val_accuracy: 0.9208\n",
      "Epoch 482/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0516 - accuracy: 0.9783 - val_loss: 0.3194 - val_accuracy: 0.9235\n",
      "Epoch 483/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0553 - accuracy: 0.9809 - val_loss: 0.3216 - val_accuracy: 0.9217\n",
      "Epoch 484/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0523 - accuracy: 0.9806 - val_loss: 0.2933 - val_accuracy: 0.9297\n",
      "Epoch 485/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0436 - accuracy: 0.9848 - val_loss: 0.2709 - val_accuracy: 0.9306\n",
      "Epoch 486/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0485 - accuracy: 0.9813 - val_loss: 0.3143 - val_accuracy: 0.9150\n",
      "Epoch 487/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0473 - accuracy: 0.9821 - val_loss: 0.3114 - val_accuracy: 0.9248\n",
      "Epoch 488/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0581 - accuracy: 0.9785 - val_loss: 0.3076 - val_accuracy: 0.9266\n",
      "Epoch 489/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0491 - accuracy: 0.9816 - val_loss: 0.3263 - val_accuracy: 0.9190\n",
      "Epoch 490/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0458 - accuracy: 0.9821 - val_loss: 0.3015 - val_accuracy: 0.9292\n",
      "Epoch 491/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0500 - accuracy: 0.9802 - val_loss: 0.3118 - val_accuracy: 0.9230\n",
      "Epoch 492/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0580 - accuracy: 0.9786 - val_loss: 0.2964 - val_accuracy: 0.9301\n",
      "Epoch 493/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0494 - accuracy: 0.9804 - val_loss: 0.3631 - val_accuracy: 0.9266\n",
      "Epoch 494/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0479 - accuracy: 0.9812 - val_loss: 0.3353 - val_accuracy: 0.9168\n",
      "Epoch 495/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0564 - accuracy: 0.9792 - val_loss: 0.4132 - val_accuracy: 0.9172\n",
      "Epoch 496/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0489 - accuracy: 0.9826 - val_loss: 0.3196 - val_accuracy: 0.9230\n",
      "Epoch 497/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0364 - accuracy: 0.9854 - val_loss: 0.3507 - val_accuracy: 0.9279\n",
      "Epoch 498/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0428 - accuracy: 0.9832 - val_loss: 0.3095 - val_accuracy: 0.9261\n",
      "Epoch 499/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0470 - accuracy: 0.9831 - val_loss: 0.3347 - val_accuracy: 0.9248\n",
      "Epoch 500/500\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0536 - accuracy: 0.9806 - val_loss: 0.3083 - val_accuracy: 0.9261\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 500\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    BATCH_SIZE, \n",
    "    EPOCHS, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard])\n",
    "\n",
    "model.save(\"D:/Project2022/models/\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuuracy 0.9320042729377747\n",
      "Test loss 0.31488239765167236\n"
     ]
    }
   ],
   "source": [
    "# test loss, test accuracy\n",
    "accuracy = model.evaluate(X_test, y_test, batch_size=100, verbose=0)\n",
    "print(\"Test acuuracy\", accuracy[1])\n",
    "print(\"Test loss\", accuracy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000231C89B3E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000231C89B3E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "88/88 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       0.94      0.92      0.93      1395\n",
      "      Normal       0.92      0.94      0.93      1414\n",
      "\n",
      "    accuracy                           0.93      2809\n",
      "   macro avg       0.93      0.93      0.93      2809\n",
      "weighted avg       0.93      0.93      0.93      2809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_test)\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"covid\", \"Normal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEGCAYAAADGwUaDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAg/0lEQVR4nO3deZxe4/3/8dd7su8SSUglISVohKKxfYsiviVdvpZaorSob7VKLbWU+v6+qm1a/aK10xS1i6UtUUsQUqWISJCFkIjEEIksYss2M5/fH+dM3Bmz3HNn5txzz7yfj8d53OdcZ7muM5N85rqvc13XUURgZmbZKCt2AczM2hIHXTOzDDnompllyEHXzCxDDrpmZhlqX+wCFFufPmUxaGC7YhfDGuGtGT2LXQRrpA9j2ZKI6Lch1zhg326xdFllg8e9+MrqCRFx4Ibk1ZzafNAdNLAdDz3Ut9jFsEb4wdb7F7sI1kiPrrxt/oZeY+mySiZPGNzgce0GvNGi/0O3+aBrZqUhgCqqil2MDeaga2YlIQjWRsPNCy2dg66ZlQzXdM3MMhIEla1g2gIHXTMrGVU46JqZZSKASgddM7PsuKZrZpaRANa6TdfMLBtBuHnBzCwzAZWlH3MddM2sNCQj0kqfg66ZlQhRiYpdiA3moGtmJSF5kOaga2aWiaSfroOumVlmqlzTNTPLhmu6ZmYZCkRlK3jDmIOumZUMNy+YmWUkEGui9N9nWPp1dTNrE5LBEWUNLvmQdKOkxZJm5KRdLOk1Sa9I+rukjXL2nSdpjqTZkg7ISf+KpOnpviskNVgVd9A1s5JRmQ6QqG/J001AzTcGPwYMj4gdgNeB8wAkDQNGA9ul51wjqbrKfS1wIjA0XRp8C7GDrpmVhAhRGWUNLvldK54CltVIezQiKtLN54CB6fpBwLiIWB0R84A5wK6SBgA9I+LZiAjgFuDghvJ2m66ZlYyq/GqyfSVNydkeGxFjG5nVD4C70vXNSIJwtfI0bW26XjO9Xg66ZlYSkgdpeYWsJRExotB8JJ0PVAC3VyfVWpy60+vloGtmJaH6QVpzknQs8C1gZNpkAEkNdlDOYQOBd9P0gbWk18ttumZWMipDDS6FknQg8HPgvyLi05xd44HRkjpJGkLywGxyRCwEPpK0e9pr4fvA/Q3l45qumZWEphyRJulOYB+S9t9y4AKS3gqdgMfSnl/PRcSPI2KmpLuBWSTNDidHRGV6qZNIekJ0AR5Ol3o56JpZyajKs3dCQyLiqFqSb6jn+DHAmFrSpwDDG5O3g66ZlYRkwpvSbxF10DWzkhCIta1gGLCDrpmVhAjyHvzQkjnomlmJUL6DI1o0B10zKwmBa7pmZpnygzQzs4wE8iTmZmZZSV7BXvohq/TvwMzaiEbNl9tiOeiaWUkImm5EWjE56JpZyXBN18wsIxFyTdfMLCvJgzQPAzYzy4g8OMLMLCvJgzS36ZqZZcYj0szMMuIRaWZmGWvuF1NmwUHXzEpCBKytctA1M8tE0rzgoGtmlhmPSLNM3XDWUF6a2JueG69lzOPTABg3ZgteerwP7TsE/TdfxQmXvE63XpVUrBV/OWcr5s/oTmWl+Oqhi/nWKeUAXPK97VixuCOVFbD1rh/y/d/Mpaz0+5y3eGf8/k123Xc5HyztwEmjdgBgz1FLOea0dxi01UpOP2Q73pjeHYCd9lzB8WcvoH3HoGKNuOGiwbz8bK9iFr/oWkuXsaLW1SVtKmmcpLmSZkl6SNLWjbzGCElX1LHvLUl9m6a0xbfn4Ys485aZ66UN3+sDxjw2ld88Oo1Nh6zkwasHAfDCg31Zu6aM3zw2jV8++BJP3rEp77/dCYCTr3mNX0+YxpjHp/HRsg5MfrDV/IhatMfu7cv/HL/temnzX+/Kr08ayozJPdZL/3BZe375w234yagduPTsLTnr0rlZFrWFSpoXGlpauqLVdCUJ+Dtwc0SMTtN2BDYBXs/3Oul756c0Rxlbmm12+3Bd4Kw2fO8P1q1vufNHvPDQxgBIwepP21FZAWtXldG+Q9ClRyXAus/KClGxpqwVfGErDTNe6En/zVavl/b23C61Hjt3Vrd16/Nf70LHTkGHjlWsXdPyg0pzag3vSCvmb3BfYG1EXFedEBEvAU9LuljSDEnTJR0JIOkuSd+oPlbSTZK+I2kfSf9I0zaW9KikaZL+BK3gN9QIT921CTvssxyAEd9YSqeulZw+Yjd+tvsujDqxnO4bVaw79pJjtuPUnXajS/cKdvnmkmIV2fKw56hlzJ3Vtc0H3KT3QrsGl5aumL/F4cCLtaQfCuwIfBnYH7hY0gBgHFAdgDsCI4GHapx7AfB0ROwEjAcG15axpBMlTZE0Zemyqia4leIbf+VA2rUP9jjkfQDmvdSdsnbBH1+YzCXPTOGRP2/G4vmf1ZLPum0ml015nrVrypj1zEZFKrU1ZPDQT/nBOW9z5flDil2UoqseHNHQkg9JN0paLGlGTlofSY9JeiP97J2z7zxJcyTNlnRATvpX0srhHElXpN/g69US/3TuCdwZEZURsQj4J7AL8DCwn6ROwCjgqYhYWePcvYHbACLiQWB5bRlExNiIGBERIzbu0xJ/BI3z9D39eXliH350xWyqf+XP3t+P7b+2nPYdgp591zJ0xEe89cr67YYdOwc77b+MaY/1KUKprSF9N13N/7vuDS45a0sWLuhc7OK0CFXpa9jrW/J0E3BgjbRzgYkRMRSYmG4jaRgwGtguPecaSdVV6muBE4Gh6VLzmp9TzIgzE/hKLem1/tQiYhUwCTiApMY7ro7rRlMUrlS8MmkjHrp2IKfdMItOXT6rtW/8hdW8+u+NiIDVn5Yxd2oPBmz1Kas+KeODRR0AqKyAV57szYAta/7tsmLr1qOCC294nZsuHsSsF3s0fEIbUN17oSlquhHxFLCsRvJBwM3p+s3AwTnp4yJidUTMA+YAu6bfwHtGxLMREcAtOefUqZhdxp4AfivphxHxZwBJu5DUTo+UdDPQh6T2enZ6zjjgv4ERwHG1XPMp4GjgN5JGAb1rOaZkXXvKNrz2bC8+Xt6eM3bdhYN/toAHrx5IxZoyLj56OABb7vQRx/1uLiOPXcj1Z27N+fvvBCH2PGIRg770KSve78DlJwxj7ZoyqirhS19dwb7HLCzynbUNP798Djvs9iE9e1dw6zNTufXygXz8QXtOuuAtevWp4MIbZvPmrG78z3Hb8u3vL+ILm6/iqFPe4ahT3gHg/GO3ZcXSDkW+i+LKs3dCX0m5D9fHRsTYPM7bJCIWAkTEQkn90/TNgOdyjitP09am6zXT61W0oBsRIekQ4DJJ5wKrgLeA04HuwMskf9zOiYj30tMeJflrMj4i1tRy2QuBOyVNJWmWWNCsN5Gxk66a/bm0r41eVOuxnbtVccp1r30uvVe/tVzwj5ebvGzWsN+ftlWt6f9+9PPNO+Ou3oxxVzf4/7dNiRAV+QXdJRExogmzrq36HPWk16uogyMi4l3giFp2nc1ntdvc49cCG9dIm0TS7EBELAW+nrP7jCYqqpm1AM08OGKRpAFpLXcAsDhNLwcG5Rw3EHg3TR9YS3q9Sv8pkpm1CU3ZpluH8cCx6fqxwP056aMldZI0hOSB2eS0KeIjSbunvRa+n3NOnTwM2MxKRlPVdCXdCexD0v5bTtLd9CLgbkknkDRNHg4QETMl3Q3MAiqAkyOiMr3USSQ9IbqQ9LB6uKG8HXTNrCQ05STmEXFUHbtG1nH8GGBMLelTSMYc5M1B18xKRmsYBuyga2YlIQIqPIm5mVl2WsPUjg66ZlYS/GJKM7OMhYOumVl2/CDNzCwjEW7TNTPLkKh07wUzs+y4TdfMLCOt5W3ADrpmVhoiadctdQ66ZlYy3HvBzCwj4QdpZmbZcvOCmVmG3HvBzCwjEQ66ZmaZcpcxM7MMuU3XzCwjgahy7wUzs+y0goqug66ZlQg/SDMzy1grqOo66JpZyWjVNV1JV1LP35WIOLVZSmRmVosAqqpacdAFpmRWCjOzhgTQmmu6EXFz7rakbhHxSfMXycysdq2hn26Dnd4k7SFpFvBquv1lSdc0e8nMzGqKPJY8SDpD0kxJMyTdKamzpD6SHpP0RvrZO+f48yTNkTRb0gEbcgv59DS+DDgAWAoQES8De29IpmZmjSciGl4avIq0GXAqMCIihgPtgNHAucDEiBgKTEy3kTQs3b8dcCBwjaR2hd5FXsM7IuLtGkmVhWZoZlawJqrpkjStdpHUHugKvAscBFQ3q94MHJyuHwSMi4jVETEPmAPsWugt5BN035b0H0BI6ijpLNKmBjOzzARElRpcgL6SpuQsJ653mYh3gEuABcBCYEVEPApsEhEL02MWAv3TUzYDciue5WlaQfLpp/tj4PI0k3eACcDJhWZoZla4vHovLImIEXVeIWmrPQgYAnwA3CPpmEZmWvAjvQaDbkQsAY4uNAMzsybTNL0X9gfmRcT7AJL+BvwHsEjSgIhYKGkAsDg9vhwYlHP+QJLmiILk03vhi5IekPS+pMWS7pf0xUIzNDMrWNO06S4AdpfUVZKAkSRNpuOBY9NjjgXuT9fHA6MldZI0BBgKTC70FvJpXrgDuBo4JN0eDdwJ7FZopmZmjdZEgyMi4nlJ9wJTgQpgGjAW6A7cLekEksB8eHr8TEl3A7PS40+OiII7E+QTdBURt+Zs3ybplEIzNDMrVFMNjoiIC4ALaiSvJqn11nb8GGBMU+Rd39wLfdLVJyWdC4wj+VtzJPBgU2RuZtYorXzuhRdJgmz1Xf4oZ18Av26uQpmZ1UatYBhwfXMvDMmyIGZm9Wrc4IcWK6/5dCUNB4YBnavTIuKW5iqUmdnnqXXPMlZN0gXAPiRB9yFgFPA04KBrZtlqBTXdfIYBH0byRO+9iDge+DLQqVlLZWZWm6o8lhYun+aFlRFRJalCUk+SURoeHGFm2Wrtk5jnmCJpI+DPJD0aPmYDRmOYmRWqVfdeqBYRP0lXr5P0CNAzIl5p3mKZmdWiNQddSTvXty8ipjZPkczMWq/6arqX1rMvgP2auCxFMW96D44bvGexi2GNMOHd54pdBGukdgOa5jqtunkhIvbNsiBmZvUKWv0wYDOzlqU113TNzFqaVt28YGbW4rSCoJvPmyMk6RhJ/5tuD5ZU8JswzcwK1nRvAy6afIYBXwPsARyVbn9E8iYJM7PMKPJbWrp8mhd2i4idJU0DiIjlkjo2c7nMzD6vjfReWCupHWnFXVI/SmJaCTNrbUqhJtuQfJoXrgD+DvSXNIZkWsffNmupzMxq0wradPOZe+F2SS+STO8o4OCIeLXZS2ZmlqtE2mwbks8k5oOBT4EHctMiYkFzFszM7HPaQtAlefNv9QsqOwNDgNnAds1YLjOzz1EreJqUT/PC9rnb6exjP6rjcDMzq0ejR6RFxFRJuzRHYczM6tUWmhck/SxnswzYGXi/2UpkZlabJnyQlr4N53pgeHJlfkDSbHoXsAXwFnBERCxPjz8POAGoBE6NiAmF5p1Pl7EeOUsnkjbegwrN0MysYE3XZexy4JGI2JbkZbuvAucCEyNiKDAx3UbSMGA0yXOsA4Fr0rELBam3ppteuHtEnF1oBmZmTaYJarrpC3b3Bo4DiIg1wBpJBwH7pIfdDEwCfk5SyRwXEauBeZLmALsCzxaSf501XUntI6KSpDnBzKyoRNJ7oaElD18kaSL9i6Rpkq6X1A3YJCIWAqSf/dPjNwPezjm/PE0rSH013ckkAfclSeOBe4BPqndGxN8KzdTMrNHyb9PtK2lKzvbYiBibs92eJLb9NCKel3Q5aVNCHWqb8KHgOnc+vRf6AEtJ3olW3V83AAddM8tWfqFuSUSMqGd/OVAeEc+n2/eSBN1FkgZExEJJA4DFOccPyjl/IPBuo8qdo74Haf3TngszgOnp58z0c0ahGZqZFawJHqRFxHvA25K2SZNGArOA8cCxadqxwP3p+nhgtKROkoYAQ0laAgpSX023HdCdJq5am5kVqgnnXvgpcHs6Te2bwPEkldC7JZ0ALAAOB4iImZLuJgnMFcDJ6fOugtQXdBdGxK8KvbCZWZNroqAbES8BtTVBjKzj+DHAmKbIu76gW/qzBZtZ6xGtf+6FWiO+mVnRtIKGzTqDbkQsy7IgZmYNaRPz6ZqZtRgOumZmGSmR1/E0xEHXzEqCcPOCmVmmHHTNzLLkoGtmliEHXTOzjLSVV7CbmbUYDrpmZtlp7cOAzcxaFDcvmJllxYMjzMwy5qBrZpYNj0gzM8uYqko/6jromllpcJuumVm23LxgZpYlB10zs+y4pmtmliUHXTOzjLSBtwGbmbUY7qdrZpa1KP2o66BrZiXDNV1rEQZuuYpfXDd/3famg9dw68Wb8vK/u/PTi8rp0q2KReUd+f3Jg/n043ZFLGnbc+kZg3j+8Z5s1LeCsU/OBuDm/9uUZyf0QoKN+q7lrMsWsPGmFbw2rSuXnz0ISJ4Xfe/M9/jqqBUAnP2drVi2qD0dOydR53fj5rJR34qi3FPRNPHgCEntgCnAOxHxLUl9gLuALYC3gCMiYnl67HnACUAlcGpETCg037INLHedJIWkS3O2z5L0y+bKr44yTJI0Iss8i6F8bmd+8p/b8JP/3IZTDtia1SvLeObhXpx+ydvc+NsB/HjkNjzzcE8OO2lxsYva5nz9yGWMuf3N9dIOO2kx102czbWPz2a3/T/ktj9uCsAW26zkqkeS9DG3z+XycwZSmRNXf371fK59PNnf5gJuSlUNL41wGvBqzva5wMSIGApMTLeRNAwYDWwHHAhckwbsgjRb0AVWA4dK6lvIyZJcCy/Ajnt9zML5HVn8TkcGbrma6c91A2DaUz3Y85srily6tmf73T+hR+/K9dK69fgsMqxaWYaUrHfuGrRL/9WvXf1Zun2mqYKupIHAN4Hrc5IPAm5O128GDs5JHxcRqyNiHjAH2LXQe2jOwFYBjAXOAM7P3SFpc+BGoB/wPnB8RCyQdBOwDNgJmCppY2AlsC2wOXA8cCywB/B8RByXXu9aYBegC3BvRFzQjPfVou1z0HIm3dcbgPmzO7PHAR/y7IRe7PWtFfT7wtoil86q/eWiTXn8nj5061nJ/907Z136a1O7cunPBrG4vCPnXLlgXRAGuPSMwZSVwZ7f/IDvnr6o7QXlIN8HaX0lTcnZHhsRY2sccxlwDtAjJ22TiFgIEBELJfVP0zcDnss5rjxNK0hz1nQBrgaOltSrRvpVwC0RsQNwO3BFzr6tgf0j4sx0uzewH0nwfgD4I0k1f3tJO6bHnB8RI4AdgK9J2qG+Qkk6UdIUSVPWsrrwu2th2neoYvevf8hTDyQ/7j/8bBDfPm4JVz3yOl26V1Kxpq39L225jj/3PW5/cRb7Hbqc8Tf2W5e+7c6f8udJs7ny4dcZd2V/1qxKfmc/v2o+f3piNpfe9wYznu/G4/f2LlbRi0rR8AIsiYgROct6AVfSt4DFEfFivtnWklZw63KzBt2I+BC4BTi1xq49gDvS9VuBPXP23RMRud/HHoiIAKYDiyJiekRUATNJGrwBjpA0FZhGEpCHNVCusdW/kA50KuDOWqZd9vuIOdO78MGSDgC8PaczvzhqS045cGsm3debhfM7FrmEVtO+hyzn6Ydq1klg8NDVdO5axVuzOwPQd0DyLaVr9yr2PeQDZk/rmmk5W4zIY2nYV4H/kvQWMA7YT9JtwCJJAwDSz+qHIOXAoJzzBwLvFnoLzV3ThaQafwLQrZ5jcn9Un9TYV10VrcpZr95uL2kIcBYwMq05Pwh03pACl6p9Dv5gXdMCQK+Nk/+oUvDd0xbxj1s3LlbRLMc7b372x++5Cb0YtFXyz/q9BR3XPThbVN6B8rmd2WTgGiorYMXS5LlNxVp4/vGebLHtqszLXWzVgyPyqOnWKyLOi4iBEbEFyQOyJyLiGGA8SfMl6ef96fp4YLSkTmm8GQpMLvQ+mv1hVUQsk3Q3SeC9MU3+N8nN3gocDTy9AVn0JAnUKyRtAowCJm3A9UpSpy5V7LzXR1x+zsB1afse/AHfPm4JAM883ItHx/UpVvHarN+dtDmvPNudFcvac/RXhvG9M99j8hM9KZ/bibIy6L/ZGk79fTkAMyZ3466rhtC+PZSVBT/9bTm9Nq5k1adl/OK7W1JZISorYee9PmbU0UuLfGdFENHck5hfBNwt6QRgAXB4km3MTGPYLJJnVSfX+DbeKFn1ELgUOCVn+1TgRklnkz5IK/TCEfGypGkkzQ1vAs9sSEFL1eqVZRw+fPh6affd0I/7buhXxxmWhfOunf+5tAO/u6zWY/c/bDn7H7b8c+mdu1Zx9YTXm7xsJamJY25ETCKtpEXEUmBkHceNAcY0RZ7NFnQjonvO+iKga872WyQPx2qec1xd2+k5w+vYt955Oen7NLbcZtZyeUSamVlWAvA70szMMlT6MddB18xKh5sXzMwy5Fewm5llxa9gNzPLTjI4ovSjroOumZUOvyPNzCw7rumamWXFbbpmZllq9rkXMuGga2alw80LZmYZiUa/A61FctA1s9Lhmq6ZWYZKP+Y66JpZ6VBV6bcvOOiaWWkIPDjCzCwrIjw4wswsUw66ZmYZctA1M8uI23TNzLLl3gtmZpkJNy+YmWUmcNA1M8tU6bcuOOiaWeloDf10y4pdADOzvEU0vDRA0iBJT0p6VdJMSael6X0kPSbpjfSzd84550maI2m2pAM25BYcdM2sNERAZVXDS8MqgDMj4kvA7sDJkoYB5wITI2IoMDHdJt03GtgOOBC4RlK7Qm/DQdfMSkcT1HQjYmFETE3XPwJeBTYDDgJuTg+7GTg4XT8IGBcRqyNiHjAH2LXQW3DQNbPSkV/Q7StpSs5yYl2Xk7QFsBPwPLBJRCxMsomFQP/0sM2At3NOK0/TCuIHaWZWGgLI7x1pSyJiREMHSeoO/BU4PSI+lFTnoXWUpiCu6ZpZiQiIqoaXPEjqQBJwb4+Iv6XJiyQNSPcPABan6eXAoJzTBwLvFnoXDrpmVhqCJnmQpqRKewPwakT8IWfXeODYdP1Y4P6c9NGSOkkaAgwFJhd6G25eMLPS0TT9dL8KfA+YLumlNO0XwEXA3ZJOABYAhydZxkxJdwOzSHo+nBwRlYVm7qBrZqWjCYJuRDxN7e20ACPrOGcMMGaDM8dB18xKhie8MTPLTgCe2tHMLEOu6ZqZZSXyHebbojnomllpCIg8++G2ZA66ZlY68huR1qI56JpZ6XCbrplZRiLce8HMLFOu6ZqZZSWIyoJH37YYDrpmVhryn9qxRXPQNbPS4S5jZmbZCCBc0zUzy0iEa7pmZllqDQ/SFK2gC8aGkPQ+ML/Y5WgmfYElxS6E5a01/742j4h+G3IBSY+Q/IwasiQiDtyQvJpTmw+6rZmkKfm8oM9aBv++2ga/I83MLEMOumZmGXLQbd3GFrsA1ij+fbUBbtM1M8uQa7pmZhly0DUzy5CDbomQtKmkcZLmSpol6SFJWzfyGiMkXVHHvrck5dMH0mohKSRdmrN9lqRfZlyGSZLc5ayFc9AtAZIE/B2YFBFbRsQw4BfAJo25TkRMiYhTm6OMxmrg0EL/cEny6NA2wkG3NOwLrI2I66oTIuIl4GlJF0uaIWm6pCMBJN0l6RvVx0q6SdJ3JO0j6R9p2saSHpU0TdKfAGV7S61OBUnvgzNq7pC0uaSJkl5JPwen6TdJ+oOkJ4Hfp9vXSnpS0puSvibpRkmvSrop53rXSpoiaaakC7O6QWsaDrqlYTjwYi3phwI7Al8G9gculjQAGAdUB+COwEjgoRrnXgA8HRE7AeOBwc1S8rblauBoSb1qpF8F3BIROwC3A7lNPFsD+0fEmel2b2A/kuD9APBHYDtge0k7psecn45c2wH4mqQdmuNmrHk46Ja2PYE7I6IyIhYB/wR2AR4G9pPUCRgFPBURK2ucuzdwG0BEPAgsz67YrVNEfAjcAtRswtkDuCNdv5Xk91btnojIncXlgUj6cU4HFkXE9EjeOz4T2CI95ghJU4FpJAF5WJPeiDUrB93SMBP4Si3ptTYJRMQqYBJwAEmNd1wd13Un7aZ3GXAC0K2eY3J/7p/U2Lc6/azKWa/ebi9pCHAWMDKtOT8IdN6QAlu2HHRLwxNAJ0k/rE6QtAtJ7fRISe0k9SOpvU5ODxkHHA/sBUyo5ZpPAUen1xpF8rXWNlBELAPuJgm81f4NjE7Xjwae3oAsepIE6hWSNiH5JmMlxE9MS0BEhKRDgMsknQusAt4CTge6Ay+T1J7OiYj30tMeJfmqOz4i1tRy2QuBO9Ovqf8EFjTrTbQtlwKn5GyfCtwo6WzgfZI/hgWJiJclTSP59vMm8MyGFNSy52HAZmYZcvOCmVmGHHTNzDLkoGtmliEHXTOzDDnompllyEHXGiSpUtJL6RwP90jqugHXuknSYen69ZLqHE2VzhXxHwXkUeuMafnMpCbp40bm9UtJZzW2jNZ2OehaPlZGxI4RMRxYA/w4d6ekdoVcNCL+OyJm1XPIPkCjg65ZS+aga431L2CrtBb6pKQ7gOnpqLiLJb2Qzqb1I0impZR0VToH8INA/+oL5c7/KulASVMlvZzOxLUFSXA/I61l7yWpn6S/pnm8IOmr6bmNnjFN0n2SXkxn6jqxxr5L07JMTEf6IWlLSY+k5/xL0rZN8tO0Nscj0ixv6Zyvo4BH0qRdgeERMS8NXCsiYpd0op1nJD0K7ARsA2xPMv/vLODGGtftB/wZ2Du9Vp+IWCbpOuDjiLgkPe4O4I8R8XQ6PeIE4Et8NmParyR9E1gviNbhB2keXYAXJP01IpaSzJkwNSLOlPS/6bVPIZm28ccR8Yak3YBrSGYDM2sUB13LRxdJL6Xr/wJuIPnaPzki5qXpXwd2qG6vBXoBQ0nmg7gznUnrXUlP1HL93UlmQpsH6+YvqM3+wDBpXUW2p6QeaR6Hpuc+KCmfGdNOTYdWAwxKy7qUZGKZu9L024C/Seqe3u89OXl3yiMPs89x0LV8rIyIHXMT0uCTO0OWgJ9GxIQax32DhmczUx7HQNIctkfNaSrTsuQ9nl3SPiQBfI+I+FTSJOqeqSvSfD+o+TMwK4TbdK2pTABOktQBQNLWkrqRzGY2Om3zHUDyFoyaniWZjHtIem6fNP0joEfOcY+SM5FMzqTejZ0xrRewPA2425LUtKuVAdW19e+SNFt8CMyTdHiahyR9uYE8zGrloGtN5XqS9tqpkmYAfyL5JvV34A2SSbmvJZnRbD0R8T5JO+zfJL3MZ1/vHwAOqX6QRjJb14j0Qd0sPutFcSGwdzpj2tdpeMa0R0jmpn0F+DXwXM6+T4DtJL1I0mb7qzT9aOCEtHwzgYPy+JmYfY5nGTMzy5BrumZmGXLQNTPLkIOumVmGHHTNzDLkoGtmliEHXTOzDDnompll6P8DiCIgRa3saJUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=[\"Covid\",\"Normal\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c50830f626f547e043f1157b775d5349ebf6934572c5315bc4ad9efe15cebdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
